<!DOCTYPE html>
<html lang="en">
<head><meta name="generator" content="Hexo 3.9.0">
    <script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5d32dc3eba941200129ff9a8&product=sop" async="async"></script>
    <meta charset="utf-8">
<title>Basic Deep learning 01 - Stand firm Peter</title>
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

<link rel="canonical" href="http://www.stand-firm-peter.me/2018/02/06/basic-deep learning-01/">


<meta property="og:image" content="/gallery/deepimg10.jpg">



<!-- <meta property="og:title" content=Basic Deep learning 01 - Stand firm Peter> -->
<meta property="og:description" content="Peter's playground.">

<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<script>
  (adsbygoogle = window.adsbygoogle || []).push({
    google_ad_client: "ca-pub-4926107872672843",
    enable_page_level_ads: true
  });
</script>


<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({
          google_ad_client: "ca-pub-4926107872672843",
          enable_page_level_ads: true
     });
</script>




<link rel="icon" href="/images/favicon.ico">


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.7.2/css/bulma.css">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.4.1/css/all.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Ubuntu:400,600|Source+Code+Pro">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css">


    
    
    
    <style>body>.footer,body>.navbar,body>.section{opacity:0}</style>
    

    
    
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css">
    

    
    

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.css">


    
    
    
    

<link rel="stylesheet" href="/css/back-to-top.css">


    
    
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-124184693-1"></script>
<script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-124184693-1');
</script>


    
    
    
    
<link rel="stylesheet" href="/css/progressbar.css">
<script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>

    
    
    

    
    
    


<link rel="stylesheet" href="/css/style.css">
</head>
<body class="is-2-column">
    <nav class="navbar navbar-main">
    <div class="container">
        <div class="navbar-brand is-flex-center">
            <a class="navbar-item navbar-logo" href="/">
            
                <img src="/images/icon1.jpg" alt="Basic Deep learning 01" height="28">
            
            </a>
        </div>
        <div class="navbar-menu">
            
            <div class="navbar-start">
                
                <a class="navbar-item" href="/">Home</a>
                
                <a class="navbar-item" href="/archives">Archives</a>
                
                <a class="navbar-item" href="/categories">Categories</a>
                
                <a class="navbar-item" href="/tags">Tags</a>
                
            </div>
            
            <div class="navbar-end">
                
                
                
                <a class="navbar-item search" title="Search" href="javascript:;">
                    <i class="fas fa-search"></i>
                </a>
                
            </div>
        </div>
    </div>
</nav>
    
    <section class="section">
        <div class="container">
            <div class="columns">
                <div class="column is-8-tablet is-8-desktop is-8-widescreen has-order-2 column-main"><div class="card">
    
    <div class="card-image">
        <span class="image is-7by1">
            <img class="thumbnail" src="/gallery/deepimg10.jpg" alt="Basic Deep learning 01">
        </span>
    </div>
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2018-02-06T14:31:02.000Z">2018-02-06</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/Machine-Learning/">Machine Learning</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    25 minutes read (About 3784 words)
                </span>
                
                
            </div>
        </div>
        
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                Basic Deep learning 01
            
        </h1>
        <div class="content">
            <ul>
<li>Deep Learning 개념 및 용어들을 알아봅니다.</li>
<li><code>Optimizer</code>, <code>Loss function</code>, <code>Back propagation</code>  </li>
</ul>
<a id="more"></a>


<h6 id="Peter-Cha"><a href="#Peter-Cha" class="headerlink" title="Peter Cha"></a>Peter Cha</h6><h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><ul>
<li><p>Deep Learning을 사용해서 우리가 하고자 하는 일련의 과정은 결국, 우리가 만든 AI(model)가 특정 데이터를 얼마나 잘, 데이터를 구별(classification), 혹은 감지(detection)할 수 있게 할 것인가? 하는 것입니다. 물론, GAN과 같은 Unsupervised Learning에서는 말이 달라 질 수 있지만, 설명을 위해 편의상 그렇다고 생각해봅시다. </p>
</li>
<li><p>AI를 학습시키고자 하는 데이터만 주면, model 스스로 ‘아, A는 이렇게 생겼구나, 이렇게 생기면 B라고 하구나’하고 그 데이터가 가지고 있는 특징(feature)을 스스로 깨우치기 원하는 거죠. 그렇게 잘 학습이 잘 되면, 한 번도 본 적은 없지만 여태껏 봐왔던 특징을 가지고 있는 새로운 이미지를 봤을 때, ‘아, 이건 A야.’혹은, ‘B야’하고 맞출 수 있게 되는 것이구요.</p>
</li>
<li><p>더 쉽게 이야기 해보죠. 우리는 강아지와 고양이가 어떻게 생겼는지 우리 model에게 알려주고, 처음보는 강아지나 고양이를 봐도 그 것이 강아지인지, 고양이인지 잘 구별할 수 있었으면 좋겠습니다. 아래 그림처럼 강아지와, 고양이 그림을 엄청나게 많이 주고 우리는 우리가 만든 Model에게 ‘강아지는 이렇게 생긴거야’, ‘고양이는 이렇게 생겼단다.’하고 알려줍니다. 우리는 이 과정을 학습, 혹은 training - learning이라고 부릅니다. 그렇게 잘 학습된 모델은, 훈련할 때 본 적은 없지만, 처음 본 강아지 사진(test)을 봐도 ‘얘는 강아지네요. 고양이는 아니에요’라고 말할 수 있게 됩니다. </p>
</li>
</ul>
<center><img src="/gallery/Model.jpg" width="700"></center>

<p>(Image from <a href="https://www.kdnuggets.com/2017/09/databricks-vision-making-deep-learning-simple.html" rel="external nofollow noopener noreferrer" target="_blank">KDnuggets</a>)</p>
<ul>
<li><p>The purpose of deep learning is all about the question, “How can we let our AI <code>classify</code> or <code>detect</code> the certain image or something?” Of course, there are exceptions like GAN, unspervised learning area, let’s simplify the concept for the explanation.</p>
</li>
<li><p>What we want to do is to create the model knowing the <code>characteristics</code> or <code>feature</code> of a particular class of data, so it can answer which class the data in.</p>
</li>
<li><p>Let’s talk more easily. We want to tell our model how puppies or cats look like and wish it can distinguish whether it is a puppy or a cat when it sees another puppy or another cat for the first time. As shown in the picture above, we give a lot of puppies and cats pictures to our model, and we teach the model, ‘puppy looks like this’, and ‘cat looks like this.’ This is called, <code>learning</code> or <code>training</code>. Then, as the process progresses, the model can distinguish the cat from the dog. That’s all what we are going to talk about.</p>
</li>
</ul>
<h3 id="In-this-post"><a href="#In-this-post" class="headerlink" title="In this post,"></a>In this post,</h3><ul>
<li><p>Deep Learning을 이해하고, 직접 Deep Learning을 구현하고자 했을 때 필요한 기본 개념들을 정리해 보았습니다. <code>학습</code>이란 무엇을 의미하는지, <code>Optimizer</code>는 어떤 역할을 하는 것인지, <code>Loss function</code>은 무엇인지, 그리고 마지막으로 <code>Back propagation</code>은 어떻게 진행되는지, 간단한 예시를 통해 알아보도록 하겠습니다. :) </p>
</li>
<li><p>In this post, I will talk about the basic concepts of deep learning. Let’s start to learn what <code>Learning</code> means, <code>Optimizer</code> does, <code>Loss function</code> is, and How the <code>Back propagation</code> works via a simple example. </p>
</li>
</ul>
<br>

<h2 id="Learning"><a href="#Learning" class="headerlink" title="Learning"></a>Learning</h2><ul>
<li><p>특정한 값을 예측을 하고 싶다고 하면, 우리는 먼저 실제로 그러한 예측을 할 수 있는 <code>Model</code>이 필요합니다. 그리고, 그 <u>모델이 예측한 값(<code>prediction</code>)과 실제 값(<code>grounth truth</code> or <code>answer</code>)과의 값의 차이</u>를 <code>loss</code>라고 말합니다.</p>
</li>
<li><p>예를 들어, 간단한 선형 모델인 <code>y = wx</code>을 우리가 모델로 가지고 있다고 합니다. <code>y</code>는 실제 정답이고 <code>x</code>는 input값 입니다. 이 때, <code>w</code>를 우리는 <strong>weight</strong>라고 부릅니다. 보통 맨 처음엔 이 <code>w</code>를 랜덤하게 고릅니다. w가 매우 적절하게 잘 정해져서 실제 정답인 <code>y</code>와 <code>wx</code>가 똑같은 값이 되었다면 $loss$는 0이 되겠죠!</p>
</li>
<li><p>그래서 Input인 x를 주면 정답인 y를 잘 맞추려면, 당연히 우리는 이 w를 잘 맞출 필요가 있습니다. 근데 위에서 말한 것 처럼 w를 랜덤하게 시작해서는 곤란하죠. 한 번 만에 잘 맞춘다는 건 힘듭니다. </p>
</li>
<li><p>그래서 우리는 학습을 진행을 함에 따라, 우리는 <u>무엇이 됐을지 모르는 이 <code>w</code>값</u>을 <code>반복적으로 update</code>를 시켜서, $loss$를 최소화 할 수 있게끔 만듭니다. </p>
</li>
<li><p>그래서 <code>학습</code>이라는 것은 <strong>loss를 최소화 시키는 w 찾기!</strong> 라고 할 수 있습니다. </p>
<hr>
</li>
<li><p>When we predict some values, firstly we need a <code>model</code> that can actually do predict, and we call the difference with a prediction and an actual value, ground truch, <code>loss</code>.</p>
</li>
<li><p>For example, if we have a linear model <code>y = wx</code>, <code>y</code> is the answer, and <code>x</code> is input. Then, we call the <code>w</code> <strong>weight</strong>. If the weight is set very properly, then the loss will be 0!</p>
</li>
<li><p>We often choose the inital value of <code>w</code> randomly.</p>
</li>
<li><p>As the training proceeds, we <code>repeatedly update</code> this w so that we can find minimizes the loss.</p>
</li>
<li><p>Therefore, <code>Learning</code> is <strong>finding</strong> <code>w</code> that <strong>minimizes the loss!</strong></p>
</li>
</ul>
<br>

<h2 id="Optimizer"><a href="#Optimizer" class="headerlink" title="Optimizer"></a>Optimizer</h2><center><img src="/gallery/gradient_descent_algorithm.png" width="500"></center>

<h3 id="Weight-update"><a href="#Weight-update" class="headerlink" title="Weight update"></a>Weight update</h3><ul>
<li><p>자,우리는 $loss$를 최소화시키는 $w$를 알고 싶습니다. 그럴 때, $w$가 값에따라, 그림과 같이 $loss$와 $w$의 값으로 그래프를 그렸다고 했을 때, U자로 형성됐다고 생각하고, $loss$를 최소화하는 $w$의 값으로 $w$를 update하고 싶습니다. 시작점은 편의상, 랜덤하게 정해졌다고 합시다.</p>
</li>
<li><p>w값을 update시키기 위해서, 우리는 다음과 같은 공식을 씁니다. 여기서 $\alpha$가 뜻하는 것은 <code>learning rate</code>라고 하는 것인데요, 보통 0.001같은 아주 작은 값이고, 그래서 <code>다음 학습할 때 쓸 w는 지금 w와 얼마만큼 떨어져있는지</code>정도를 의미합니다. </p>
<h3 id="w-w-alpha-cdot-frac-partial-loss-partial-w"><a href="#w-w-alpha-cdot-frac-partial-loss-partial-w" class="headerlink" title="$w = w - \alpha  \cdot \frac {\partial loss}{\partial w}$"></a>$w = w - \alpha  \cdot \frac {\partial loss}{\partial w}$</h3></li>
<li><p>이 w값은 미분을 하면 구할 수 있는데요, 미분의 의미는 결국 아주 작은 구간에서의 <code>순간변화율</code>이라고 우리가 알고 있는 만큼, 이는 미분은 곧, 기울기의 정도를 표현한다고 할 수 있죠. 이 $w$값을 구하기 위한 미분 방법은 아래에 나오는 Back Propagation을 소개하면서 다시 이야기 하도록 하겠습니다. </p>
</li>
<li><p>작은 예시로, Back Propagation이 ‘내가 지금 알고 있는 지식을 가지고 대학교 졸업 후의 나로 돌아 갈 수 있다면, 훨씬 더 좋은 선택과 결정을 하면서 살 수 있을 것이다.’ 같은 겁니다. 여기서, 근데 이 learning rate을 너무 크게 설정해줘서, 필요이상으로 군 입대 하루 전으로 돌아간다면 끔찍하겠죠? 그 과거로 ‘적절히’ 돌아가야 지금 가지고 있는 정보를 십분 활용할 수 있기 때문에, 이 learning rate라는 수치가 중요합니다. </p>
</li>
</ul>
<hr>

<ul>
<li><p>Let me think we want to know the value of weigh which minimizes the loss. If we draw a graph consists of loss and w, let us consider it looks like a bowl like the image above. Then, we want to <code>update</code> the weight to the point which becomes the value minimizing the loss. Of course, the starting point is randomly selected.</p>
</li>
<li><p>To update the w value, we use follwing equation. <code>alpha</code> means <code>learning rate</code> which is usually very small number like 0.001, so it means that <code>How far the next step w is from where now w is.</code>  </p>
<h3 id="w-w-alpha-cdot-frac-partial-loss-partial-w-1"><a href="#w-w-alpha-cdot-frac-partial-loss-partial-w-1" class="headerlink" title="$w = w - \alpha  \cdot \frac {\partial loss}{\partial w}$"></a>$w = w - \alpha  \cdot \frac {\partial loss}{\partial w}$</h3></li>
<li><p>As we know, the meaning of derivative is <code>Instantaneous rate of change</code>, inclination. Let me introduce the way how to calculate the derivative of w, later on the Back propagation part.</p>
</li>
</ul>
<h3 id="SGD"><a href="#SGD" class="headerlink" title="SGD"></a>SGD</h3><ul>
<li>미분을 이용하여, 만약 미분 결과값이 -인 경우, w는 좀더 양수쪽으로 가게 되고, 반대로는 음수로 가는 방식으로 우리는 w를 update할 수 있습니다. 이런 update 방법을 <code>Stochastic Gradient Descent</code> 최적화 - 한국어로는 경사하강법 -, 또는 줄여서 <code>SGD</code>라고 부릅니다. </li>
<li>SGD 이외에 최적화 기법으로 Adam, Adamx 등등 다양한 기법들이 있습니다만, 클래식한 이런 경사하강법의 방식의 다른 방식이라고 이해해도 크게 틀리지 않습니다.</li>
</ul>
<hr>

<ul>
<li>By using derivative, We can update the w in this way: if the drivative value(=gradient) is minus, then w will be move toward the posivie side, and visa versa. This kind of update approach is called <code>Stochastic Gradient Descent</code> Optimization, or <code>SGD</code> for short.</li>
<li>There are other more various different Optimizers like Adam, Adamax and so on, but you might think that those are different to classical stochastic gradient descent.</li>
</ul>
<br> 

<h2 id="Loss-function"><a href="#Loss-function" class="headerlink" title="Loss function"></a>Loss function</h2><ul>
<li>자, 그러면 위에서 설명한 loss라는 것을 계산하기 위해서는 어떤 방법을 사용할까요? </li>
<li><code>Loss function</code>을 설명하기 위해서, 쉬운 loss function 하나를 예시로 들어봅시다.</li>
<li><code>MSE</code>는 모델의 loss를 산출하는 방법 중 하나입니다. </li>
<li><code>MSE</code>는 Mean Squared Error의 준 말로, 문자 그대로 아래에 보이는 수식 - <strong>예측한 값에서 실제 값을 빼고 그 차이를 제곱하여 평균을 내는 방식</strong> - 으로 모델의 loss를 계산합니다.</li>
</ul>
<hr>

<ul>
<li><p>Here, what should we do to get the <code>loss</code> mentioned before?</p>
</li>
<li><p>To explain <code>loss function</code>, let’s take an easy loss function as an example.</p>
</li>
<li><p>MSE is an one of ways to measure the <code>loss</code> of a model.</p>
</li>
<li><p>The Acronym for the <strong>Mean Square Error</strong> which is following equation. <code>y hat</code> is a prediction of our model, and <code>y</code> is a real value. So, it means simply the sum of <strong>differences between forecasts and actual values.</strong></p>
<center><img src="/gallery/mse.png" width="250"></center>
</li>
<li><p>Binary class에 대한 loss를 구해줘야 할 때는, MSE 보다는 <code>BCEloss</code>를 더 잘 씁니다. 이렇게 더 다양한 loss function들이 있습니다. </p>
</li>
<li><p>There are various other loss functions like <code>BCEloss</code> for binary loss, and so on.</p>
</li>
</ul>
<br>

<h2 id="Back-Propagation"><a href="#Back-Propagation" class="headerlink" title="Back Propagation"></a>Back Propagation</h2><ul>
<li><p><code>역전파</code>라고도 하는, <code>Back Progagation</code>은 <code>loss를 weight로 미분한 값</code>을 계산하는 방법입니다.  </p>
</li>
<li><p>예를 들어, 우리의 모델이 선형회기식인, Linear model이라고 하고, 우리의 loss function이 MSE라고 합시다. </p>
</li>
<li><p>그러면 우리 모델이 loss를 구할 때 거쳐가게 될 공식은,<br>  $loss = (\hat y - y)^2$ 이기 때문에, 즉 $(x*w - y)^2$이 될테고,<br>  이 식은 아래의 그림과 같이 도식화 할 수 있습니다. </p>
<hr>
</li>
<li><p>Back propagation is the way to calculate the derivate value of loss by <code>w</code>.</p>
</li>
<li><p>For example, our model is a linear model, and we use MSE as a loss function. Then, the gates of our model will look like following.</p>
</li>
</ul>
<center><img src="/gallery/backprop1.png" width="600"></center>

<ul>
<li><code>x = 1, y = 2, 그리고 w = 1</code>이라고 합시다. 그러면 loss를 구하는 forward path는 명백합니다.</li>
<li>Let’s assume that <code>x = 1, y = 2, and w = 1</code>. Then, the forward path is obvious.</li>
</ul>
<center><img src="/gallery/forward.png" width="600"></center>



<h3 id="Derivate-Computation"><a href="#Derivate-Computation" class="headerlink" title="Derivate Computation"></a>Derivate Computation</h3><ul>
<li><a href="https://en.wikipedia.org/wiki/Chain_rule" rel="external nofollow noopener noreferrer" target="_blank">Chain Rule</a>에 의해서, 우리는 차근 차근 <code>w의 미분값</code>을 계산해 나갈 수 있습니다. </li>
<li>$loss\text{ } function$ 공식에서 사용하는 operator 하나를, 하나의 gate라고 생각할 때, 각 gate마다 input으로 들어오게 되는 그 값이 최종 $loss$ 가 산출되는데 얼마만큼이나 기여를 하나. 하는 정도가 곧 우리가 미분을 하는 이유입니다. </li>
<li>그래서 결국은 그렇게 w가 $loss\text{ } function$에서 input으로 들어가게 될 때의 미분값을 구하면, 그 것은 즉, <code>w가 loss를 구하는데 얼마나 영향을 미치는가(= 기울기)</code>라는 의미가 됩니다. :D</li>
<li>Back Propagation은 가장 우측의 gate와 함께 loss로부터 시작합니다. </li>
</ul>
<hr>

<ul>
<li>By using <a href="https://en.wikipedia.org/wiki/Chain_rule" rel="external nofollow noopener noreferrer" target="_blank">Chain Rule</a>, we can calculate <code>the derivative value of w</code>, step by step. </li>
<li>Let us consider the each operator in the loss function is a gate, then, we are going to calculate how much this input of each gate contributes to the loss. That’s the reason why we do the derivative calculation.</li>
<li>So, at last, we can get the derivative of w as an input of a gate, it means <code>the amount of contribution of w to the final loss value</code>. :D</li>
<li>The back propagation starts from the loss with rightmost local gate. </li>
</ul>
<hr>

<h3 id="x-2-gate"><a href="#x-2-gate" class="headerlink" title="$x^2$ gate"></a>$x^2$ gate</h3><ul>
<li><p><code>$loss$인 1</code>은 <code>s인 -1을 제곱</code>해서 나온 값이니까요, $loss = s^2$ 으로 생각할 수 있습니다. loss를 <code>제곱 gate</code>로 미분한 다는 의미의  $\frac{\partial loss} {\partial s}$라는 식은 곧, $\frac{\partial s^2} {\partial s}$라는 식과 같다고 생각할 수 있습니다. </p>
<h3 id="frac-partial-loss-partial-s-frac-partial-s-2-partial-s"><a href="#frac-partial-loss-partial-s-frac-partial-s-2-partial-s" class="headerlink" title="$\frac{\partial loss} {\partial s}$ =  $\frac{\partial s^2} {\partial s}$"></a>$\frac{\partial loss} {\partial s}$ =  $\frac{\partial s^2} {\partial s}$</h3></li>
<li><p>$s^2$을 $s$로 미분한거죠! 그러면 $\frac{\partial s^2} {\partial s} = 2s$ 이기 때문에, 우리가 알고 있는 s = -1를 대입하면, $x^2$gate의 local gradient는 <code>-2</code>가 됩니다. </p>
</li>
</ul>
<center><img src="/gallery/backward.png" width="600"></center>

<ul>
<li><p>$loss$ is 1, and <code>s</code> is -1, so, the local derative of <code>square gate</code> is <code>-2</code>.</p>
<h3 id="frac-partial-loss-partial-s-frac-partial-s-2-partial-s-2s"><a href="#frac-partial-loss-partial-s-frac-partial-s-2-partial-s-2s" class="headerlink" title="$\frac{\partial loss} {\partial s}$ = $\frac{\partial s^2} {\partial s} = 2s$"></a>$\frac{\partial loss} {\partial s}$ = $\frac{\partial s^2} {\partial s} = 2s$</h3><p>  Again, <code>s</code> is -1. Therefore, <code>the local gradient of - gate</code> is -2.</p>
</li>
</ul>
<hr>

<h3 id="gate"><a href="#gate" class="headerlink" title="$-$ gate"></a>$-$ gate</h3><ul>
<li><p>$x^2$gate에서 -2가 <code>- gate</code>에 $loss$로 들어왔습니다. 그리고 그 - gate의 계산결과는 s인, -1 이었구요. 자, 이제 Chain Rule을 사용해서 <code>- gate</code>의 local gradient를 구해볼까요? </p>
</li>
<li><p>우리는, Chain Rule에 의해서, <code>- gate</code>의 local gradient를 아래와 같은 식으로 표현할 수 있습니다.</p>
<h3 id="frac-partial-loss-partial-hat-y-frac-partial-loss-partial-s-frac-partial-s-partial-hat-y-Rightarrow-2-cdot-frac-partial-hat-y-partial-y-partial-hat-y-2-cdot1-2"><a href="#frac-partial-loss-partial-hat-y-frac-partial-loss-partial-s-frac-partial-s-partial-hat-y-Rightarrow-2-cdot-frac-partial-hat-y-partial-y-partial-hat-y-2-cdot1-2" class="headerlink" title="$\frac{\partial loss} {\partial \hat y} = \frac{\partial loss}{\partial s}\frac {\partial s}{ \partial \hat y} \Rightarrow -2\cdot\frac {\partial \hat y - \partial y}{\partial \hat y} = -2\cdot1 = -2$"></a>$\frac{\partial loss} {\partial \hat y} = \frac{\partial loss}{\partial s}\frac {\partial s}{ \partial \hat y} \Rightarrow -2\cdot\frac {\partial \hat y - \partial y}{\partial \hat y} = -2\cdot1 = -2$</h3></li>
<li><p>$\frac{\partial loss}{\partial s}$은 -2라는 것을 $x^2$ gate에서 이미 알고 있기때문에, 나머지, s를, $\hat y$로 미분한 결과만 계산해서 곱하면 끝납니다. s는 $\hat y - y$ 라는 식의 결과나 마찬가지었으니, 치환해서 생각하면 편하구요. </p>
</li>
<li><p>그래서 결과는 <code>-gate</code>에서도 여전히 <code>local gradient는 -2</code>가 되군요!</p>
</li>
</ul>
<center><img src="/gallery/backward.png" width="600"></center>

<br>

<ul>
<li><code>-2</code> is passed to the <code>- gate</code> as loss. In the <code>- gate</code>, $y$ is a constant value and <strong>$\hat y$</strong> is 1, so the derivative is <code>-2</code>.</li>
<li>We already know that $\frac{\partial loss}{\partial s}$ = -2, so, the thing we need to do is to calculate the $\frac {\partial \hat y - \partial y}{\partial \hat y}$.<h3 id="frac-partial-loss-partial-hat-y-frac-partial-loss-partial-s-frac-partial-s-partial-hat-y-Rightarrow-2-cdot-frac-partial-hat-y-partial-y-partial-hat-y-2-cdot1-2-1"><a href="#frac-partial-loss-partial-hat-y-frac-partial-loss-partial-s-frac-partial-s-partial-hat-y-Rightarrow-2-cdot-frac-partial-hat-y-partial-y-partial-hat-y-2-cdot1-2-1" class="headerlink" title="$\frac{\partial loss} {\partial \hat y} = \frac{\partial loss}{\partial s}\frac {\partial s}{ \partial \hat y} \Rightarrow -2\cdot\frac {\partial \hat y - \partial y}{\partial \hat y} = -2\cdot1 = -2$"></a>$\frac{\partial loss} {\partial \hat y} = \frac{\partial loss}{\partial s}\frac {\partial s}{ \partial \hat y} \Rightarrow -2\cdot\frac {\partial \hat y - \partial y}{\partial \hat y} = -2\cdot1 = -2$</h3></li>
</ul>
<hr>

<h3 id="gate-1"><a href="#gate-1" class="headerlink" title="$*$  gate"></a>$*$  gate</h3><ul>
<li><p>자 이제 마지막으로, <code>w</code>가 input으로 들어간 <code>* gate</code>의 local gradient를 계산하고 w의 gradient를 계산하는 과정을 끝냅시다. </p>
</li>
<li><p>-gate에서 -2가 $loss$로 넘어왔고, 또 다시, 우리는 위와 같은 방법으로 Chain Rule을 쓰면, </p>
<h3 id="frac-partial-loss-partial-w-frac-partial-loss-partial-hat-y-frac-partial-hat-y-partial-w"><a href="#frac-partial-loss-partial-w-frac-partial-loss-partial-hat-y-frac-partial-hat-y-partial-w" class="headerlink" title="$\frac {\partial loss}{\partial w} = \frac{\partial loss}{\partial \hat y}\frac{\partial \hat y}{\partial w}$"></a>$\frac {\partial loss}{\partial w} = \frac{\partial loss}{\partial \hat y}\frac{\partial \hat y}{\partial w}$</h3><p>  로, 표현할 수 있고, 또 우린 이미 $\frac{\partial loss}{\partial \hat y}$ = -2 라는 것을 알고 있습니다. </p>
</li>
<li><p>그래서 여기서 $\hat y$를 의미하는 식인 $wx$를 $w$로 미분한 값만 알면되는데, 그 값은 $x$이므로 그냥 x였던, 1를 넣어주면, $loss$에 대한 <code>w의 미분값</code>이 <code>-2</code>라는 결과를 얻습니다. 이런 식으로 우리는 w의 미분값을 계산해 나가면서, $loss$가 최소가 되는 w를 찾습니다. </p>
</li>
</ul>
<center><img src="/gallery/backprop.png" width="700"></center>

<br>

<ul>
<li>Let’s finish this process with calculating the local gradient of the <code>* gate</code>.</li>
<li>As we know, -2 is given from the <code>- gate</code>, so, as the same way, using the Chain Rule again, we can write the equation like following.<h3 id="frac-partial-loss-partial-w-frac-partial-loss-partial-hat-y-frac-partial-hat-y-partial-w-1"><a href="#frac-partial-loss-partial-w-frac-partial-loss-partial-hat-y-frac-partial-hat-y-partial-w-1" class="headerlink" title="$\frac {\partial loss}{\partial w} = \frac{\partial loss}{\partial \hat y}\frac{\partial \hat y}{\partial w}$"></a>$\frac {\partial loss}{\partial w} = \frac{\partial loss}{\partial \hat y}\frac{\partial \hat y}{\partial w}$</h3></li>
<li>We already know the value of $\frac{\partial loss}{\partial \hat y}$ is -2, so, we just put the value of derivative of $wx$ with $w$, 1.</li>
<li>Then, at last, we can know the <code>derivative value of w</code> is <code>-2</code>. In this way, we can find the weight point where the loss becomes minimum.</li>
</ul>
<h3 id="Update-weight"><a href="#Update-weight" class="headerlink" title="Update weight"></a>Update weight</h3><ul>
<li>그렇게 계산이 끝난 W의 loss를 어떻게 update해줄까요? 아래 보시는 것처럼 단순히 $w = w - learning{:} rate * w.loss$ 로 Update를 하게 됩니다. 아래 예시에서는 learning rate로 0.01을 줬네요.</li>
<li>이것으로 Back Propagation에 대한 설명을 마치도록 하겠습니다. </li>
</ul>
<br>

<center><img src="/gallery/backprop_last.png" width="700"></center>

<br>

<ul>
<li>Then, how to update calculated weight’s loss? Simply we can calculate simply like this. $w = w - learning{:} rate * w.loss$ . In the example above, it used 0.01 as a learning rate.</li>
</ul>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>
        </div>
        
        
        <div id="bmc" align="center">
            <style>.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#000000 !important;background-color:#FFDD00 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing: 0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:'Cookie', cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#000000 !important;}</style><link href="https://fonts.googleapis.com/css?family=Cookie" rel="stylesheet"><a class="bmc-button" target="_blank" href="https://www.buymeacoffee.com/petercha" rel="external nofollow noopener noreferrer"><img src="https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg" alt="Buy me a coffee"><span style="margin-left:5px">Buy me a coffee</span></a>
        </div>
        
        
            <p><br></p>
            <div class="level is-size-7 is-uppercase">
                <div class="level-start">
                    <div class="level-item">
                        <span class="is-size-6 has-text-grey has-mr-7">#</span>
                        <a class="has-link-grey -link" href="/tags/Back-propagation/">Back propagation</a>, <a class="has-link-grey -link" href="/tags/Loss-function/">Loss function</a>, <a class="has-link-grey -link" href="/tags/Optimizer/">Optimizer</a>, <a class="has-link-grey -link" href="/tags/basic/">basic</a>, <a class="has-link-grey -link" href="/tags/deep-learning/">deep_learning</a>, <a class="has-link-grey -link" href="/tags/ml/">ml</a>, <a class="has-link-grey -link" href="/tags/tutorial/">tutorial</a>
                    </div>
                </div>
            </div>
            
        
        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- Natural -->
<ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4926107872672843" data-ad-slot="1904278923" data-ad-format="auto" data-full-width-responsive="true"></ins>
<script>
    (adsbygoogle = window.adsbygoogle || []).push({});
</script>
        <br>
        
<div class="sharethis-inline-share-buttons"></div>
<script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5d32dc3eba941200129ff9a8&amp;product=custom-share-buttons" async="async"></script>

        
        
    </div>
</div>







<div class="card card-transparent">
    <div class="level post-navigation is-flex-wrap is-mobile">
        
        <div class="level-start">
            <a class="level level-item has-link-grey  article-nav-prev" href="/2018/04/06/Basic-Deep-Learning-02/">
                <i class="level-item fas fa-chevron-left"></i>
                <span class="level-item">Basic Deep learning 02</span>
            </a>
        </div>
        
        
        <div class="level-end">
            <a class="level level-item has-link-grey  article-nav-next" href="/2018/01/06/Start/">
                <span class="level-item">How to create a Hexo Blog</span>
                <i class="level-item fas fa-chevron-right"></i>
            </a>
        </div>
        
    </div>
</div>



<div class="card">
    <div class="card-content">
        <h3 class="title is-5 has-text-weight-normal">Comments</h3>
        
<script>
    var disqus_config = function () {
        this.page.url = 'http://www.stand-firm-peter.me/2018/02/06/Basic-Deep learning-01/';
        this.page.identifier = '2018/02/06/Basic-Deep learning-01/';
    };
    (function() {
        var d = document, s = d.createElement('script');  
        s.src = '//' + 'petercha90' + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>

<div id="disqus_thread">
    
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
        <br>
        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- Natural -->
<ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4926107872672843" data-ad-slot="1904278923" data-ad-format="auto" data-full-width-responsive="true"></ins>
<script>
    (adsbygoogle = window.adsbygoogle || []).push({});
</script>
    </div>
</div>
</div>
                
                




<div class="column is-4-tablet is-4-desktop is-4-widescreen  has-order-3 column-right ">
    
        
<div class="card widget">
    <div class="card-content">
        <div class="menu">
            <h3 class="menu-label">
                Categories
            </h3>
            <ul class="menu-list">
            <li>
        <a class="level is-marginless" href="/categories/Deep-Learning-paper/">
            <span class="level-start">
                <span class="level-item">Deep Learning paper</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">1</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/Machine-Learning/">
            <span class="level-start">
                <span class="level-item">Machine Learning</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">8</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/Tutorial/">
            <span class="level-start">
                <span class="level-item">Tutorial</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">6</span>
            </span>
        </a></li>
            </ul>
        </div>
    </div>
</div>
    
        
<div class="card widget">
    <div class="card-content">
        <h3 class="menu-label">
            Recent
        </h3>
        
        <article class="media">
            
            <a href="/2019/08/11/mobilenet/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/gallery/mobile.jpg" alt="MobileNet V1">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2019-08-11T07:44:56.000Z">2019-08-11</time></div>
                    <a href="/2019/08/11/mobilenet/" class="has-link-black-ter is-size-6">MobileNet V1</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Deep-Learning-paper/">Deep Learning paper</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2019/06/12/keras_101/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/gallery/keras1.jpg" alt="Keras tutorial (1)">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2019-06-12T14:03:01.000Z">2019-06-12</time></div>
                    <a href="/2019/06/12/keras_101/" class="has-link-black-ter is-size-6">Keras tutorial (1)</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Machine-Learning/">Machine Learning</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2019/06/12/Colab_tutorial/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/gallery/colabimg3.jpg" alt="Colab tutorial :)">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2019-06-12T12:31:02.000Z">2019-06-12</time></div>
                    <a href="/2019/06/12/Colab_tutorial/" class="has-link-black-ter is-size-6">Colab tutorial :)</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Tutorial/">Tutorial</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2019/05/25/docker-103/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/gallery/docker1_5.jpg" alt="Docker tutorial (3)">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2019-05-25T06:26:56.000Z">2019-05-25</time></div>
                    <a href="/2019/05/25/docker-103/" class="has-link-black-ter is-size-6">Docker tutorial (3)</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Tutorial/">Tutorial</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2019/05/09/docker-102/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/gallery/dk1.jpg" alt="Docker tutorial (2)">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2019-05-09T06:26:56.000Z">2019-05-09</time></div>
                    <a href="/2019/05/09/docker-102/" class="has-link-black-ter is-size-6">Docker tutorial (2)</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Tutorial/">Tutorial</a>
                    </p>
                </div>
            </div>
        </article>
        
    </div>
</div>

    
        
<div class="card widget">
    <div class="card-content">
        <h3 class="menu-label">
            Tag Cloud
        </h3>
        <a href="/tags/Back-propagation/" style="font-size: 10px;">Back propagation</a> <a href="/tags/Batch/" style="font-size: 10px;">Batch</a> <a href="/tags/CNN/" style="font-size: 10px;">CNN</a> <a href="/tags/Colab/" style="font-size: 10px;">Colab</a> <a href="/tags/Docker/" style="font-size: 13.33px;">Docker</a> <a href="/tags/Epoch/" style="font-size: 10px;">Epoch</a> <a href="/tags/Filter/" style="font-size: 10px;">Filter</a> <a href="/tags/Kernel/" style="font-size: 10px;">Kernel</a> <a href="/tags/L1/" style="font-size: 10px;">L1</a> <a href="/tags/L2/" style="font-size: 10px;">L2</a> <a href="/tags/Lasso/" style="font-size: 10px;">Lasso</a> <a href="/tags/Loss-function/" style="font-size: 10px;">Loss function</a> <a href="/tags/Optimizer/" style="font-size: 10px;">Optimizer</a> <a href="/tags/Padding/" style="font-size: 10px;">Padding</a> <a href="/tags/Pooling/" style="font-size: 10px;">Pooling</a> <a href="/tags/Ridge/" style="font-size: 10px;">Ridge</a> <a href="/tags/basic/" style="font-size: 11.67px;">basic</a> <a href="/tags/blog/" style="font-size: 10px;">blog</a> <a href="/tags/container-ssh/" style="font-size: 10px;">container ssh</a> <a href="/tags/convex-optimisation/" style="font-size: 10px;">convex_optimisation</a> <a href="/tags/dataframe/" style="font-size: 10px;">dataframe</a> <a href="/tags/deep-learning/" style="font-size: 18.33px;">deep_learning</a> <a href="/tags/docker/" style="font-size: 13.33px;">docker</a> <a href="/tags/hexo/" style="font-size: 10px;">hexo</a> <a href="/tags/keras/" style="font-size: 10px;">keras</a> <a href="/tags/log/" style="font-size: 10px;">log</a> <a href="/tags/logarithm/" style="font-size: 10px;">logarithm</a> <a href="/tags/loss/" style="font-size: 10px;">loss</a> <a href="/tags/machine-learning/" style="font-size: 13.33px;">machine-learning</a> <a href="/tags/machine-learning/" style="font-size: 10px;">machine_learning</a> <a href="/tags/ml/" style="font-size: 20px;">ml</a> <a href="/tags/mobilenet/" style="font-size: 10px;">mobilenet</a> <a href="/tags/pandas/" style="font-size: 10px;">pandas</a> <a href="/tags/pseudo-label/" style="font-size: 10px;">pseudo-label</a> <a href="/tags/regularization/" style="font-size: 10px;">regularization</a> <a href="/tags/ssh/" style="font-size: 10px;">ssh</a> <a href="/tags/tensorflow/" style="font-size: 11.67px;">tensorflow</a> <a href="/tags/tensorpack/" style="font-size: 10px;">tensorpack</a> <a href="/tags/tutorial/" style="font-size: 16.67px;">tutorial</a> <a href="/tags/useful-info/" style="font-size: 15px;">useful-info</a>
    </div>
</div>

    
    
    <br>
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- Natural -->
<ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4926107872672843" data-ad-slot="1904278923" data-ad-format="auto" data-full-width-responsive="true"></ins>
<script>
    (adsbygoogle = window.adsbygoogle || []).push({});
</script>
    
</div>

            </div>
        </div>
    </section>
    <footer class="footer">
    <div class="container">
        <div class="level">
            <div class="level-start has-text-centered-mobile">
                <a class="footer-logo is-block has-mb-6" href="/">
                
                    <img src="/images/icon1.jpg" alt="Basic Deep learning 01" height="28">
                
                </a>
                <p class="is-size-7">
                &copy; 2019 Peter Cha&nbsp;
                Powered by <a href="https://hexo.io/" target="_blank" rel="external nofollow noopener noreferrer">Hexo</a> & <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="external nofollow noopener noreferrer">Icarus</a>
                
                </p>
            </div>
            <div class="level-end">
            
                <div class="field has-addons is-flex-center-mobile has-mt-5-mobile is-flex-wrap is-flex-middle">
                
                
                <p class="control">
                    <a class="button is-white is-large" target="_blank" title="Creative Commons" href="https://creativecommons.org/" rel="external nofollow noopener noreferrer">
                        
                        <i class="fab fa-creative-commons"></i>
                        
                    </a>
                </p>
                
                <p class="control">
                    <a class="button is-white is-large" target="_blank" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/" rel="external nofollow noopener noreferrer">
                        
                        <i class="fab fa-creative-commons-by"></i>
                        
                    </a>
                </p>
                
                <p class="control">
                    <a class="button is-white is-large" target="_blank" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus" rel="external nofollow noopener noreferrer">
                        
                        <i class="fab fa-github"></i>
                        
                    </a>
                </p>
                
                </div>
            
            </div>
        </div>
    </div>
</footer>
    <script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script>
<script>moment.locale("en");</script>


    
    
    
    <script src="/js/animation.js"></script>
    

    
    
    
    <script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script>
    <script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script>
    <script src="/js/gallery.js" defer></script>
    

    
    

<div id="outdated">
    <h6>Your browser is out-of-date!</h6>
    <p>Update your browser to view this website correctly. <a id="btnUpdateBrowser" href="http://outdatedbrowser.com/" rel="external nofollow noopener noreferrer" target="_blank">Update
            my browser now </a></p>
    <p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">&times;</a></p>
</div>
<script src="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.js" defer></script>
<script>
    document.addEventListener("DOMContentLoaded", function () {
        outdatedBrowser({
            bgColor: '#f25648',
            color: '#ffffff',
            lowerThan: 'flex'
        });
    });
</script>


    
    
<script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script>
<script>
document.addEventListener('DOMContentLoaded', function () {
    MathJax.Hub.Config({
        'HTML-CSS': {
            matchFontHeight: false
        },
        SVG: {
            matchFontHeight: false
        },
        CommonHTML: {
            matchFontHeight: false
        },
        tex2jax: {
            inlineMath: [
                ['$','$'],
                ['\\(','\\)']
            ]
        }
    });
});
</script>

    
    

<a id="back-to-top" title="Back to Top" href="javascript:;">
    <i class="fas fa-chevron-up"></i>
</a>
<script src="/js/back-to-top.js" defer></script>


    
    

    
    
    
    
    
    
    
    <script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script>
    <script src="/js/clipboard.js" defer></script>
    

    
    
    


<script src="/js/main.js" defer></script>

    
    <div class="searchbox ins-search">
    <div class="searchbox-container ins-search-container">
        <div class="searchbox-input-wrapper">
            <input type="text" class="searchbox-input ins-search-input" placeholder="Type something...">
            <span class="searchbox-close ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="searchbox-result-wrapper ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
    (function (window) {
        var INSIGHT_CONFIG = {
            TRANSLATION: {
                POSTS: 'Posts',
                PAGES: 'Pages',
                CATEGORIES: 'Categories',
                TAGS: 'Tags',
                UNTITLED: '(Untitled)',
            },
            CONTENT_URL: '/content.json',
        };
        window.INSIGHT_CONFIG = INSIGHT_CONFIG;
    })(window);
</script>
<script src="/js/insight.js" defer></script>
<link rel="stylesheet" href="/css/search.css">
<link rel="stylesheet" href="/css/insight.css">
    
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>