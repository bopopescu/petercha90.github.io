{"pages":[],"posts":[{"title":"Logarithms","text":"Deep Learning ë…¼ë¬¸ì—ì„œ ìì£¼ ë“±ì¥í•˜ëŠ” Log. Machine learning ë° í†µê³„ì—ì„œ ìì£¼ ì“°ëŠ” ì´ìœ ! Logë¥¼ ì™œ ì“°ëŠ” ê±¸ê¹Œ ë§ì€ ë”¥ëŸ¬ë‹ ë…¼ë¬¸ë“¤ì„ ì½ë‹¤ë³´ë©´, í•˜ë‚˜ê°™ì´ ìˆ˜ì‹ìœ¼ë¡œ ì„¤ëª…í•˜ê¸° ì‹œì‘í•˜ëŠ”ë°, ê·¸ ë•Œ ê¼­ ë‚˜ì˜¤ëŠ” ì¹œêµ¬ê°€ ì´ Logë‹¤. ì´ë¯¸ ì•„ì‹œëŠ” ë¶„ë“¤ì—ê² ì‹œì‹œí•œ ì´ì•¼ê¸°ì˜€ê² ì§€ë§Œ, ëŒ€ì¶© ì–´ë ´í’‹ì´ í•„ìì™€ ê°™ì´ â€˜ìˆ«ì í¬ê¸° ì‘ê²Œ í•´ì£¼ë ¤ê³  í•˜ëŠ” ê±°ê² ì§€..â€™ì •ë„ë¡œë§Œ ìƒê°í•˜ê³  ìˆì—ˆë‹¤ë©´(ë§ê¸´ ë§ë‹¤ë§Œâ€¦), ì •í™•í•œ ì˜ë¯¸ë¥¼ ì•Œì•„ë³´ì. ì•„ë˜ëŠ” ìƒìš©ë¡œê·¸ì¸ $\\text{log}x$ì™€, $\\text{ln}x$ë¡œ ë§ì´ ì“°ëŠ” ìì—°ìƒìˆ˜ $e$ë¥¼ ë°‘ìœ¼ë¡œ í•˜ëŠ” $\\text{log}_ex$ì˜ ê·¸ë˜í”„ë‹¤. ì´ ê·¸ë˜í”„ë¥¼ ë³´ë©´ì„œ í•  ìˆ˜ ìˆëŠ” ìƒê°ì€, â€˜$x$ê°’ì´ ì—„ì²­ë‚˜ê²Œ ì»¤ì§„ë‹¤ê³  í•´ë„, $y$ ì¦ê°€ìœ¨ì€ ê²©í•˜ê²Œ ë³€í•˜ì§€ ì•Šêµ¬ë‚˜.â€™ $\\to$ â€˜$x$ìˆ˜ì¹˜ê°€ ë‚®ì„ ë•ŒëŠ” ë¯¼ê°í•˜ê²Œ ë°˜ì‘í•˜ê³ , ë†’ì„ ë•ŒëŠ” ë‘”ê°í•˜êµ¬ë‚˜.â€™ $\\to$ â€˜ê·¸ëŸ¼ ìˆ˜ì¹˜ê°€ ëŒ€ë¶€ë¶„ ë‚®ì„ ë•ŒëŠ” ë¹„êµí•˜ê¸° ì¢‹ì„ ê±° ê°™ê³ , ì´ìƒì¹˜ì™€ ê°™ì€ ë¹„ì •ìƒì ì¸ ì˜ˆì™¸ ì¼€ì´ìŠ¤ë“¤ë„ ê°™ì´ ê³ ë ¤í•  ìˆ˜ ìˆê² ë‹¤.â€™ ì •ë„ê°€ ë  ê²ƒì´ë‹¤. ê·¸ëŸ¼ ì´ê±¸ í™œìš©í•˜ë©´ ì•„ë˜ì™€ ê°™ì€ ìƒí™©ì— ìœ ìš©í•˜ê²Œ ì“¸ ìˆ˜ ìˆë‹¤. $log$ëŠ” ì–´ë””ì— ì‚¬ìš©ë˜ë‚˜ìš” ëŒ€í‘œì ìœ¼ë¡œ ë‘ ê°€ì§€ì˜ ê²½ìš°ì— ë§ì´ ì‚¬ìš©ë˜ëŠ” ê²ƒ ê°™ë‹¤. ë°ì´í„°ë“¤ ê°„ì˜ ìˆ˜ì¹˜ì ì¸ ê°„ê·¹ì´ ë„ˆë¬´ ì»¤, ì£¼ì–´ì§„ ìˆ˜ì¹˜ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ë©´ íšŒê¸°ë¶„ì„ì‹œì— ê²°ê³¼ê°€ ì™œê³¡ë  ìˆ˜ë„ ìˆì–´ì„œ. ë¹„ì„ í˜•ì ì¸ ë°ì´í„°ì˜ ë¶„í¬ë¥¼ ì„ í˜•ì ìœ¼ë¡œ ì‰½ê²Œ ë³´ê¸° ìœ„í•´ì„œ 1. ì•„ë˜ì˜ ì‚¬ì§„ì€ ë™ë¬¼ë“¤ì˜ ì²´ì¤‘ë³„ ë‡Œì˜ í¬ê¸°ë¥¼ ë‚˜íƒ€ë‚¸ scatter plotì´ë‹¤. íŒŒì¶©ë¥˜ê°™ì€ ì‘ì€ ë™ë¬¼ë“¤ ë¶€í„°, ì½”ë¼ë¦¬, ê³ ë˜, ê³µë£¡ê¹Œì§€ ë‹¤ ë“¤ì–´ ìˆë‹¤ê³  ìƒê°í•´ë³´ë©´ ê·¸ ë¹„êµëŒ€ìƒë“¤ì´ ì„œë¡œ ê°€ì§€ëŠ” ìˆ˜ì¹˜ì ì¸ ì°¨ì´ëŠ” ì‹¤ì œë¡œ ì™¼ìª½ ê·¸ë¦¼ê³¼ ê°™ë‹¤. ì˜¤ë¥¸ìª½ì€ ê°™ì€ ë°ì´í„°ì— ìƒìš©ë¡œê·¸ë¥¼ ì·¨í•œ ê²ƒì´ê³  ì‹¤ì œë¡œ ê·¸ ê²½í–¥ì„±ì„ ë” íŒŒì•…í•˜ê¸° ì‰¬ìš´ í˜•íƒœê°€ ë˜ì—ˆë‹¤. ì•„ë˜ ì‚¬ì§„ë„ ê·¸ëŸ° ë°©ì‹ìœ¼ë¡œ $\\text{log}$ë¥¼ ì·¨í•´ì„œ íŒŒì¶©ë¥˜ë¶€í„° ê³ ë˜ì™€ ì½”ë¼ë¦¬, ê³µë£¡ê¹Œì§€ ë¹„êµí•œ plotì¸ë°, xì¶•ê³¼ yì¶•ì˜ ìˆ˜ì¹˜ë¥¼ ìì„¸íˆ ë³´ë©´ $\\text{log}$ë¥¼ ì·¨í•œ ê·¸ë˜í”„ì„ì„ ì•Œ ìˆ˜ ìˆë‹¤. 2. ì•„ë˜ëŠ” $y=2^x$ ê·¸ë˜í”„ì™€, ì´ ê·¸ë˜í”„ì— ìì—°ë¡œê·¸ë¥¼ ì·¨í•œ $\\text{ln}2^x$ì˜ ê·¸ë˜í”„ë‹¤. ë¹„ì„ í˜• ê·¸ë˜í”„ì¸ $y=2^x$ë¥¼ ì„ í˜•ìœ¼ë¡œ ë§Œë“¤ì–´ ì£¼ê³  ìˆë‹¤. ì´ì²˜ëŸ¼, ë¡œê·¸ëŠ” ë³µì¡í•œ ë¹„ì„ í˜•ì¸ ìˆ˜ì‹ë“¤ì„ ê°„ì†Œí™” ì‹œì¼œì£¼ëŠ” ì—­í• ì„ í•œë‹¤. ê³±ì…ˆê³¼ ë‚˜ëˆ—ì…ˆì´ logì—°ì‚°ì´ ë˜ë©´ì„œ +, -ë¡œ ë°”ë€Œê¸° ë•Œë¬¸ì— ì•„ë¬´ë˜ë„, Modelì—ì„œ computationì„ ë§ì´ í•´ì•¼í•˜ëŠ” ë¶€ë‹´ë„ ì¢€ë” ì¤„ì–´ ë“¤ì§€ ì•Šì„ê¹Œ?! ì´ëŸ° ì´ì  ë•Œë¬¸ì—ë„ ë§ì´ ì“°ëŠ” ê²ƒ ê°™ë‹¤. ì´ìƒ, $\\text{log}$ë¥¼ ì™œ ì“°ëŠ”ì§€ í•œ ë²ˆ ì•Œì•„ ë³´ì•˜ë‹¤. Reference blog1, blog2 Desmos(ê·¸ë˜í”„ ê·¸ë ¤ì£¼ëŠ” ì‚¬ì´íŠ¸) document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","link":"/2018/09/12/Logarithms/"},{"title":"Hi, Colab! :)","text":"Cloud Jupyter Notebook powered by Google Colab Introduction Colabì´ë€? ğŸ˜¶ Jupyter Notebookë¥¼ êµ¬ê¸€ ë“œë¼ì´ë¸Œì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ê²ƒì¸ë°, ì—¬íƒœ ìˆì—ˆë˜ êµ¬ê¸€ ë¬¸ì„œë‚˜ êµ¬ê¸€ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ì²˜ëŸ¼, ì‹¤ì‹œê°„ í˜‘ì—…ì´ ê°€ëŠ¥í•œ ë²„ì „ì´ë¼ê³  ìƒê°í•˜ë©´ ëœë‹¤ê³  í•©ë‹ˆë‹¤. ì›ë˜ êµ¬ê¸€ ë‚´ë¶€ì—ì„œ ì§ì›ë“¤ì´ ì‚¬ìš©í•˜ë˜ ê²ƒì´ë¼ê³  í•˜ë„¤ìš”! ê·¸ë˜ì„œ errorê°€ ìƒê¸°ë©´ STACK OVERFLOW ë²„íŠ¼ì´ ..:+1: ê·¸ë ‡ê¸° ë•Œë¬¸ì—, Jupyter Notebookë‚˜ ë‹¤ë¥¸ IDEì—ì„œ í”íˆ ì œê³µí•˜ëŠ” Variableë‹¤ìŒ .ì„ ì°ê³ , Tabí‚¤ë¥¼ ì¹˜ë©´ í•˜ìœ„ìš”ì†Œ(í•¨ìˆ˜ or ë³€ìˆ˜)ì˜ ì¼ë¶€ë§Œ ì³ë„ ë‚˜íƒ€ë‚˜ê²Œ í•˜ëŠ” ì¹œìˆ™í•œ ê¸°ëŠ¥ë“¤ë„, ì¡°ê¸ˆ ë°˜ì‘ì´ ëŠë¦¬ê¸´ í•˜ì§€ë§Œ, 0.5ì´ˆ ì •ë„ ë’¤ì— ë‚˜íƒ€ë‚©ë‹ˆë‹¤. :D GPU, TPU ì‚¬ìš© ì„¤ì •ì„ í•˜ì‹œë ¤ê±°ë“ , ë§¨ì²˜ìŒ Notebookì„ ìƒì„±í•˜ì‹¤ ë•Œ, ì„ íƒí•˜ì‹¤ ìˆ˜ë„ ìˆê³ , ìˆ˜ì • -> ë…¸íŠ¸ ì„¤ì •ì„ ëˆ„ë¥´ì‹œë©´ GPU, TPU ì‚¬ìš© ì„¤ì •ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ğŸ˜„ Linux ëª…ë ¹ì–´ ì‚¬ìš©í•˜ê¸° ğŸ˜² Colabì—ì„œëŠ” ëŠë‚Œí‘œë¡œ ì“´ ë’¤ì— ëª…ë ¹ì–´ë¥¼ ì¹˜ë©´ terminalì—ì„œ ì‘ë™í•˜ëŠ” ê²ƒìœ¼ë¡œ ì²˜ë¦¬í•´ì¤ë‹ˆë‹¤. ë¡œì»¬ì—ì„œ Bashì°½ì„ ì¼œì„œ ì„¤ì¹˜í•˜ê³  ë‹¤ì‹œ Jupyterë¡œ ëŒì•„ì™€ì•¼í–ˆë˜ ê·€ì°®ì€ ê³¼ì •ì´ ë§¤ìš° ì‹¬í”Œí•´ì¡ŒìŠµë‹ˆë‹¤! í•˜ì§€ë§Œ, 1$ cat sample.txt ê°™ì€ native Linuxì—ì„œë‚˜ ê°€ëŠ¥í•œ ëª‡ëª‡ ë¬¸ë²•ë“¤ì€ ì‘ë™í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ê·¸ë˜ì„œ, 100% Linux native ëª…ë ¹ì–´ë¥¼ ì“¸ ìˆ˜ ìˆëŠ” ê²ƒì€ ì•„ë‹ˆë©°, ì–´ë””ê¹Œì§€ë‚˜ ê·¸ë•Œ ê·¸ë•Œ, í•„ìš”í•œ library, package ì„¤ì¹˜ í¸ì˜ë¥¼ ìœ„í•œ ìˆ˜ì¤€ì´ë¼ê³  ë³¼ ìˆ˜ ìˆì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤. ë¦¬ëˆ…ìŠ¤ ëª…ë ¹ì–´ì—ì„œ ìµìˆ™í•œ ë¶„ë“¤ì€ ë‹¹ì—°íˆ ê²½ë¡œ ì´ë™ì„ í• ë•Œ cdë¥¼ ì“¸ í…ë°, !cdëŠ” ë¨¹íˆì§€ ì•Šê³ , osë¥¼ importí•˜ì‹  ë’¤ì—, os.chdir()ë¡œ ì´ë™í•´ì•¼ í•©ë‹ˆë‹¤. ë¹ˆ í´ë”ë¥¼ í•˜ë‚˜ ë§Œë“¤ê³  ê·¸ ì•ˆì— ì§§ì€ txtíŒŒì¼ì„ ë§Œë“¤ì–´ í™•ì¸í•´ ë´…ì‹œë‹¤. Cell. 1 123456import os!mkdir testos.chdir('test')!pwd# ëª…ë ¹ì–´ëŠ” ëª»ì°¾ëŠ”ë‹¤ê³  ë‚˜ì˜¤ì§€ë§Œ ìƒì„±ì€ í•©ë‹ˆë‹¤ :)!'Sample text!' > sample.txt Output: 123/content/test /bin/bash: Sample text!: command not found sample.txt #### Cell. 2 1234# ëª©ë¡ì—ëŠ” íŒŒì¼ì´ í™•ì¸ë˜ì§€ë§Œ, !ls# catì€ ì‘ë™í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. !cat sample.txt **Output:** 1sample.txtColab.ì—ì„œ ì“¸ ìˆ˜ ìˆëŠ” GPU ğŸ˜‰ ì¼ë‹¨ í•„ìš”í•œ Utilì„ ë‹¤ìš´ì„ ë°›ê³ , 1234!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi!pip install gputil!pip install psutil!pip install humanize Import í•´ì¤ì‹œë‹¤. 1234import psutilimport humanizeimport osimport GPUtil as GPU GPUëŠ” í•˜ë‚˜ë§Œ í—ˆë½í•´ ì¤ë‹ˆë‹¤ë§Œâ€¦ ê°“ê¸€ë‹˜ì˜ ê·¸ í•˜ë‚˜ëŠ” ì—ì´ìŠ¤ì…ë‹ˆë‹¤. 2019.06.12 í˜„ì¬. ë¬´ë ¤ T4. ğŸ˜­ ê°œì¸ ì‹¤í—˜ìš©ìœ¼ë¡œëŠ” ì¶©ë¶„í•œ ê²ƒ ê°™ìŠµë‹ˆë‹¤. 123456GPUs = GPU.getGPUs()gpu = GPUs[0]print(gpu.__dict__[\"name\"])print(\"The number of GPUs: {}\".format(len(GPUs)))print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil* 100, gpu.memoryTotal)) Output: 123Tesla T4The number of GPUs: 1GPU RAM Free: 15079MB | Used: 0MB | Util 0% | Total 15079MB ì°¸ê³ ì‚¬í•­ ì•ˆíƒ€ê¹ì§€ë§Œ, Colabì€ Dockerê¸°ë°˜ì˜ Containerë¡œ ì‹¤í–‰ë˜ê¸° ë•Œë¬¸ì— í•œ ë²ˆì— 12ì‹œê°„ê¹Œì§€ë§Œ ì‚¬ìš© í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ë˜ì„œ, ì‘ì—… í•˜ì‹œë˜ Colabì„ ê»ë‹¤ê°€ ì ì‹œ í›„ ë‹¤ì‹œ ì‹œì‘í•˜ë©´ ìƒˆë¡œìš´ docker containerë¥¼ ë°›ê¸° ë•Œë¬¸ì— ìƒˆë¡œìš´ ì¸ìŠ¤í„´ìŠ¤ ìœ„ì—ì„œ ì‹œì‘í•  ë•Œë§ˆë‹¤ ì„¤ì¹˜ê°€ í•„ìš”í•œ íŒ¨í‚¤ì§€ë“¤ì„ ë§¤ë²ˆ ë‹¤ì‹œ ì„¤ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤. ê·¸ ë‹¤ìŒ ë¶€í„°ëŠ” Jupyter notebookì„ ì‚¬ìš©í•˜ë“¯ ì‚¬ìš©í•˜ë©´ ë©ë‹ˆë‹¤. Local file Upload! ğŸ˜€ Localê°€ì§€ê³  ìˆëŠ” CIFAR10 png dataë¡œ í…ŒìŠ¤íŠ¸ í•´ë´¤ìŠµë‹ˆë‹¤. 12from google.colab import filescifar10 = files.upload() ë¡œì»¬ì—ì„œ filesë¥¼ í†µí•´ì„œ ê°€ì ¸ì˜¤ëŠ” ë°ì´í„°ë“¤ì€ ê¸°ë³¸ì ìœ¼ë¡œ dictionary í˜•íƒœë¡œ ë°›ì•„ì„œ ë³€ìˆ˜ì— ì €ì¥í•©ë‹ˆë‹¤. ì´ ì—…ë¡œë“œí•œ ë°ì´í„°ë“¤ë„ instanceê°€ ë°”ë€Œë©´(= ìƒˆë¡œ ì‹œì‘í•˜ë©´) ì—†ì–´ì§€ë‹ˆ, ì°¸ê³ í•˜ì„¸ìš”. cifar10 ì´ë¼ëŠ” ë³€ìˆ˜ì— ë“¤ì–´ì˜¨ local uploaded dataë¥¼ ì•„ë˜ì™€ ê°™ì´ í™•ì¸í•´ë³´ë©´ ê·€ì—¬ìš´ ê°œêµ¬ë¦¬ë¥¼ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ğŸ˜¶ 123456789import ioimport matplotlib.pyplot as pltfrom PIL import Imageitem = cifar10.get(list(cifar10.keys())[0])image = Image.open(io.BytesIO(item))plt.imshow(image) ì‚¬ì‹¤ ì´ë ‡ê²Œ ì´ë¯¸ì§€ë¥¼ ì˜¬ë¦¬ë©´, upload í•˜ê³ ì í•˜ëŠ” ë°ì´í„°ê°€ ë§ì„ ìˆ˜ë¡ ì†ë„ë„ ëŠë¦´ ë¿ë§Œ ì•„ë‹ˆë¼ ë¸Œë¼ìš°ì €ë¥¼ ë‹¤ì‹œ ì‹œì‘í•  ë•Œë§ˆë‹¤, ë˜ ì—…ë¡œë“œë¥¼ í•´ì•¼í•©ë‹ˆë‹¤. ë¡œì»¬ì— ë°ì´í„°ê°€ ë§ì„ ê²½ìš°ëŠ” ê°œì¸ Google Driveì— ì—…ë¡œë“œ í•œ ë‹¤ìŒ, ê·¸ directory ì•ˆì—ì„œ ì‘ì—…ì„ í•˜ë©´ ë˜ê² ì£ ? ê·¸ë ‡ë‹¤ë©´ ì‘ì—…í•˜ëŠ” ì½”ë“œê°€ ìˆëŠ” Google Drive ìì²´ë¥¼ Mount í•˜ëŠ” ë°©ë²•ì„ ì•Œì•„ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. :) Mount your Google Drive Google DriveëŠ” í•œ ë²ˆë§Œ Mountí•˜ë©´ ë©ë‹ˆë‹¤. ì•„ë˜ ì½”ë“œë¥¼ ì‹¤í–‰ì‹œí‚¤ì‹œë©´, ì„¤ì¹˜ë¥¼ í•˜ë‹¤ê°€ êµ¬ê¸€ ê³„ì • ì¸ì¦ì„ í•´ë‹¬ë¼ëŠ” ë§í¬ê°€ ë‚˜ì˜¤ëŠ”ë°, ê±°ê¸°ì„œ verification codeë¥¼ ì˜ ë³µì‚¬í•˜ì…”ì„œ ì¸ì¦í•˜ì‹œë©´ ë©ë‹ˆë‹¤. 123456789101112!apt-get install -y -qq software-properties-common python-software-properties module-init-tools!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null!apt-get update -qq 2>&1 > /dev/null!apt-get -y install -qq google-drive-ocamlfuse fusefrom google.colab import authauth.authenticate_user()from oauth2client.client import GoogleCredentialscreds = GoogleCredentials.get_application_default()import getpass!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URLvcode = getpass.getpass()!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} \"/home\"ìœ¼ë¡œ ê²½ë¡œë¥¼ ì´ë™í•œ ë’¤ì—, driveë¼ëŠ” í´ë”ë¥¼ ë§Œë“¤ì–´ì„œ ë³¸ì¸ ê³„ì •ì˜ êµ¬ê¸€ ë“œë¼ì´ë¸Œë¥¼ driveë¼ëŠ” í´ë”ì— Mountí•©ë‹ˆë‹¤. ì´ ê³¼ì •ì„ ê±°ì¹˜ë©´ ê°œì¸ Google Driveì— ìˆëŠ” íŒŒì¼ë“¤ì´ ì´ í´ë” ì•ˆì— ë“¤ì–´ê°€ê²Œ ë©ë‹ˆë‹¤. ì €ì˜ ê²½ìš°, Colab_Notebooksë¼ëŠ” ì´ë¦„ìœ¼ë¡œ í´ë”ê°€ ìƒì„±ë˜ì–´ ìˆê³ , ê·¸ í´ë” ì•ˆì— ì´ íŠœí† ë¦¬ì–¼ì´ ìˆìŠµë‹ˆë‹¤. 123456os.chdir(\"/home\")!mkdir drive!google-drive-ocamlfuse driveos.chdir(\"/home/drive/Colab_Notebooks\")!ls ì œê°€ ì˜®ê²¨ë†“ì€ trainí´ë” ì•ˆì— ì´ë¯¸ì§€ë“¤ì„ í™•ì¸í•´ ë´…ë‹ˆë‹¤. ğŸ˜¶ References Jaeyeon Baekë‹˜ì˜ ë¸”ë¡œê·¸, ìµœê±´í˜¸ë‹˜ì˜ Google Colaboratory ì‚¬ìš©ë²• DEEP LEARNING TURKEY document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","link":"/2019/06/12/Colab_tutorial/"},{"title":"How to create a Hexo Blog","text":"Simple Hexo Tutorialì…ë‹ˆë‹¤. HexoëŠ” Github pagesë¥¼ ì‚¬ìš©í•´ì„œ ë§Œë“œëŠ” ë¸”ë¡œê·¸ì…ë‹ˆë‹¤. ê·¸ëŸ¬ë‹ˆ, Github ê³„ì •ì„ ê°€ì§€ê³  ê³„ì…”ì•¼ ì‚¬ìš©í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. Github pagesëŠ” username.github.ioë¼ëŠ” ì´ìœ ê³ ìœ  ë„ë©”ì¸(ë¬´ë ¤ https)ë„ ì£¼ëŠ” ì•„ì£¼ ê³ ë§ˆìš´ ë¸”ë¡œê·¸ì…ë‹ˆë‹¤. ì§€ê¸ˆ ë³´ê³  ê³„ì‹  ì´ ë¸”ë¡œê·¸ë„, Hexoë¡œ ë§Œë“¤ì–´ì¡ŒìŠµë‹ˆë‹¤. ë„ë©”ì¸ë§Œ ì œê°€ ì‚¬ì„œ ë°”ê¿¨ì„ ë¿ì´êµ¬ìš”. ì´ ë¸”ë¡œê·¸ë¥¼ ì„¤ì¹˜í•˜ê³  ê´€ë¦¬í•˜ê³  ì‚¬ìš©í•˜ë ¤ë©´, HTML, Markdown, gitì— ëŒ€í•œ ê¸°ë³¸ì ì¸ ì´í•´ëŠ” ìˆì–´ì•¼ í•©ë‹ˆë‹¤. ì‚¬ì‹¤, ì–¸ê¸‰í•œ ê¸°ìˆ ë“¤ì„ ì˜ì€ ëª°ë¼ë„, ëŒ€ì¶© í•œ ë²ˆì”©ë§Œ í•´ë³´ì…¨ìœ¼ë©´, í•˜ì‹œë‹¤ë³´ë©´ ìµìˆ™í•´ì ¸ì„œ í• ë§Œ í•˜ì‹¤ ê²ƒë„ ê°™ìŠµë‹ˆë‹¤. :) 1. Make a repository at GithubGithubì— ê°€ì…”ì„œ ìƒˆë¡œ Repositoryë¥¼ ë§Œë“œì‹œëŠ”ë°, ê·¸ repositoryì˜ ì´ë¦„ì€ ê¼­, username.github.ioë¡œ í•˜ì…”ì•¼ í•©ë‹ˆë‹¤. ì•„ë˜ ë³´ì´ëŠ” ì‚¬ì§„ì²˜ëŸ¼ìš”. 2. Install Hexonode.js & gitHexoë¥¼ ì„¤ì¹˜í•˜ê³ , ì‚¬ìš©í•˜ë ¤ë©´ node.jsì™€ gitì´ ì„¤ì¹˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤. ì´ ë‘ê°€ì§€ íˆ´ì´ ì˜ ì„¤ì¹˜ê°€ ë˜ì–´ìˆë‹¤ë©´, ì•„ë˜ì™€ ê°™ì€ ëª…ë ¹ì–´ í•œ ì¤„ë¡œ ê°„ë‹¨í•˜ê²Œ Hexoë¥¼ ì„¤ì¹˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. $ npm install -g hexo-cli local directoryë³¸ì¸ì´ ì‚¬ìš© í•˜ê³ ì í•˜ëŠ” í´ë”ë¥¼ ë§Œë“œì‹œê³  ë“¤ì–´ê°€ì…”ì„œ, ëª…ë ¹ì–´ë¡œ $ hexo init $ npm install ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì…ë ¥í•©ë‹ˆë‹¤. ê·¸ë¦¬ê³  ë‚˜ì„œ ì„¤ì¹˜ê°€ ëë‚˜ë©´, Hexo blogë¥¼ ì‹œì‘í•  ìˆ˜ ìˆëŠ” íŒŒì¼ë“¤ì´ ì„¤ì¹˜ ëœ ê²ƒì„ í™•ì¸ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì €ëŠ” temp_blogë¼ëŠ” í´ë”ë¥¼ ë§Œë“¤ì–´ì„œ ì„¤ì¹˜í•´ ë³´ì•˜ìŠµë‹ˆë‹¤. 3. Start Hexo Blogë¯¿ê¸°ì§€ëŠ” ì•Šì§€ë§Œ, ì´ë ‡ê²Œ ìœ„ì˜ 3ê°œ ëª…ë ¹ì–´ë¡œ ë‹¹ì‹ ì˜ Hexo Blogê°€ ìƒê²¼ìŠµë‹ˆë‹¤. ìƒì„±ëœ Blogë¥¼ í™•ì¸í•´ ë³´ë„ë¡ í•©ì‹œë‹¤. $ hexo server localhost:4000ìœ¼ë¡œ ì ‘ì†ì„ í•˜ë¼ê³  í•˜ë‹ˆ, ì›¹ë¸Œë¼ìš°ì € ì°½ì„ í†µí•´ http://localhost:4000/ ì„ ì…ë ¥í•˜ê±°ë‚˜, ì£¼ì†Œë¥¼ í´ë¦­í•´ì„œ í™•ì¸í•´ ë´…ì‹œë‹¤. Ta da!! ë¸”ë¡œê·¸ê°€ ìƒê²¼ë‹¤ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤! :D ê°€ì¥ ê¸°ë³¸ í…Œë§ˆì¸ landscapeë¡œ ì„¤ì •ë˜ì–´ìˆê³ , ê¸€ì€ Hello World ë°–ì— ì—†ì§€ë§Œ, ì´ì œ ì—¬ëŸ¬ë¶„ì˜ ì·¨í–¥ëŒ€ë¡œ ë°”ê¿”ë‚˜ê°€ê¸°ë§Œ í•˜ë©´ ë©ë‹ˆë‹¤! ì, ê·¸ëŸ¼ ì°¨ê·¼ì°¨ê·¼íˆ ì–´ë–»ê²Œ ë¸”ë¡œê·¸ì˜ ì„¤ì •ì„ ë°”ê¿€ ìˆ˜ ìˆëŠ”ì§€, ê¸€ì€ ì–´ë–»ê²Œ ì“°ë©´ ë˜ëŠ”ì§€, ì‹¤ì œë¡œ ë‚˜ì—ê²Œ ë¶€ì—¬ëœ ë„ë©”ì¸ì— ë°°í¬ë¥¼ í•  ìˆ˜ ìˆëŠ”ì§€ ì•Œì•„ë´…ì‹œë‹¤. 4. Hexo _config.ymlìš°ë¦¬ê°€ ì„¤ì¹˜í•œ í´ë”ë¥¼ ë³´ë©´, _config.ymlíŒŒì¼ì„ í™•ì¸ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ëŒ€ëµì ì¸ ëª¨ìŠµì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤. ê°„ë‹¨í•˜ê²Œ, title, timezone, url, ê·¸ë¦¬ê³  deployë¶€ë¶„ë§Œ ë³¸ì¸ì—ê²Œ ë§ëŠ” ì •ë³´ë¡œ ê³ ì³ë³´ê¸°ë¡œ í•©ë‹ˆë‹¤. 1234567891011121314151617181920212223242526272829303132# Hexo Configuration## Docs: https://hexo.io/docs/configuration.html## Source: https://github.com/hexojs/hexo/# Sitetitle: Stand firm Petersubtitle:description:author: John Doelanguage: entimezone: Asia/Seoul# URL## If your site is put in a subdirectory, set url as 'http://yoursite.com/child' and root as '/child/'url: http://petercha90.github.ioroot: /permalink: :year/:month/:day/:title/permalink_defaults:...# Extensions## Plugins: https://hexo.io/plugins/## Themes: https://hexo.io/themes/theme: landscape# Deployment## Docs: https://hexo.io/docs/deployment.html## ë°°í¬ë°©ì‹ì€ gitìœ¼ë¡œ, typeì€ ë³¸ì¸ì˜ repository ì£¼ì†Œ!deploy: type: git repo: https://github.com/PeterCha90/petercha90.github.io.git Deploymentë¶€ë¶„ì—ì„œ deploy ë°©ì‹(git)ê³¼, ìš°ë¦¬ ë¸”ë¡œê·¸ì™€ ì‹¤ì œ ë¶€ì—¬ë°›ì€ ë„ë©”ì¸ê³¼ì˜ ì—°ê²°ì„ í•  ìˆ˜ ìˆê²Œ ì£¼ì†Œë¥¼ ì˜ ì ì–´ì¤˜ì•¼, ì´í›„ì— ë‚˜ì˜¤ëŠ” hexo deployëª…ë ¹ì–´ë¥¼ í†µí•´ ì‹¤ì œë¡œ ë¸”ë¡œê·¸ë¥¼ ë°°í¬í•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤.hexo serverë¡œ ì¼°ë˜ ë¡œì»¬ ì„œë²„ë¥¼ Ctrl + cë¡œ ì¢…ë£Œí•œ ë‹¤ìŒ, hexo serverë¡œ ì„œë²„ë¥¼ êµ¬ë™ì‹œí‚¨ ë’¤, localhost:4000ìœ¼ë¡œ ì ‘ì†í•´ì„œ í™•ì¸í•´ ë³´ë©´, titleì´ ì˜ ë°”ë€Œì–´ ìˆìŠµë‹ˆë‹¤ :D 5. Create a new postê·¸ëŸ¼, postingì€ ì–´ë–»ê²Œ í•˜ë©´ ë ê¹Œìš”?! ì´ì—­ì‹œ, ë§¤ìš° ì‰½ìŠµë‹ˆë‹¤. $ hexo new â€œsample_postingâ€ ì´ ëª…ë ¹ì–´ë¥¼ ì¹˜ë©´, ìë™ìœ¼ë¡œ /source/_posts/ ë°‘ì—, sample_posting.mdì´ë¼ëŠ” íŒŒì¼ì´ ë™‡.í•˜ê³  ìƒê²¼ë‹¤ëŠ” ë©”ì„¸ì§€ë¥¼ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ íŒŒì¼ì„ ì—´ì–´ë³´ì‹œë©´ ë­ê°€ ì íŒê²Œ ë³„ë¡œ ì—†ìŠµë‹ˆë‹¤. 12345---title: sample_postingdate: 2018-01-13 22:56:29tags:--- ê·¸ë˜ì„œ ì œê°€ ëª‡ ì ì ì–´ë³´ì•˜ìŠµë‹ˆë‹¤. 123456789101112---title: sample_postingdate: 2018-01-13 22:56:29tags:---Markdown > ëª‡ì ì ì–´ ë³´ì•˜ìŠµë‹ˆë‹¤. ## ë‘ ì ì ì–´ ë´¤ìŠµë‹ˆë‹¤. **ì„¸ ì ì…ë‹ˆë‹¤.** ê·¸ëŸ¼ ì´ sample_posting.mdíŒŒì¼ì„ ì €ì¥í•˜ì‹œê³ , ì•„ë˜ì˜ ëª…ë ¹ì–´ë¥¼ ìˆ˜í–‰í•´ ë´…ë‹ˆë‹¤. $ hexo generate ë­”ê°€ ë§ì´ ìƒì„±ëë‹¤ëŠ” ë©”ì„¸ì§€ê°€ ë‚˜ì™”ìŠµë‹ˆë‹¤. ê·¸ë¦¬ê³  ë‹¤ì‹œ hexo serverë¥¼ ì‚¬ìš©í•´ì„œ ì„œë²„ë¥¼ ì—¬ì‹œê³ , ë¡œì»¬ 4000ë²ˆ í¬íŠ¸ë¡œ ì ‘ì†í•´ì„œ í™•ì¸í•´ ì£¼ì„¸ìš” :D ì§œì”~ ì´ë ‡ê²Œ ìš°ë¦¬ì˜ ì²« ë²ˆì§¸ Postingì´ ì˜ ë“±ë¡ ëìŠµë‹ˆë‹¤! ğŸ‰ğŸ‰ ìœ„ì˜ ì œê°€ ì ì€ ë‚´ìš©ê³¼ ê²°ê³¼ë¥¼ ë³´ì‹œë©´ ì•Œ ìˆ˜ ìˆë“¯ì´, HexoëŠ” ê¸°ë³¸ì ìœ¼ë¡œ Markdown ì–¸ì–´ë¥¼ ì§€ì›í•©ë‹ˆë‹¤. 6. Deploy to remote sitesì, ê·¸ëŸ¼ ì´ë²ˆì—ëŠ” ë§ˆì§€ë§‰ìœ¼ë¡œ ì´ë ‡ê²Œ ì‘ì„±í•œ ë¸”ë¡œê·¸ì™€ í¬ìŠ¤íŒ…ì„ ìš°ë¦¬ì˜ ì‹¤ì œ ì›ê²© ì €ì¥ì†Œ(Github repository)ë¡œ ë°°í¬í•´ë³´ë„ë¡ í•©ë‹ˆë‹¤. ë¨¼ì €, ì•„ë˜ì™€ ê°™ì´ hexo-deployer-gitì„ ë¨¼ì € ì„¤ì¹˜í•´ì£¼ì‹œê³ , 1$ npm install --save hexo-deployer-git ì•„ë˜ì˜ ëª…ë ¹ì–´ë¥¼ ì…ë ¥í•˜ì‹œë©´, ë°°í¬ê°€ ëë‚¬ìŠµë‹ˆë‹¤!ğŸ˜† 1$ hexo deploy 2, 3ë¶„ ë’¤ì— username.github.ioë¡œ ì ‘ì†í•˜ì…”ì„œ í™•ì¸í•´ ë³´ì„¸ìš” :) 7. Summaryhexo server Blog contentsê°€ ì˜¬ë°”ë¥´ê²Œ ë³´ì´ëŠ”ì§€ í™•ì¸í•  ìˆ˜ ìˆëŠ” ë¡œì»¬ ì„œë²„ë¥¼ êµ¬ë™í•©ë‹ˆë‹¤. hexo new \"title\" ìƒˆë¡œìš´ â€œtitleâ€ì´ë¼ëŠ” ì´ë¦„ì˜ postingì„ ì‘ì„±í•©ë‹ˆë‹¤. hexo generate ìˆ˜ì •ëœ ì‚¬í•­ìœ¼ë¡œ deployí•  ìˆ˜ ìˆë„ë¡ contentsë¥¼ ìƒì„±í•©ë‹ˆë‹¤. hexo deploy ì›ê²© ì €ì¥ì†Œ(github repository)ì— ì‹¤ì œë¡œ ë°°í¬í•©ë‹ˆë‹¤. Tips : hexo generate = hexo g hexo deploy = hexo d hexo clean: ê²Œì‹œê¸€ì— htmlë¬¸ë²•ì´ renderingë˜ì§€ ì•Šê³  ê¹¨ì ¸ì„œ ë‚˜ì˜¬ ë•Œ, ê°€ë”ì”© ì‹¤í–‰Contents ìƒì„± í›„ ë°”ë¡œ ë°°í¬í•˜ê¸° hexo generate deploy = hexo g -d 8. Themesê¸°ë³¸ í…Œë§ˆë„ í›Œë¥­í•˜ì§€ë§Œ, ì¢€ ë” ë‹¤ë¥¸ ëŠë‚Œì˜ í…Œë§ˆë¥¼ ì›í•˜ì‹ ë‹¤ë©´, ì—¬ê¸°ë¡œ ë“¤ì–´ê°€ì…”ì„œ, í…Œë§ˆë¥¼ ê³ ë¥´ì‹œê³  ë³¸ì¸ì˜ _config.ymlíŒŒì¼ì„ ìˆ˜ì •í•˜ë©´ ë©ë‹ˆë‹¤!êµ¬ì²´ì ì¸ í…Œë§ˆ ì ìš© ë°©ì‹ì€ ë³´í†µ ì„ íƒí•œ í…Œë§ˆì—ì„œ ì„¤ëª…ì„ í•´ì£¼ê¸° ë•Œë¬¸ì—, ì„¸ë¶€ì„¤ì •ì´ ì œê°ê° ë‹¤ë¦…ë‹ˆë‹¤. _config.yml íŒŒì¼ì—ì„œ, themeì´ë¼ëŠ” key ê°’ì„ ë³¸ì¸ì´ ì„ íƒí•œ í…Œë§ˆì˜ ì´ë¦„ìœ¼ë¡œ ë°”ê¾¼ë‹¤ëŠ” ì ì€ ê³µí†µì´ê² ì§€ë§Œìš” :D ì§€ê¸ˆ ì´ íŠœí† ë¦¬ì–¼ì„ ê·¸ëŒ€ë¡œ ë”°ë¼í•˜ì…¨ë‹¤ë©´ ì§€ê¸ˆ ì—¬ëŸ¬ë¶„ë“¤ì˜ ìƒíƒœëŠ” ì•„ë˜ì™€ ê°™ì„ ê²ë‹ˆë‹¤. theme: landscape document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","link":"/2018/01/06/Start/"},{"title":"tf.identity()","text":"Tensorflowì—ì„œ ìì£¼ ë“±ì¥í•˜ëŠ” tf.identity()ì— ëŒ€í•´ ì•Œì•„ë´…ë‹ˆë‹¤. tf.control_dependencies()ì™€ í•¨ê»˜ ëª¨ë¸ì„ êµ¬í˜„í•˜ë‹¤ë³´ë©´ ê±°ì˜ ì œì¼ ë§ˆì§€ë§‰ì¸ fully connectedì¸ Linearì— ì´ë¥´ëŸ¬ ë§¨ ë§ˆì§€ë§‰ logitsì„ ë½‘ì•„ë‚´ê¸° ì „ì— ê¼­ í•œ ë²ˆì¯¤ì€ ë³´ê²Œ ë˜ëŠ” ì¹œêµ¬ê°€ ì´ tf.identity(). ìŠµê´€ì ìœ¼ë¡œ ê·¸ëƒ¥ ì“°ëŠ”ê±´ê°€ë³´ë‹¤ í•˜ë‹¤ê°€ ë¬¸ë“ ë” ê¹Šì´ ì´í•´í•˜ê³  ë„˜ì–´ê°€ì•¼í•˜ê² ë‹¤ ì‹¶ì–´ì„œ ì´ë ‡ê²Œ í¬ìŠ¤íŒ…ìœ¼ë¡œ ë‚¨ê¸´ë‹¤. tf.identity()ë¥¼ ì´í•´í•˜ê¸° ìœ„í•´ì„œëŠ” tf.control_dependencies()ë¥¼ ë¨¼ì € ì´í•´í•´ì•¼ í•œë‹¤. Tensorflowì˜ ê³µì‹ë¬¸ì„œì— ë”°ë¥´ë©´ ê·¸ ì„¤ëª…ì´ ì•„ë˜ì™€ ê°™ë‹¤. tf.control_dependencies() tf.control_dependencies(control_inputs) control_inputs: A list of Operation or Tensor objects which must be executed or computed before running the operations defined in the context. Can also be None to clear the control dependencies. If eager execution is enabled, any callable object in the control_inputs list will be called. Context ì•ˆì—ì„œ ì •ì˜ëœ Operationì´ Runningë˜ê¸° â€œì „â€œì— â€œë¨¼ì €â€œ ì‹¤í–‰ì‹œì¼œì¤„ ì¹œêµ¬ë“¤ì„ control inputsìœ¼ë¡œ ë„£ì–´ì£¼ë©´ ë¨¼ì € ì‹¤í–‰í•´ì¤€ë‹¤ëŠ” ì˜ë¯¸ë‹¤. ê·¸ëŸ¼ ì´ì œ tf.identity()ë¥¼ ì‚´í´ë³´ì. tf.identity() tf.identity(input, name=None) Return a tensor with the same shape and contents as input. input: A Tensor. name: A name for the operation (optional). ê·¸ëƒ¥ ì…ë ¥ëœ Tensorë‘ ë˜‘ê°™ì€ Shape, ë˜‘ê°™ì€ contentsë¥¼ ëŒë ¤ì¤€ë‹¤. ê·¸ëŸ¼ ì™œ ì“°ëŠ” ê±°ì§€?? 1234567891011x = tf.Variable(0.0)x_plus_1 = tf.assign_add(x, 1)with tf.control_dependencies([x_plus_1]): y = tf.identity(x)init = tf.initialize_all_variables()with tf.Session() as session: init.run() for i in range(5): print(y.eval()) ì—¬ê¸°ì—ì„œ ê°€ì ¸ì˜¨ ì˜ˆì‹œë¥¼ ë³´ë©´, ì´ìœ ë¥¼ ì¢€ ì•Œ ìˆ˜ ìˆëŠ”ë°, ë§Œì•½ì— y = tf.identity(x) ë¶€ë¶„ì´ ê·¸ëƒ¥ y = xë¼ë©´ ì•„ë¬´ ì¼ë„ ì¼ì–´ë‚˜ì§€ ì•ŠìŒì„ ì•Œ ìˆ˜ ìˆë‹¤. printì˜ ê²°ê³¼ê°€ ì£„ë‹¤. 0 0 0 0 0 ì´ë‹¤. ì™œëƒí•˜ë©´, tf.control_dependencies()ëŠ” â€œOperationâ€ì´ ì‹¤í–‰ë˜ê¸° ì „ì— inputsìœ¼ë¡œ ë“¤ì–´ì˜¨ ë¶€ë¶„ì„ ì²˜ë¦¬í•´ì¤€ë‹¤ê³  í–ˆëŠ”ë°, y = xëŠ” ì•„ë¬´ëŸ° operationì´ ì—†ê¸° ë•Œë¬¸ì— x_plus_1ë¥¼ ì‹¤í–‰í•˜ì§€ ì•ŠëŠ”ë‹¤. ê²°ë¡  Tensorflowë¡œ ëª¨ë¸ì„ ë§Œë“¤ ë•Œ, ì£¼ë¡œ ë§¨ ë§ˆì§€ë§‰ì— Fully connected Layerì—ì„œ Outputì— í•´ë‹¹í•˜ëŠ” Logitsì„ ë½‘ì„ ë•Œ ì´ tf.identity()ë¥¼ ë§ì´ ì“°ëŠ” ì´ìœ ëŠ” tf.control_dependencies()ë¥¼ ì‹¤í–‰ì‹œì¼œì£¼ê¸° ìœ„í•œ ê±´ë•ì§€(?)ë¥¼ ë§Œë“¤ê¸° ìœ„í•´ì„œë‹¤. document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","link":"/2018/09/07/tf-identity/"},{"title":"Pandas Cheat Sheet","text":"Pandasì˜ Dataframe ê´€ë ¨ ê¸°ëŠ¥ì •ë¦¬. Cheat Sheet for Pandas Dataframe. 0. Start Import pandas1import pandas as pd 1. Creating a dataframe Dictionary Style:12345df = pd.DataFrame( {\"a\" : [4, 5, 6], \"b\" : [7, 8, 9], \"c\" : [10, 11, 12]}, index = [1, 2, 3]) Array Style:123456df = pd.DataFrame( [[4, 7, 10], [5, 8, 11], [6, 9, 12]], index=[1, 2, 3], columns=['a', 'b', 'c']) 2. Select an row or column There are 5 ways to access the value that is at index 0, in column â€˜aâ€™.loc selects the value by label, not index.iloc accesses to the value using row and column index. 12df.loc[0]['a']df.iloc[0][0] at selects the value by label, not index.iat accesses to the value using row and column index. 12df.at[0, 'a']df.iat[0,0] ix can use both label and index. 1df.ix[0, 'a'] The difference between loc and at is the return type. loc can return more than one row, it means loc can return a scalar, a Serise or a Dataframe. On the other hand, at only can access to a cell of certain position, it means it returns a scalar only. Actually it returns a scalar faster than loc, so if you have to deal with great amount of data, it would be more suitable. 123456789101112df.at[2, 'b'] # A scalar.df.iat[2, 2]df.loc[2]['b']df.iloc[2][2]df.ix[2, 'b'] df.loc[2][:'b'] # A Series.df.iloc[2][:2]df.ix[2, :'b'] df.iloc[:2][:2] # A dataframe.df.ix[:2, :'b'] If you want to retrieve the value(s) from a series, 12sr = df.bsr.values() Select multiple rows or columns 1234567# rowsdf.iloc[[0, 2]] df.loc[[1, 3]] # row names # columnsdf.iloc[:, [0, 2]]df[[\"a\", \"c\"]] # column names 3. Selecting rows with conditions Condition in the brackets.1234df[df.a > 4]df[(df.a > 4) & (df.b < 9)]# You have to wrap all conditions with parentheses.df[((df.a > 4) | (df.b < 9)) & (df.c > 10)] Condition using query.123df.query('a > 4')df.query('a > 4 and b < 9')df.query('(a > 4 or b < 9) and c > 10') 4. Adding rows or columns Adding new rows12df.loc[3] = 0 # fill with 0df.loc[3] = [5, 7, 1] # Add a row Creating a new column12345df[\"d\"] = 0 # fill with 0 df[\"d\"] = df.a # copy column 'a'df[\"d\"] = pd.Series([13, 14, 15], index = df.index) # fill with new valuesdf.loc[ : , \"d\"] = pd.Series([13, 14, 15], index = df.index) 5. Delete Indices, Rows or Columns Delete rows1234567df.drop([0, 2], axis=0) # Delete the rows with labels 0, 2df.set_index(\"a\", inplace=True) # Delete all rows with label 4df.drop(4, axis=0, inplace=True)df.reset_index(inplace=True)df = df.iloc[2:, ] # Delete the first two rows using iloc selector Delete columns.12df.drop(\"a\", axis=1, inplace=True) # Delete a columndf.drop([\"a\", \"c\"], axis=1, inplace=True) # Delete multiple columns 6. Combine Dataframes pd.concat()1234567891011121314151617df2 = pd.DataFrame( # Make two more dataframes {\"a\" : [1, 4, 7], \"b\" : [2, 5, 8], \"c\" : [3, 6, 9]}, index = [1, 2, 3])df3 = pd.DataFrame( {\"d\" : [1, 7], \"e\" : [2, 8]}, index = [1, 3])# concat rows df4 = pd.concat([df, df2]) # indices can be duplicateddf4.reset_index(drop=True, inplace=True) # Reset index# concat columnsdf5 = pd.concat([df, df3], axis=1) pd.merge()12345678910df6 = pd.DataFrame( # Make another dataframes {\"a\" : [4, 5, 7], \"f\" : [20, 50, 80], \"g\" : [30, 60, 90]}, index = [1, 2, 3])df7 = pd.merge(df, df6) # Inner join df8 = pd.merge(df, df6, how='outer') # Outer joindf9 = pd.merge(df, df6, how='left') # left joindf10 = pd.merge(df, df6, how='right') # right join 7. Iterate over a dataframe iterrows()12for index, row in df.iterrows() : print(row['a'], row['b'], row['c']) 8. Reading and Writing a dataframe Reading a csv file:1234pd.read_csv('name.csv')# if the file has a date column,pd.read_csv(\"name.csv\", parse_dates=[\"column_name\"])# Then, pandas transform it as a numpy.datetime64 column. Writing as a csv file:123df.to_csv(\"name.csv\", index=False)# optionsdf.to_csv(\"name.csv\", sep='\\t', encoding='utf-8') Writing as an Excel file:123writer = pd.ExcelWriter('name.xlsx')df.to_excel(writer, 'DataFrame')writer.save() 9. Other Useful functions Following commands are used often. 123456789101112df.head(n) # Select first n rows df.tail(n) # Select last n rowsdf.nlargest(n, 'a') # Select and order top n entries.df.nsmallest(n, 'c') # Select and order bottom n entriesdf.sample(frac=0.5) # Randomly select fraction of rows.df.sample(n=2) # Randomly select n rowsdf.isna() # Check whether each element has NA or not df.dropna() # Drop rows with any column having NA/null datadf.fillna(value) # Replace all NA/null data with valuedf.rename(columns={\"a\": \"k\"}, inplace=True) # Renaming \"a\" column as \"k\"df.describe() # To see basic statisticsdf.reset_index(drop=True, inplace=True) # Reset index References DataCamp pandas.pydata.org Shane Lynn Data Science School document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","link":"/2019/02/16/pandas-101/"},{"title":"Basic Deep learning 02","text":"Deep Learning ê°œë… ë° ìš©ì–´ë“¤ì„ ì•Œì•„ë´…ë‹ˆë‹¤. Batch, Epoch, CNN Peter Cha Deep Learningì„ ì´í•´í•˜ê³ , ì§ì ‘ Deep Learningì„ êµ¬í˜„í•˜ê³ ì í–ˆì„ ë•Œ í•„ìš”í•œ ê¸°ë³¸ ê°œë…ë“¤ì„ ì •ë¦¬í•´ ë³´ì•˜ìŠµë‹ˆë‹¤. ì´ë²ˆ í¬ìŠ¤íŒ…ì—ì„œëŠ” Epoch, Batchë¼ëŠ” ë‹¨ì–´ë“¤ì˜ ì˜ë¯¸ì™€, ê¸°ë³¸ì ì¸ CNN - Convolutional Neural Networkì— ëŒ€í•œ í‚¤ì›Œë“œë“¤ì„ ë‹¤ë£¹ë‹ˆë‹¤. ìœ ëª…í•œ MNIST ë°ì´í„°ë¥¼ í•™ìŠµí•˜ëŠ” ëª¨ë¸ì„ ë§Œë“¤ê³  ì‹¶ë‹¤ê³  í–ˆì„ ë•Œ, ì–¸ê¸‰í•œ í‚¤ì›Œë“œë“¤ì´ ì–´ë–¤ ì˜ë¯¸ë¡œ ì‚¬ìš©ë˜ëŠ”ì§€ ì˜ˆì‹œë¡œ í•¨ê»˜ ë³´ë ¤í•©ë‹ˆë‹¤. In this post, you will learn the Concepts needed when you need to understand the process of training AI or implement the AI by yourself. We are going to talk about Epoch, Batch, and basic CNN knowledges.Supposed we want to make a model which classifies MNIST data, letâ€™s check how the keywords above can be used. MNIST MNIST dataëŠ” ì•„ë˜ì—ì„œ ë³´ì‹œëŠ” ê²ƒì²˜ëŸ¼ 0 ~ 9ê¹Œì§€ì˜ ìˆ«ìê°€ ì í˜€ ìˆëŠ”, ì†ê¸€ì”¨ dataì…ë‹ˆë‹¤. ë”°ë¼ì„œ ì´ 10ê°€ì§€ì˜ classê°€ ìˆìŠµë‹ˆë‹¤. ì´ ë°ì´í„°ë¥¼ ì´ìš©í•´ì„œ ìš°ë¦¬ê°€ í•™ìŠµì‹œí‚¤ê³  ì‹¶ì€ ëª¨ë¸ì€ ë”°ë¼ì„œ ìƒˆë¡œìš´ ì†ê¸€ì”¨ dataë¥¼ ë³´ë”ë¼ë„ 0 ~ 9ì¤‘ì— ì–´ë–¤ ìˆ«ìì¸ì§€ ì˜ ë§ì¶”ëŠ” AIê°€ ë  ê²ƒì…ë‹ˆë‹¤. Images from tensorflow.gitbooks.io. As you can see above, MNIST is a dataset of handwritten digits, 0 to 9. Therefore, MNIST dataset has 10 classes to distinguish. Using this data, Our model to be trained will be able to distinguish 0 ~ 9 handwritten digits. Epoch, Batch MNISTëŠ” Training dataë¡œ ì´ 6ë§Œ ì¥ì˜ ìˆ˜ê¸°ë¡œ ëœ ìˆ«ìë¥¼ ì œê³µí•˜ê³ , Testìš©ìœ¼ë¡œ 1ë§Œ ì¥ì„ ì œê³µí•˜ëŠ” Datasetì…ë‹ˆë‹¤. ì, ê·¸ëŸ¼ ìš°ë¦¬ëŠ” 6ë§Œì¥ì„ í•œêº¼ë²ˆì— ëª¨ë¸ì—ê²Œ ì£¼ê³  í•™ìŠµí•´!ë¼ê³  í•˜ë©´ ë ê¹Œìš”? í•  ìˆ˜ëŠ” ìˆë”ë¼ë„ ê½¤ ì—¬ìœ ë¡œìš´ ë©”ëª¨ë¦¬ë¥¼ ê°€ì§„ local machineì´ ì•„ë‹ˆê³ ì„œëŠ” ì¢€ í˜ë“¤ê² ì£ ? MNISTê°€ ì•„ë‹Œ ë” í° ìš©ëŸ‰ì˜ ë°ì´í„°ì¼ ìˆ˜ë¡ ë” ê·¸ëŸ´ ê²ƒì…ë‹ˆë‹¤. ê·¸ë˜ì„œ, ìš°ë¦¬ëŠ” ì´ ë°ì´í„°ë“¤ì„ íŠ¹ì •í•œ ì–‘ìœ¼ë¡œ ë‚˜ëˆ ì„œ ì¡°ê¸ˆì”© í•™ìŠµì„ í•  ìˆ˜ ìˆê²Œ ë„£ì–´ì£¼ëŠ”ë°ìš”, ê·¸ ì‘ì€ ë‹¨ìœ„ë¥¼ Batchë¼ê³  ë¶€ë¥´ê³ , ê·¸ Batchì˜ í¬ê¸°ê°€ ì–´ë– í•œì§€ë¥¼ ì¼ì»«ëŠ” ë§ë¡œ, Batch sizeë¼ê³  ë§í•©ë‹ˆë‹¤. ìš°ë¦¬ê°€ Batch sizeë¥¼ 100ìœ¼ë¡œ ì •í–ˆë‹¤ê³  í•˜ë©´, ì´ ëª‡ ë²ˆì˜ ë°˜ë³µì„ í•´ì•¼ ì´ 60000ì¥ì˜ Training dataë¥¼ ë‹¤ í•œ ë²ˆì”© ëª¨ë¸ì´ í•™ìŠµí•  ìˆ˜ ìˆê²Œ ë ê¹Œìš”? 600ë²ˆ ì¼ ê²ƒì…ë‹ˆë‹¤. ê·¸ëŸ¼ ì‹¤ì œë¡œ, ìš°ë¦¬ ëª¨ë¸ì€ 100ì¥ì˜ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ì„œ í•œ ë²ˆ ëŒê³ (í•™ìŠµí•˜ê³ ), ì•ì—ì„œ ë°°ìš´ Back propagationì„ í†µí•´, Weightë¥¼ Updateí•˜ê²Œ ë˜ë©´, ê·¸ ë‹¤ìŒ 100ì¥ì„ ê°€ì ¸ì™€ì„œ ë˜ í•™ìŠµì„ ë˜‘ê°™ì´ ë°˜ë³µí•˜ëŠ” ì´ í–‰ìœ„ë¥¼ ì´ 600ë²ˆì„ í•˜ê²Œ ë©ë‹ˆë‹¤. ê·¸ë ‡ê²Œ 600ë²ˆì„ ë‹¤ ëŒì•˜ì„ ë•Œ, ìš°ë¦¬ëŠ” '1 epochì„ ëŒì•˜ë‹¤'ë¼ê³  ë§í•©ë‹ˆë‹¤. ì°¸ê³ ë¡œ, ì´ 600ë²ˆì„ Step sizeë¼ê³  ì¼ì»«ìŠµë‹ˆë‹¤. CNN CNNì€ Convolution Neural Networkì˜ ì•½ì–´ë¡œ, Convolution ê³„ì‚°ì´ ì–´ë–»ê²Œ Neural Network 2D ì´ë¯¸ì§€ ê³„ì‚°ê³¼ ê´€ë ¨ì´ ìˆëŠ”ì§€ëŠ” ì—¬ê¸°ë¥¼ ì°¸ê³ í•´ì£¼ì„¸ìš”. ì´ ê¸€ì—ì„œëŠ”, CNNì—ì„œ ìì£¼ ì–¸ê¸‰ë˜ëŠ”, Filter, Kernel, Stride, Pooling, ê·¸ë¦¬ê³  Paddingì— ëŒ€í•´ì„œ ì•Œì•„ë´…ë‹ˆë‹¤. Feature(= Channel or Activation map) ì ì‹œ MNISTëŒ€ì‹ ì— ê³ ì–‘ì´ê°€ ì–´ë–»ê²Œ ìƒê²¼ëŠ”ì§€ë¥¼ í•™ìŠµí•˜ëŠ” Modelì„ ë§Œë“¤ê³  ìˆë‹¤ê³  ìƒê°í•´ ë´…ì‹œë‹¤. ê·¸ëŸ¬ë©´ RGB colorë¡œ ëœ ì‚¬ì§„ì„ ë„£ì–´ì£¼ê²Œ ë˜ê³ , ìš°ë¦¬ëŠ” ëª¨ë¸ì—ê²Œ ì´ ê³ ì–‘ì´ì— ëŒ€í•œ íŠ¹ì§•(Feature)ì„ ì¶”ì¶œí•´ì„œ í•™ìŠµì„ í•˜ë¼ê³  í•  ê²ƒì…ë‹ˆë‹¤. Images from ireneli.eu. ì, ê·¸ëŸ¬ë©´ ìš°ë¦¬ ëª¨ë¸ì´ ë§¨ ì²˜ìŒ ë³´ê²Œë  ì´ë¯¸ì§€ëŠ” Width, Height, ê·¸ë¦¬ê³  Red, Green, Blue 3ê°€ì§€ë¡œ ì´ë£¨ì–´ì§„ ì´ë¯¸ì§€ë¥¼ ë°›ê²Œ ë˜ëŠ” ê²ƒì´ì£ . ì´ ë•Œ, ìš°ë¦¬ëŠ” Channelì´ë¼ê³  ë¶€ë¥´ëŠ” ë¶€ë¶„ìœ¼ë¡œ ì´ RGBì¸ Depthë¥¼ ì§€ì¹­í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë©´ ì›ë³¸ ì´ë¯¸ì§€ëŠ” 'channelì˜ sizeê°€ 3ì´ë‹¤'ë¼ê³  ë§ í•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤. ìš°ë¦¬ MNIST ì´ë¯¸ì§€ëŠ” ê°€ë¡œ 28 pixel, ì„¸ë¡œ 28 pixel ì§œë¦¬, í‘ë°± ì´ë¯¸ì§€ì…ë‹ˆë‹¤!(ì´ë¯¸ì§€ì—ëŠ” 32ë¼ê³  ì í˜€ìˆì§€ë§Œ..) ê·¸ë˜ì„œ MNIST ì´ë¯¸ì§€ì˜ channelì˜ SizeëŠ” 1ì…ë‹ˆë‹¤. Images from parse.ele.tue.nl. ì´ë²ˆì—ëŠ” ì™œ ì´ Channelì˜ ë˜ë‹¤ë¥¸ ì´ë¦„ì´ Feature, Feature mapsì¸ì§€ ì•Œì•„ë´…ì‹œë‹¤. ìš°ë¦¬ MNIST ë°ì´í„°ê°€ ìœ„ì˜ ê·¸ë¦¼ê³¼ ê°™ì´ ë“¤ì–´ê°„ë‹¤ê³  í–ˆì„ ë•Œ, $C_1$ì„ ë³´ì‹œë©´ 5x5 í¬ê¸°ì˜ Convë¥¼ í†µê³¼í•œ ë’¤, ì´ë¯¸ì§€ê°€ 4ê²¹(?)ì´ ëìŠµë‹ˆë‹¤. ì´ ë•Œ ìš°ë¦¬ëŠ” Feature mapì˜ sizeê°€ 4ê°€ ëë‹¤ê³  ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ë¦¬ê³  $C_2$ë¥¼ ë³´ì‹œë©´ feature mapì´ 12ê°œê°€ ëì£ . ì´ëŸ° í–‰ìœ„ë¥¼ í•´ì„ì„ í•˜ìë©´, ë“¤ì–´ì˜¨ ì´ë¯¸ì§€ì— ëŒ€í•´ì„œ íŠ¹ì§•ì„ ì¶”ì¶œí–ˆëŠ”ë°, $C_1$ì—ì„œëŠ” íŠ¹ì§•ì„ 4ê°œë¥¼ ì¶”ì¶œí•˜ê³ , $C_2$ì—ì„œëŠ” íŠ¹ì§•ì„ 12ê°œë¥¼ ì¶”ì¶œí•œ ë’¤ ê²°ê³¼ë¬¼ì´ë¼ê³  ìƒê°í•˜ì‹œë©´ ë©ë‹ˆë‹¤. 'íŠ¹ì§•(Feature)ì„ ì¶”ì¶œí•œë‹¤'ë¼ëŠ” ë§ì´ ë¬´ìŠ¨ ë§ì¸ì§€ ì´í•´ë¥¼ ë•ê¸° ìœ„í•´ì„œ, ì•„ë˜ ì‚¬ì§„ì„ ì¤€ë¹„í–ˆìŠµë‹ˆë‹¤. Images from deliveryimages. ìœ„ ì‚¬ì§„ì€, ì‚¬ëŒ ì–¼êµ´ì„ í•™ìŠµí•˜ëŠ” CNN ëª¨ë¸ì˜ Layerë³„ë¡œ ì¶”ì¶œí•œ íŠ¹ì§•ë“¤ì„ ì‹œê°í™” í•œ ê²ƒì…ë‹ˆë‹¤. ë§¨ì²˜ìŒì—” Pixelë¡œ êµ¬ì„±ë¼ìˆëŠ” ì›ë³¸ ì´ë¯¸ì§€ì—ì„œ ë§¨ì²˜ìŒì—ëŠ” ì·¨ìš´ íŠ¹ì§•ì¸ ê°€ë¡œ, ì„¸ë¡œ, ëŒ€ê°ì„ , ì›, ê³¡ì„  ë“±ë“±ì˜ ë¹„êµì  ë‹¨ìˆœí•œ edgeë“¤ë§Œ íŠ¹ì§•ìœ¼ë¡œ ì¶”ì¶œí•˜ê³  ìˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ëª¨ë¸ì˜ êµ¬ì¡°ê°€ ë” ê¹Šì´ ë“¤ì–´ê°ˆ ìˆ˜ë¡, ê·¸ ë‹¨ìˆœí•œ Featureë“¤ì„ ì¡°í•©í•´ì„œ ì¡°ê¸ˆë” ë³µì¡í•œ ëˆˆ, ì½”, ì… ë“±ì„ ê·¸ë¦´ ìˆ˜ ìˆê²Œ ë˜ê³ , ê·¸ ìì²´ë¥¼ Featureë¡œ ì‚¼ì„ ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤. ê·¸ëŸ¬ë‹¤ ë³´ë©´ ì‚¬ëŒì˜ ì „ì²´ì „ì¸ ì–¼êµ´ì´ë¼ëŠ” objectë¥¼ Detectí•  ìˆ˜ ìˆëŠ” ëª¨ë¸ì´ ë˜ëŠ” ê²ƒì´ì£ . ê·¸ë˜ì„œ ì œ ê°œì¸ì ìœ¼ë¡œëŠ” ë“¤ì–´ì˜¬ ë•ŒëŠ” Input Imageì˜ Colorë¼ëŠ” ì˜ë¯¸ì˜ Channelë¡œ ë¶€ë¥´ëŠ” ê²ƒì´ ë” ì™€ë‹¿ë‹¤ê°€, Layerë¥¼ í†µê³¼í•  ìˆ˜ë¡ ë”ìš±ë” ì •êµí•œ íŠ¹ì§•ë“¤ì„ ì´ë¯¸ì§€ì—ì„œ ë½‘ê¸° ë•Œë¬¸ì—, Feature mapì´ë¼ëŠ” ë§ì´ ë” ì™€ë‹¿ìœ¼ë‹ˆ ì„œë¡œ í˜¼ìš©í•´ì„œ ê°™ì€ ë…€ì„ì„ ë¶€ë¥´ëŠ” ê²ƒ ê°™ë‹¤ëŠ” ëŠë‚Œì´ ìˆìŠµë‹ˆë‹¤. Kernel(= Filter) & Stride ë°”ë¡œ ìœ„ì—ì„œ ì„¤ëª…í•œ Feature Mapì€ ì´ì œ ì„¤ëª…í•  Kernel, í˜¹ì€ Filterë¼ëŠ” ë…€ì„ì„ í†µê³¼í•œ ë’¤ ë‚˜ì˜¨ ê²°ê³¼ë¬¼ ì…ë‹ˆë‹¤. ì´ë¯¸ì§€ê°€ ë“¤ì–´ì™”ì„ ë•Œ, kernelì´ë¼ëŠ” Windowë¥¼ ì •í•˜ê³ , ê·¸ Windowë¥¼ ì›€ì§ì´ë©´ì„œ ê·¸ Kernelì´ ê°€ì§€ê³  ìˆëŠ” weightê°’ë“¤ê³¼ Input imageì™€ì˜ ì—°ì‚°ì„ í†µí•´ ìƒˆë¡œìš´ ê°’ì„ ê°€ì§„ Imageë¥¼ ìƒì„±í•˜ê²Œ ë˜ëŠ” ê²ƒì´ì£ . ì•„ë˜ ì˜ˆì‹œë¥¼ í†µí•´ ë” ìì„¸íˆ ì•Œì•„ ë´…ì‹œë‹¤. Images from blog.bkbklim.com. ìœ„ Animationì—ì„œ Inputì´ë¯¸ì§€ëŠ” 5x5 Sizeì´ê³ , 3x3 Sizeì˜ Kernel, í˜¹ì€ Filterê°€ í•œ ì¹¸ì”© ì›€ì§ì´ë©´ì„œ Imageì™€ ìì‹ ì´ ê°€ì§€ê³  ìˆëŠ” Feature mapì„ ê³„ì‚°í•˜ì—¬ ê²°ê³¼ê°’ì„ ë‚´ë†“ê³  ìˆìŠµë‹ˆë‹¤. Kernelì€ Xì ëª¨ì–‘ì˜ Filterë„¤ìš”. element-wise ê³±, ì¦‰, dot productë¥¼ ê³„ì‚°í•˜ì—¬ ìì‹ ì˜ í•„í„°ì— ë¶€í•©í•˜ëŠ” ìœ„ì¹˜ë©´ ê³±í•œ ê°’ì´, ì•„ë‹ˆë©´ 0ì´ ê³±í•´ì ¸ì„œ ì˜ë¯¸ì—†ëŠ” 0ì´ ë‚˜ì˜¤ê²Œ ë©ë‹ˆë‹¤. ê·¸ë ‡ê²Œ ë‚˜ì˜¨ ê²°ê³¼ë“¤ì„ ë‹¤ ë”í•œ ê°’ í•˜ë‚˜ë§Œ ê²°ê³¼ë¡œ ë‚´ë†“ìŠµë‹ˆë‹¤. ì—¬ê¸°ì„œ ë“±ì¥í•˜ëŠ” Stride! ìì—°ìŠ¤ëŸ½ê²Œ ì´ ì• ë‹ˆë©”ì´ì…˜ì—ì„œëŠ” í•œ ì¹¸ì”© ì›€ì§ì´ê³  ìˆìŠµë‹ˆë‹¤ë§Œ, ì–´ë””ê¹Œì§€ë‚˜, Strideê°€ 1x1ì¼ ë•Œì˜ ì›€ì§ì„ì…ë‹ˆë‹¤. StrideëŠ” ì–´ëŠ ì •ë„ì˜ ê°„ê²©ì„ ê°€ì§€ê³  Kernel ê³„ì‚°ì„ ì§„í–‰í•  ê²ƒì¸ì§€ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì²™ë„ì…ë‹ˆë‹¤. Strideê°€ 2x2ì˜€ë‹¤ë©´, ë‘ì¹¸ì”© ì›€ì§ì¼í…Œê³ , ì´ Input Sizeì™€ëŠ” ë§ì§€ ì•Šê¸° ë•Œë¬¸ì— ì—ëŸ¬ë¥¼ ì¼ìœ¼í‚µë‹ˆë‹¤. ì•„ë˜ëŠ” Filterë¥¼ ì„¤ëª…í•˜ëŠ” ë˜ ë‹¤ë¥¸ ì´ë¯¸ì§€ ì¸ë°ìš”, ìš°ë¦¬ê°€ ì–¸ê¸‰í•œ ì € Filterì— ë³´ì´ëŠ” $w$ê°€ ì‹¬ìƒì¹˜ ì•ŠìŠµë‹ˆë‹¤. Backpropagationì„ í•˜ë©´ì„œ Updateë˜ëŠ” Weightë“¤ì€ ë‹¤ ì €, Filterì˜ Weightë“¤ì…ë‹ˆë‹¤! ë” ëª…í™•í•œ íŠ¹ì§•ë“¤ì„ ì¶”ì¶œí•˜ê¸° ìœ„í•œ ì„¸ë ¨ëœ Filterê°€ ë˜ê¸° ìœ„í•´ ê·¸ weightë“¤ì„ ë§ì¶°ë‚˜ê°€ëŠ” ê²ƒì´ì£ . ê·¸ëŸ¼ ì´ë ‡ê²Œ ë§Œë“¤ì–´ì§„ Filterë“¤ì„ í†µê³¼í•˜ëŠ” Feature mapë“¤ì€ ì–´ë–»ê²Œ í˜•ì„±ë˜ëŠ”ì§€, ë” ëª…í™•í•œ ì´í•´ë¥¼ ìœ„í•´ ì•„ë˜ ì‚¬ì§„ì„ ë³´ì‹¤ê¹Œìš”. Images from deliveryimages. ìœ„ì™€ ê°™ì€ Filterê°€ í•˜ë‚˜ ìˆìŠµë‹ˆë‹¤. ê³¡ì„ ì„ ì°¾ëŠ” Filterë„¤ìš”. ê·¸ëŸ¼ ì´ Filterê°€ ë“¤ì–´ì˜¨ ì¥ ì´ë¯¸ì§€ë¥¼ Strideì— ë§ê²Œ ëŒì•„ ë‹¤ë‹ˆê²Œ ë©ë‹ˆë‹¤. ê·¸ëŸ¬ë©´ì„œ, ì´ ê³¡ì„ ì— í•´ë‹¹í•˜ëŠ” ìœ„ì¹˜ê°€ ìˆëŠ”ì§€ ì°¾ìŠµë‹ˆë‹¤. ì´ Filterê°€ í•œë°”í€´ ë‹¤ ëŒê³  ì™„ì„±ëœ Feature mapì€, ì•„ë˜ì™€ ê°™ì´ í•´ë‹¹ Filterì— ë°˜ì‘í•˜ëŠ” ë¶€ë¶„ì— ë†’ì€ ìˆ«ìë¥¼, ì•„ë‹Œ ë¶€ë¶„ì—ì„œëŠ” 0ì— ê°€ê¹Œìš´ ìˆ˜ë¥¼ ê°€ì§„ Feature mapì´ ë˜ëŠ” ê²ƒì´ì£ . Images from deliveryimages.ì‘ì•„ì§€ëŠ” Image Size ìœ„ì— ë‚˜ì˜¨ Animationì—ì„œ ì£¼ëª©í•  ì ì€, 5x5 ì´ì—ˆë˜ ì´ë¯¸ì§€ ì‚¬ì´ì¦ˆê°€, Kernel ê³„ì‚°ì„ ë§ˆì¹œ í›„, 3x3ê°€ ëë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤! ì´ëŸ° ê³„ì‚°ì´ ì € ìœ„ì— ì‚¬ì§„ì—ì„œ ë³´ì…¨ë“¯ì´ 32x32 sizeì˜€ë˜ MNIST ì´ë¯¸ì§€ê°€, $C_1$ì—ì„œ 28x28ì´ë˜ê³ , $C_2$ì—ì„œ 10x10 sizeë¡œ ì¤„ê²Œ ë˜ì—ˆëŠ”ì§€ ì„¤ëª…í•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤. Padding ì´ë¯¸ì§€ê°€ ê³„ì† Convolution layerë¥¼ í†µê³¼í•˜ë©´ì„œ ì‘ì•„ì§€ë©´ ë‚˜ì¤‘ì—ëŠ” 1x1ê¹Œì§€ ê°€ë‹¤ëª»í•´ ì—†ì–´ì§€ì§€ ì•Šì„ê¹Œìš”?! ê·¸ë˜ì„œ ì´ë¯¸ì§€ì˜ Sizeê°€ ë„ˆë¬´ ì¤„ì–´ë“¤ì§€ ì•Šê²Œ ì´ë¯¸ì§€ ì£¼ë³€ì— ê°’ì„ ë„£ì–´ì£¼ëŠ” ê¸°ë²•ì„ paddingì´ë¼ê³  í•©ë‹ˆë‹¤. ê°€ì¥ ë§ì´ ì“°ì´ëŠ” Zero paddingìœ¼ë¡œ ì˜ˆì‹œë¥¼ ë³´ì´ìë©´ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤. ì €ë ‡ê²Œ Kernel Sizeê°€ 2x2ì´ê³ , Strideê°€ 1x1ì¸ ê²½ìš°, ì›ë³¸ì´ 3x3 Sizeì˜€ìœ¼ë©´ 2x2 kernelë¡œ ê³„ì‚°ì„ í•´ë„ ì´ 9ë²ˆì„ ê³„ì‚°í•˜ì—¬ ì›ë³¸ ì‚¬ì´ì¦ˆë¥¼ ê·¸ëŒ€ë¡œ ìœ ì§€í•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤. Pooling Poolingì€ Filter ê³„ì‚°ì´ ì•„ë‹Œ, kernel sizeì— í•´ë‹¹í•˜ëŠ” ì˜ì—­ì— ìˆëŠ” ê°’ë“¤ì„ ì¼ê´„ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ê³  ì‹¶ì„ ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤. ëŒ€í‘œì ì¸ Poolingìœ¼ë¡œ ë§ì´ ì“°ì´ëŠ” Max Poolingì˜ ê°œë…ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤. Images from deliveryimages. ë§ ê·¸ëŒ€ë¡œ 2x2 Max poolingì„ í•˜ê² ë‹¤ í•˜ë©´, í•´ë‹¹ ì‚¬ì´ì¦ˆì—ì„œ ê°€ì¥ í° ê°’ë§Œ ì·¨í•˜ëŠ” ê²ƒì´ì£ . ê°€ì¥ ì¤‘ìš”í•œ ì •ë³´ë§Œ ì·¨í•˜ê² ë‹¤ëŠ” ì˜ë„ê°€ ìˆìŠµë‹ˆë‹¤. ê·¸ ì™¸ì—ë„ Average Poolingì„ ë¹„ë¡¯í•œ ë‹¤ì–‘í•œ Poolingì´ ìˆìŠµë‹ˆë‹¤. ì´ Poolingì˜ ì¥ì ì€, ë¬´ì—‡ë³´ë‹¤ ê³„ì‚°ì´ ë‹¨ìˆœí•´ì„œ ê³„ì‚°ëŸ‰, Computation Costê°€ ì‘ë‹¤ëŠ” ê²ƒ ì •ë„ê°€ ë˜ê² ìŠµë‹ˆë‹¤. ìœ„ì—ì„œ ë°°ìš´ Paddingì„ ì‘ìš©í•´ë³´ë©´, Paddingì„ ì ë‹¹íˆ ì¤€ ì´ë¯¸ì§€ì— Poolingì„ í•˜ë©´ ì´ë¯¸ì§€ ì‚¬ì´ì¦ˆëŠ” ì¤„ì§€ ì•Šì§€ë§Œ ë¹ ë¥¸ ê³„ì‚°ì€ ê°€ëŠ¥í•œ êµ¬ì¡°ë„ ê°€ëŠ¥í•˜ê² ì£ ? ì—¬ê¸°ê¹Œì§€ ê¸°ë³¸ì ì¸ ë”¥ëŸ¬ë‹ ìš©ì–´ì¸, Batch, Epoch, ê·¸ë¦¬ê³  CNNì˜ ê¸°ë³¸ ìš©ì–´ë“¤ì„ ì‚´í´ ë³´ì•˜ìŠµë‹ˆë‹¤! ë‹¤ìŒ í¬ìŠ¤íŒ…ì—ì„œëŠ”, Activation Function, MLPì™€ CNNì˜ ì°¨ì´ì ì— ëŒ€í•´ ì´ì•¼ê¸° í•´ ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","link":"/2018/04/06/Basic-Deep-Learning-02/"},{"title":"Hi, Keras! :) (1)","text":"A Keras Usage with fashion MNIST Keras example using Colab Pytorchì™€ Tensorflowì˜ Wrapperì¸ Tensorpackë§Œ ì¨ë´¤ë˜ ì €ëŠ”, ì˜¬í•´ ì²˜ìŒìœ¼ë¡œ Kerasë¥¼ ì‚¬ìš©í•´ë³´ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. ë¸”ë¡ê³¼ í•¨ê»˜ í•˜ëŠ” íŒŒì´ì¬ ë”¥ëŸ¬ë‹ ì¼€ë¼ìŠ¤ ë¼ëŠ” ì±…ìœ¼ë¡œ ê³µë¶€í•˜ë©´ì„œ ê·¸ ê°„ê²°í•¨ì— ë†€ëê³ , ëŒ€ì¶©ëŒ€ì¶© ì´í•´í•˜ê³  ë„˜ì–´ê°”ë˜ ê°œë…ë“¤ì´ ì¢‹ì€ ì˜ˆì‹œë¡œ ì„¤ëª…ë˜ì–´ ìˆì–´, ê·¸ ë‚´ìš©ë“¤ì„ ì •ë¦¬í•´ë³´ê³ ì í¬ìŠ¤íŒ…ì„ í•˜ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ë²ˆ í¬ìŠ¤íŒ…ì€ ì±…ì˜ Part 1, ì¼€ë¼ìŠ¤ ì‹œì‘í•˜ê¸°ì™€ Part 2. ë”¥ëŸ¬ë‹ ê°œë…ì¡ê¸°ì— ë‚˜ì˜¤ëŠ” Keras ì˜ˆì œë“¤ì„ Fashion MNIST ë°ì´í„°ë¡œ ì¬êµ¬ì„±í•´ ë³¸ ê²ƒì…ë‹ˆë‹¤. ğŸ˜¬ ì±… ë‚´ìš© ì´ì™¸ì— ì¶”ê°€ëœ ë¶€ë¶„ì€, Colabì˜ Notebookìœ¼ë¡œ ì´ë²ˆ í¬ìŠ¤íŒ…ì´ êµ¬ì„±ì´ ë˜ì—ˆë‹¤ëŠ” ê²ƒì´ê³ , ì—¬ê¸°ì—ì„œ Colab Notebookìœ¼ë„ ë™ì¼í•œ ë‚´ìš© í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜, matplotlibì˜ plot ëŒ€ì‹ ì—, Tensorboardcolabì„ ì‚¬ìš©í•˜ì—¬ì„œ plot ì‹œê°í™”ë¥¼ í•˜ë„ë¡ ë°©ì‹ì„ ë°”ê¿”ë³´ì•˜ìŠµë‹ˆë‹¤. í”ì¾Œíˆ ë¸”ë¡œê·¸ í¬ìŠ¤íŒ…ì„ í—ˆë½í•´ì£¼ì‹  ì €ì ê¹€íƒœì˜ë‹˜ê»˜ ë‹¤ì‹œ í•œ ë²ˆ ê°ì‚¬ë¥¼ í‘œí•©ë‹ˆë‹¤. â˜º Import packages ì, ì‹œì‘í•´ë³¼ê¹Œìš”! ğŸ˜1234567891011121314import osimport kerasimport tensorflow as tfimport keras.utils as utils import matplotlib.pyplot as pltfrom tqdm import tqdm_notebookfrom keras.datasets import fashion_mnistfrom keras.layers import Dense, Activationfrom keras.models import Sequential, load_model# remove error message from tensorflowtf.logging.set_verbosity(tf.logging.ERROR)%matplotlib inline Output: 1Using TensorFlow backend. keras.utils: ìì£¼ ì‚¬ìš©ë˜ëŠ” ìœ ìš©í•œ ê¸°ëŠ¥ë“¤ ëª¨ìŒ. ëŒ€í‘œì ìœ¼ë¡œ One-hot encodingì„ í•´ì£¼ëŠ” to_categorical(), l1-l2 normalizeë¥¼ ê°€ëŠ¥í•˜ê²Œ í•´ì£¼ëŠ” normalize() ë“±ì´ ìˆë‹¤. keras.datasets: MNIST, Fashion MNIST, CIFAR10, CIFAR100, IMDB Movie reviews ê¸ì •-ë¶€ì • íŒë³„ì…‹, Reuters ë‰´ìŠ¤í† í”½ ë¶„ë¥˜ì…‹, Boston ë¶€ë™ì‚°ê°€ê²© datasetì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆë‹¤. keras.layers: Denseë¶€í„° CNN, Pooling, Padding, RNN ë“±ë“±.. ìµìˆ™í•œ ë”¥ëŸ¬ë‹ layerë“¤ì˜ ì§‘í•©ì†Œ. keras.models: keras ëª¨ë¸ì„ ë§Œë“œëŠ” ë°©ë²•ì€ í¬ê²Œ, Sequentialê³¼ Model - functional APIë¥¼ ì‚¬ìš©í•˜ëŠ” ë°©ë²• 2ê°€ì§€ë¡œ ë‚˜ë‰œë‹¤. Pytorchë‘ ë¹„ìŠ·í•˜ë‹¤. Sequentialì€ ì‚¬ìš©í•  ëª¨ë¸ì˜ ë¶€í’ˆì„ ë‹¤ ì„¤ì •í•œ ë’¤ Inputì„ ë„£ìœ¼ë©´ í•œë²ˆì— ë ˆì´ì–´ì™€ ë ˆì´ì–´ ì‚¬ì´ ì„¤ì •ì„ ì„¸íŒ…í•œ outputì— ë§ê²Œ ë§ì¶°ì£¼ê³ , functional APIì¸ Modelì„ ì‚¬ìš©í•˜ë©´ í•œë•€í•œë•€(?) ê·¸ íë¦„ì„ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ì •í•  ìˆ˜ ìˆëŠ” ììœ ë„ë¥¼ ê°€ì§„ë‹¤. ë³¸ í¬ìŠ¤íŒ…ì—ì„œëŠ” Sequentialì„ ì‚¬ìš©í•  ê²ƒì´ë‹ˆ, Modelì„ ì‚¬ìš©í•˜ëŠ” ì˜ˆì‹œëŠ” ì—¬ê¸°ì—ì„œ í™•ì¸. Loading Data Fashion MNIST 1(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data() Output: 12345678Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz32768/29515 [=================================] - 0s 9us/stepDownloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz26427392/26421880 [==============================] - 5s 0us/stepDownloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz8192/5148 [===============================================] - 0s 0us/stepDownloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz4423680/4422102 [==============================] - 2s 1us/step Peeking the data 10ê°œì˜ Fashion MNIST ë°ì´í„°ë“¤ì„ ì‹œê°í™”! ğŸ˜123456789101112class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']plt.figure(figsize=(8, 4))for i in range(10): plt.subplot(2, 5, i+1) plt.xticks([]) plt.yticks([]) plt.imshow(x_train[i], cmap=plt.cm.binary) plt.xlabel(class_names[y_train[i]]) plt.grid(False)plt.show() Preprocessing 50000 for Training, 10000 for Validation, 10000 for Test 123456789x_val = x_train[50000:]y_val = y_train[50000:]x_train = x_train[:50000]y_train = y_train[:50000]# preprocessing x_train = x_train.reshape(50000, 784).astype('float32') / 255.0x_val = x_val.reshape(10000, 784).astype('float32') / 255.0x_test = x_test.reshape(10000, 784).astype('float32') / 255.0 Label one-hot encoding (utils.to_categorical):keras.utils.to_categorical API 1234# label one-hot encoding.y_train = utils.to_categorical(y_train)y_val = utils.to_categorical(y_val)y_test = utils.to_categorical(y_test) Callbacks Tensorboard ë„ìš°ê¸° Early Stopping / 5ë²ˆì„ ê¸°ë‹¤ë ¤ë„ ì„±ëŠ¥ì´ ë‚˜ì•„ì§€ì§€ ì•Šì„ ê²½ìš° í•™ìŠµ ì¤‘ë‹¨ Model Checkpoint / val_lossê°€ ê°€ì¥ ë‚®ì„ ë•Œë§Œ ì €ì¥ 123456789101112131415161718from tensorboardcolab import *from keras.callbacks import EarlyStopping, ModelCheckpoint# 3. Tensorboard ì„¸íŒ…tbc=TensorBoardColab()# 4. Early Stopping early_stopping = EarlyStopping(patience=5) # 5. Model Checkpointpath = './model/'if not os.path.exists(path): os.mkdir(path) model_path = path + '{epoch:02d}-{val_loss:.4f}.h5'checkpoint = ModelCheckpoint(filepath = model_path, monitor = 'val_loss', verbose = 0, save_best_only = True) Output:123Wait for 8 seconds...TensorBoard link:https://57207182.ngrok.io Create a model / Train / Test Sequential() - ëª¨ë¸ ìƒì„± add() - ëª¨ë¸ ë¸”ëŸ­ë¼ìš°ê¸° compile() - ëª¨ë¸ í•™ìŠµì— ì“¸ ë„êµ¬ ì„¸íŒ…í•˜ê¸° fit() - í•™ìŠµì‹œí‚¤ê¸° evaluate() - í‰ê°€í•˜ê¸° 123456789101112131415161718192021222324252627282930313233343536373839# GPU ì‚¬ìš©# with tf.device('/device:GPU:0'):# 1. ëª¨ë¸ êµ¬ì„±model = Sequential()model.add(Dense(units=64, input_dim=28*28, activation='relu'))model.add(Dense(units=10, activation='softmax'))# 2. ëª¨ë¸ í•™ìŠµê³¼ì • ì„¤ì •í•˜ê¸° model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])# 3. ëª¨ë¸ í•™ìŠµì‹œí‚¤ê¸°for epoch in tqdm_notebook(range(50)): hist = model.fit(x_train, y_train, epochs=1, batch_size=32, verbose=0, validation_data=(x_test, y_test), callbacks=[TensorBoardColabCallback(tbc), early_stopping, checkpoint]) # tensorboard lines tbc.save_value(\"fasion mnist\", \"train_acc\", epoch, hist.history['acc'][0]) tbc.save_value(\"fasion mnist\", \"val_acc\", epoch, hist.history['val_acc'][0]) tbc.save_value(\"fasion mnist\", \"train_loss\", epoch, hist.history['loss'][0]) tbc.save_value(\"fasion mnist\", \"val_loss\", epoch, hist.history['val_loss'][0]) tbc.flush_line(\"train_acc\") tbc.flush_line(\"val_acc\") tbc.flush_line(\"train_loss\") tbc.flush_line(\"val_loss\") if (epoch+1)%10 == 0: print('-----'*5) print(\"Epoch: {} | Loss: {:0.3f} | Acc: {:0.3f}\".format( epoch+1, hist.history['loss'][0], hist.history['acc'][0]))loss_and_metrics = model.evaluate(x_test, y_test, batch_size=32)tbc.close()print('-----'*10)print('\\nLoss and metrics: ' + str(loss_and_metrics)) Output:12345678910111213141516HBox(children=(IntProgress(value=0, max=50), HTML(value='')))-------------------------Epoch: 10 | Loss: 0.393 | Acc: 0.864-------------------------Epoch: 20 | Loss: 0.342 | Acc: 0.879-------------------------Epoch: 30 | Loss: 0.312 | Acc: 0.890-------------------------Epoch: 40 | Loss: 0.288 | Acc: 0.898-------------------------Epoch: 50 | Loss: 0.270 | Acc: 0.90510000/10000 [==============================] - 1s 60us/step--------------------------------------------------Loss and metrics: [0.3537946595430374, 0.8761] Tensorboard Plot: Model Structure Visualization Model êµ¬ì¡° ì‹œê°í™”í•˜ê¸°: model.summary() & SVG() ğŸ˜ƒ 12345from IPython.display import SVGfrom keras.utils.vis_utils import model_to_dotprint(model.summary())SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg')) Output: 123456789101112_________________________________________________________________Layer (type) Output Shape Param # =================================================================dense_1 (Dense) (None, 64) 50240 _________________________________________________________________dense_2 (Dense) (None, 10) 650 =================================================================Total params: 50,890Trainable params: 50,890Non-trainable params: 0_________________________________________________________________None Save & Load Model Model ì €ì¥ & ë¶ˆëŸ¬ì˜¤ê¸° 12 model.save('fashion_mnist_model.h5')model = load_model('fashion_mnist_model.h5') document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","link":"/2019/06/12/keras_101/"},{"title":"Hi, Docker! :) (3)","text":"Docker Containerì— SSH ì ‘ì† í˜„ì¬ ë‚´ ì»¨í…Œì´ë„ˆë¥¼ ì´ë¯¸ì§€ë¡œ ì €ì¥í•˜ê¸° Docker Tutorial, ì„¸ ë²ˆì§¸â­ì…ë‹ˆë‹¤! ì´ë²ˆ í¬ìŠ¤íŒ…ì—ì„œëŠ” ì´ì „ ê¸€ì—ì„œ ë…¸ì¶œì‹œí‚¨ 22 port ë¥¼ ì‚¬ìš©, ì»¨í…Œì´ë„ˆ í™˜ê²½ìœ¼ë¡œ ì™¸ë¶€ì—ì„œ SSH ì ‘ì†ì„ í•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ ë‹¤ë£¨ê³ , SSH Settingì´ ëë‚œ ì»¨í…Œì´ë„ˆ ìì²´ë¥¼ ì´ë¯¸ì§€ë¡œ ë§Œë“œëŠ” ë°©ë²•ì„ ì•Œì•„ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. ìµœê·¼ë“¤ì–´ ë§ì€ íšŒì‚¬ë‚˜ ë‹¨ì²´, ê°œì¸ë“¤ì´ AWSë‚˜ Google Cloud Platform ë“±ì„ ì‚¬ìš©í•˜ë©´ì„œ GPU ë° TPU Serverë¥¼ ì‚¬ìš©í•˜ê³  ìˆì£ . ê·¸ë˜ì„œ ë‹¹ì—°íˆ AWSë‚˜ Google Cloudì—ì„œë„ Dockerë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ ëê³ , ìì—°ìŠ¤ëŸ½ê²Œ ì–¸ì œ ì–´ë””ì„œë“  ë¬´ê±°ìš´ ê³„ì‚°ì´ë‚˜ í•™ìŠµì€ Cloudë‚˜ ì›ê²© ì„œë²„ì—ì„œ ì²˜ë¦¬í•˜ê³  ì‹¤ì œ ì‚¬ìš©ìëŠ” ììœ ë¡­ê²Œ ì ‘ì†í•˜ê³  í•´ë‹¹ ë¨¸ì‹ ì„ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. Digital NomadğŸ‘ê°€ ê°€ê¹Œì›Œì§€ê³  ìˆìŠµë‹ˆë‹¤. í˜¹ì€ Digital Slave.. ì´ëŸ° í˜„ì‹¤ì— ë§ì¶°, SSHë¡œ ë‚´ Deocker Containerì— ì ‘ì†í•˜ëŠ” ë²• ì •ë„ëŠ” ì•„ëŠ” ê²ƒì´ ì¢‹ê² ì£ ? ë¬¼ë¡  í‚¤ì™€ íŒ¨ìŠ¤ì›Œë“œ ê´€ë¦¬ ë° ë³´ì•ˆìƒì˜ ì´ìœ ë¡œ ì¼ê°ì—ì„œëŠ” SSHë¡œ ì»¨í…Œì´ë„ˆì— ì ‘ì†í•  ìˆ˜ ìˆê²Œ í•˜ëŠ” ê²ƒì„ ìš°ë ¤í•˜ì§€ë§Œ, ê°œì¸ì ì¸ í•™ìŠµì´ë‚˜ ê°€ë²¼ìš´ ì‹¤í—˜ ìš©ë„ë¡œë§Œ ì‚¬ìš©í•œë‹¤ê³  í–ˆì„ ë•ŒëŠ” íš¨ìœ¨ì ì´ë¼ê³  ìƒê°í•´ í¬ìŠ¤íŒ…ì„ í•˜ê¸°ë¡œ í–ˆìŠµë‹ˆë‹¤. SSH Server in Container1. Container ìƒì„± (--cap-add) ë¨¼ì € SSHì„ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ ì´ë¯¸ì§€ë¡œ ë¶€í„° ì»¨í…Œì´ë„ˆë¥¼ ìƒì„±í•  ë•Œ, ì•„ë˜ì™€ ê°™ì€ ì˜µì…˜ì„ í•¨ê»˜ ì¤ë‹ˆë‹¤. ì´ë¯¸ì§€ëŠ” Hi, Docker! :) (2)ì—ì„œ ìƒì„±í•œ docker101ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. 1$ docker run -d --name ssh_container --cap-add=NET_ADMIN --cap-add=NET_RAW -p 8888:8888 -p 22022:22 docker101 --cap-add=NET_ADMINì—ì„œ --cap-add ì˜µì…˜ì€, ì»¨í…Œì´ë„ˆì—ê²Œ íŠ¹ì •í•œ cgroups ì„ ì‚¬ìš©í•˜ê²Œ í•´ì£¼ëŠ” ê²ƒìœ¼ë¡œ, ì—¬ê¸°ì„œëŠ” adminì˜ networkë¥¼ ì‚¬ìš©í•˜ê² ë‹¤ëŠ” ì˜ë¯¸ë¡œ NET_ADMIN ì„, adminì˜ iptablesë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ê² ë‹¤ëŠ” ì˜ë¯¸ NET_RAW ë¥¼ ë³€ìˆ˜ë¡œ ì¤ë‹ˆë‹¤. cgroups: control groupsì˜ ì•½ì - í”„ë¡œì„¸ìŠ¤ë“¤ì˜ ìì›ì˜ ì‚¬ìš©(CPU, ë©”ëª¨ë¦¬, ë””ìŠ¤í¬ ì…ì¶œë ¥, ë„¤íŠ¸ì›Œí¬ ë“±)ì„ ì œí•œí•˜ê³  ê²©ë¦¬ì‹œí‚¤ëŠ” ë¦¬ëˆ…ìŠ¤ ì»¤ë„ ê¸°ëŠ¥ (feat. wikipedia) ì €ëŠ” -p 22022:22 ë¡œ, ì»¨í…Œì´ë„ˆê°€ SSH ì ‘ì†ì„ í—ˆìš©í•  22ë²ˆ í¬íŠ¸ë¥¼ Hostì˜ 22022ì™€ ì—°ê²°ì‹œì¼œ ì£¼ê² ìŠµë‹ˆë‹¤. 2. SSH, ufw ì„¤ì¹˜ ì´ë ‡ê²Œ ìƒì„±í•œ ì»¨í…Œì´ë„ˆì— ì´ì œ SSH ì ‘ì†ì„ í•  ìˆ˜ ìˆë„ë¡ í•˜ë ¤ë©´, ì†ë´ì¤„ ê²ƒì´ ë§ê¸°ë•Œë¬¸ì—â€¦ğŸ‘Š ë°±ê·¸ë¼ìš´ë“œì—ì„œ ëŒì•„ê°€ê³  ìˆëŠ” ssh_containerì— execë¡œ ì ‘ì†í•©ë‹ˆë‹¤. 1$ docker exec -it ssh_container /bin/bash ê·¸ë¦¬ê³  SSHì™€, ë¦¬ëˆ…ìŠ¤ì—ì„œ ë°©í™”ë²½ì„ ê´€ë¦¬í•´ì£¼ëŠ” ufwë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤. 1$ apt-get install ssh ufw -y ì•„ë˜ì™€ ê°™ì´ sshdì˜ ìœ„ì¹˜ê°€ ì˜ ë‚˜ì˜¨ë‹¤ë©´ ì„¤ì¹˜ê°€ ì˜ ëœ ê²ƒì…ë‹ˆë‹¤! 12[work] # which sshd/usr/sbin/sshd 3. ë¹„ë°€ë²ˆí˜¸ ì„¤ì • (sshd_config, passwd root) SSH ì ‘ì†ì„ í•  ë•Œ ë¬¼ì–´ë³¼ ë¹„ë°€ë²ˆí˜¸ë¥¼ ì„¤ì •í•˜ë ¤ë©´, ë¨¼ì € /etc/ssh/ ì•„ë˜ì— ìˆëŠ” sshd_configíŒŒì¼ì„ ì¢€ ìˆ˜ì •í•´ì•¼í•©ë‹ˆë‹¤. 1$ vim /etc/ssh/sshd_config ë¥¼ ë³´ì‹œë©´, 123456789# $OpenBSD: sshd_config,v 1.101 2017/03/14 07:19:07 djm Exp $# This is the sshd server system-wide configuration file. See# sshd_config(5) for more information.# ì–´ì©Œêµ¬ì €ì©Œêµ¬......#LoginGraceTime 2m#PermitRootLogin prohibit-password#StrictModes yes... ë¼ê³  ëœ° í…ë°ìš”, ì—¬ê¸°ì„œ ì•„ë˜ì™€ ê°™ì´ #PermitRootLogin prohibit-password ë¶€ë¶„ì˜ ì£¼ì„ì„ í•´ì œí•˜ê³ , prohibit-passwordë¥¼ yesë¡œ ë°”ê¿”ì¤ë‹ˆë‹¤. 12345...#LoginGraceTime 2mPermitRootLogin yes#StrictModes yes... ê·¸ë ‡ê²Œ ì €ì¥ì„ í•˜ì‹  ë’¤ì—, ë‹¤ì‹œ bashë¡œ ëŒì•„ì™€ passwd root ì„ ì…ë ¥í•´ì„œ ë¹„ë°€ë²ˆí˜¸ë¥¼ ì„¤ì •í•´ì£¼ë©´ ëì…ë‹ˆë‹¤! 1234[work] # passwd rootEnter new UNIX password:Retype new UNIX password: passwd: password updated successfully 4. ufw ì„¸íŒ… etc/ufw/ì•„ë˜ì— ìˆëŠ” ufw.confíŒŒì¼ì—ì„œ ENABLED=noë¥¼, 1$ vim /etc/ufw/ufw.conf 1234# /etc/ufw/ufw.conf...ENABLED=no... ENABLED=yesë¡œ ğŸ‘‡ ë°”ê¿”ì¤ë‹ˆë‹¤. 123...ENABLED=yes... ê·¸ ë’¤ì—, bashë¡œ ëŒì•„ì™€ì„œ ufw enable ë¡œ í™œì„±í™”ë¥¼ í•´ì£¼ê³ , 12[work] # ufw enableFirewall is active and enabled on system startup ì´ì œ ì‹¤ì œë¡œ 22ë²ˆ portë¥¼ ë°©í™”ë²½ì—ì„œ í—ˆë½í•  ìˆ˜ ìˆê²Œ ufw allow ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. 123[work] # ufw allow 22/tcpRule addedRule added (v6) 5. SSH server ì‹œì‘ ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤. ì´ì œ ê·€ì°®ì€ ì¼ì€ ë‹¤ ëë‚¬ìŠµë‹ˆë‹¤.service ssh startë¡œ sshë¥¼ ì‹œì‘í•˜ê³ , 12[work] # service ssh start * Starting OpenBSD Secure Shell server sshd [ OK ] service ssh statusë¡œ ë™ì‘ì„ í™•ì¸í•˜ë©´ ë! 12[work] # service ssh status * sshd is running SSH Client ì, ê·¸ëŸ¼ ì—´ì‹¬íˆ ì„¸íŒ…í•œ ì»¨í…Œì´ë„ˆë¡œ ì´ì œ ì ‘ì†ì„ í•´ë´ì•¼ê² ì£ ?ğŸ˜ ë‹¹ì—°í•˜ì§€ë§Œ ê¸°ë³¸ ê°œë…ì€ Port forwardingì…ë‹ˆë‹¤. Hostì˜ 22022ë²ˆ portê°€ ssh_containerì˜ 22ë²ˆ portì™€ ì—°ê²°ë˜ì–´ìˆê¸° ë•Œë¬¸ì—, ê¸°ë³¸ì ìœ¼ë¡œ ì™¸ë¶€ì—ì„œ Docker ì»¨í…Œì´ë„ˆë¡œ ì ‘ì†ì„ í•˜ë ¤ë©´ Dockerê°€ ì‹¤í–‰ë˜ê³  ìˆëŠ” Host ë¨¸ì‹ ì„ í†µí•´ì„œ ì—°ê²°ì„ í•´ì•¼í•©ë‹ˆë‹¤. ë¨¼ì € ë„ì»¤ê°€ ì‹¤í–‰ë˜ê³  ìˆëŠ” ì œ PCëŠ” ë§¥ë¶ì¸ ê´€ê³„ë¡œ ifconfigë¥¼ ì‚¬ìš©í•´ì„œ ì œ ì»´í“¨í„°ì˜ IPê°€ 172.16.8.236ë¼ëŠ” ê²ƒì„ ì•Œì•„ëƒˆìŠµë‹ˆë‹¤. (linux: ifconfig - window: ipconfig) ë”°ë¼ì„œ, ssh ëª…ë ¹ì–´ë„ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤. 1$ ssh -p 22022 root@172.16.8.236 ê·¸ë ‡ë‹¤ë©´ ì´ ëª…ë ¹ì„ ë‚´ë¦¬ëŠ” ì˜ë¯¸ëŠ” ì•„ë˜ì˜ ê·¸ë¦¼ê³¼ ê°™ìŠµë‹ˆë‹¤. ì•„ë˜ì™€ ê°™ì´ ì ‘ì†ì„ í—ˆìš©í•˜ê² ëƒëŠ” ë¬¼ìŒì— ë‹µí•˜ë©´ ë¹„ë°€ë²ˆí˜¸ë¥¼ ë¬¼ì–´ë³´ê³ , 12345The authenticity of host '[172.16.8.236]:22022 ([172.16.8.236]:22022)' can't be established.ECDSA key fingerprint is SHA256:iMDl7X79mKNZEA5oadtMr2zQdJhJ4n2toAeJ58o9Tsg.Are you sure you want to continue connecting (yes/no)? yesWarning: Permanently added '[172.16.8.236]:22022' (ECDSA) to the list of known hosts.root@172.16.8.236's password: ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ë©´ ë“œë””ì–´ ssh_container ì•ˆìœ¼ë¡œ ì…ì„±(?)í•˜ê²Œ ë©ë‹ˆë‹¤! 123456789101112131415161718Welcome to Ubuntu 18.04.2 LTS (GNU/Linux 4.9.125-linuxkit x86_64) * Documentation: https://help.ubuntu.com * Management: https://landscape.canonical.com * Support: https://ubuntu.com/advantageThis system has been minimized by removing packages and content that arenot required on a system that users do not log into.To restore this content, you can run the 'unminimize' command.The programs included with the Ubuntu system are free software;the exact distribution terms for each program are described in theindividual files in /usr/share/doc/*/copyright.Ubuntu comes with ABSOLUTELY NO WARRANTY, to the extent permitted byapplicable law. [~] # sshë¥¼ ì‚¬ìš©í•´ì„œ ì»¨í…Œì´ë„ˆ ì•ˆìœ¼ë¡œ ë“¤ì–´ì™”ìŠµë‹ˆë‹¤! work directoryì•ˆì— ë°˜ê°€ìš´ Dataí´ë”ë„ ê·¸ëŒ€ë¡œ ì˜ ìˆë„¤ìš”. ì´ì œ ê³§ Digital NomadğŸ‘ê°€ ë  ê²ƒê°™ì€ ê¸°ë¶„ ì€ í¬ë§ì‚¬í•­ ì…ë‹ˆë‹¤. 1234[~] # cd work[work] # ls -a. .. .empty Data[work] # ì´ ì˜ˆì‹œëŠ” ë‚´ë¶€ë§ì´ë¼ì„œ, ì™¸ë¶€ì—ì„œ ì›ê²©ì ‘ì†ì€ ëª»í•˜ì–ì•„ìš”? ë§ìŠµë‹ˆë‹¤. ì˜ ì•„ì‹œê² ì§€ë§Œ, ì´ë²ˆ í¬ìŠ¤íŒ…ì—ì„œ ì˜ˆì‹œë¡œ ë“¤ì—ˆë˜ IP 172.16.8.236ì€ ë‚´ë¶€ë§(ê°™ì€ ê³µìœ ê¸°ë¥¼ ì“°ëŠ”, í˜¹ì€ ê°™ì€ ì‚¬ë‚´ë§)ì…ë‹ˆë‹¤. ë”°ë¼ì„œ, ë•Œë¡œëŠ” 192.xx.xxx.xxê°€ ë  ìˆ˜ë„ ìˆì£ . ê°™ì€ ë‚´ë¶€ë§ë¿ë§Œ ì•„ë‹ˆë¼, ì§„ì •ìœ¼ë¡œ ì¸í„°ë„·ì„ í†µí•´ ì–´ë””ì„œë‚˜ ì ‘ê·¼ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ê³  ì‹¶ë‹¤ë©´ ì € IPëŠ” Hostê°€ ë¶€ì—¬ë°›ì€ Public IPì¸ external IPì´ì–´ì•¼ í•©ë‹ˆë‹¤. AWSë‚˜ GCPì—ì„œ Docker ì»¨í…Œì´ë„ˆë¥¼ ì‚¬ìš©í•˜ê³  ê³„ì‹ ë‹¤ë©´, ì‚¬ìš©í•˜ê³  ê³„ì‹  Cloud Machineì— ì ‘ê·¼í•  ìˆ˜ ìˆëŠ” IPë¥¼ ì•Œë©´ ë˜ëŠ” ê²ƒì´ê³ , ìì²´ ì‚¬ì„¤ ì„œë²„ë¥¼ ìš´ì˜í•˜ì‹ ë‹¤ê³  í•´ë„ ë§ˆì°¬ê°€ì§€ ì…ë‹ˆë‹¤. í•´ë‹¹ Host ë¨¸ì‹ ì´ ê°€ì§€ê³  ìˆëŠ” Static IP, ê³ ì •IPê°€ ë˜ê² ì£ . ë‹¤ë§Œ ê°ê°ì˜ í™˜ê²½ì— ë”°ë¼ ssh ì ‘ì†ì„ í—ˆìš©í•˜ê¸° ìœ„í•œ SSH Serverì¸¡ì˜ ë°©í™”ë²½ ë° êµ¬ì²´ì ì¸ ì„¸íŒ…ì„ ë‹¤ ì„¤ëª…í•˜ê¸°ì—ëŠ” ì´ë²ˆ í¬ìŠ¤íŒ…ì˜ ë…¼ì§€ë¥¼ íë¦´ ê²ƒ ê°™ì•„ ì‚¬ì‹¤ ì œê°€ í˜ë“¤ì–´ì„œğŸ˜, ë‚´ë¶€ë§ ì ‘ì†ì´ë¼ëŠ” ì˜ˆì‹œë¥¼ í†µí•´ ssh container ì ‘ì†ì˜ ê°œë…ë§Œ ì‚´í´ë³´ì•˜ìŠµë‹ˆë‹¤. ì™¸ë¶€ë§ì„ í†µí•´ Docker Containerì— ì ‘ì†ì„ í•˜ì‹œë ¤ë©´, í•„ìš”ì— ë”°ë¼ ê°€ì§€ê³  ê³„ì‹  í™˜ê²½ì— ë”°ë¥¸ ë” ë§ì€ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤. Save My Container as an Image.(commit) ë” ê²Œìœ¼ë¥´ê³  ì‹¶ì€ ê°œë°œìê°€ ì¢‹ì€ ê°œë°œìê¸° ë•Œë¬¸ì—, ìš°ë¦¬ëŠ” ì´ ê·€ì°®ì€ ì‘ì—…ë“¤ì„, ë§¤ë²ˆ ì»¨í…Œì´ë„ˆë¥¼ ìƒì„±í•  ë•Œë§ˆë‹¤ í•´ì¤„ ìˆ˜ëŠ” ì—†ìŠµë‹ˆë‹¤! ì´ë ‡ê²Œ í˜ë“¤ê²Œ(?) ì„¸íŒ…í•œ, SSH ì ‘ì†ì´ ë˜ëŠ” ssh_containerë¥¼ imageë¡œ ë§Œë“¤ì–´ì„œ Docker Hubì—ë„ ì˜¬ë¦¬ê³ , í¸í•˜ê²Œ ì‚¬ìš©í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤. ì´ê²ƒì„ ê°€ëŠ¥í•˜ê²Œ í•´ì£¼ëŠ” ëª…ë ¹ì–´ê°€ commit ì…ë‹ˆë‹¤. ë§ì´ ë‚˜ì˜¨ ê¹€ì— ì§€ê¸ˆ ë‹¹ì¥ ì‚¬ìš©í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. ssh_containerë¡œ ssh_machine_learningì´ë¼ëŠ” ì´ë¦„ìœ¼ë¡œ Imageë¥¼ ë§Œë“­ë‹ˆë‹¤. 12$ docker commit ssh_container ssh_machine_learningsha256:2e134384b1c846ee76a069db2aad0b2664610c195b9d8c1b03d79b9e3de74a0e ì´ë¯¸ì§€ê°€ ì˜ ìƒì„±ì´ ëëŠ”ì§€ í™•ì¸ì„ í•´ë³´ë‹ˆ, ì˜ ìƒì„±ì´ ë˜ì—ˆë„¤ìš”! ì°¸ ì‰½ì£ ?ğŸ˜‡ğŸ¤˜ 1234$ docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEssh_machine_learning latest 4d9c11b16e4c 4 seconds ago 4.75GBdocker101 latest 71522855bd07 4 days ago 4.72GB Test ê·¸ëŸ¼ ì •ë§ë¡œ ì˜ë„ëŒ€ë¡œ ì˜ ìƒì„±ëœ ì´ë¯¸ì§€ì¸ì§€ í™•ì¸í•˜ê¸° ìœ„í•´, ê¸°ì¡´ì˜ ssh_containerì™€, docker101 ì´ë¯¸ì§€ë¥¼ ì‚­ì œí•©ë‹ˆë‹¤. 123456$ docker stop ssh_containerssh_container$ docker rm ssh_containerssh_container$ docker rmi docker101Untagged: docker101:latest ê·¸ë¦¬ê³  ìƒì„±í•œ ssh_machine_learning ì´ë¯¸ì§€ë¡œ ì»¨í…Œì´ë„ˆë¥¼ ìƒì„±í•˜ê³  í™•ì¸í•©ë‹ˆë‹¤. happy_corië¼ëŠ” ì´ë¦„ì˜ ì»¨í…Œì´ë„ˆë¡œ ìƒì„±ì´ ë˜ì–´ìˆìŠµë‹ˆë‹¤. 12345$ docker run -d --cap-add=NET_ADMIN --cap-add=NET_RAW -p 8888:8888 -p 22022:22 ssh_machine_learninge3f1a95dc804632ed1802c17c90b44046f13301a261d06ebd48dcd7cb8f57447$ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES292970ce1cff ssh_machine_learning \"/tini -- /bin/sh -câ€¦\" 3 seconds ago Up 2 seconds 0.0.0.0:8888->8888/tcp, 0.0.0.0:22022->22/tcp happy_cori happy_corië¡œ exec ì ‘ì†ì„ í•´ì„œ SSH Serverë¥¼ ì‹œì‘ì‹œí‚µë‹ˆë‹¤. 123$ docker exec -it happy_cori /bin/bash[work] # service ssh start * Starting OpenBSD Secure Shell server sshd [ OK ] ìœ„ì— ë‚˜ì™”ë˜ ê°™ì€ ë°©ì‹ìœ¼ë¡œ, SSH ì ‘ì†ì„ í•´ë´…ë‹ˆë‹¤.íŒì½˜ì¤€ë¹„ğŸŸ Dealing with an Error ì•„, ì§€ê¸ˆ ì €ì²˜ëŸ¼ ê°™ì€ PCë¡œ ì ‘ì†ì„ í•˜ì‹ ë‹¤ë©´ ì•„ë§ˆë„.. 123456789 @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ @ WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED! @ @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ IT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY!ì–´ì©Œêµ¬ì €ìµ¸êµ¬.....Add correct host key in /Users/chayesol/.ssh/known_hosts to get rid of this message.... ì´ëŸ° ë©‹ì§„ ì¹œêµ¬ë¥¼ ë¨¼ì € ë§Œë‚˜ê²Œ ë  ê²ƒì…ë‹ˆë‹¤. ê·¸ë„ ê·¸ëŸ´ë§Œí•œ ê²ƒì´, ì ‘ì†ì„ í•˜ë ¤ëŠ” PC ì…ì¥ì—ì„œëŠ” ë˜‘ê°™ì€ IPë¡œ ì ‘ì†ì„ í•˜ë ¤ê³  í•˜ëŠ”ë°, ì „í˜€ ë‹¤ë¥¸ Serverì¸ë°??ë¼ê³  í•˜ë©´ì„œ 'ë­ëƒì´ê±°'ë¼ê³  ì •ìƒ‰ì„ í•˜ëŠ” ê²ƒì´ì£ . ì´ëŸ´ ê²½ìš°, PCê°€ ê°€ì§€ê³  ìˆë–¤ ssh-keyë¥¼ ì•„ì˜ˆ ì´ˆê¸°í™”ì‹œì¼œì£¼ëŠ”, 1$ ssh-keygen -R YOUR.IP.ADDR.ESS ë¥¼ ì‹¤í–‰í•œ ë’¤ì— ë‹¤ì‹œ í•˜ë©´ ëœë‹¤ëŠ” ë¶„ë“¤ì´ ê³„ì‹œê³ , ì €ê°™ì€ ê²½ìš° ì´ ë°©ë²•ì´ ì•ˆë¨¹í˜€ì„œ ì—ëŸ¬ ë©”ì„¸ì§€ í•˜ë‹¨ì¯¤ì— ì¹œì ˆíˆ ì í˜€ ìˆëŠ” /Users/chayesol/.ssh/known_hostsì„ íŒŒì¼ì„ ì—´ê³  í•´ë‹¹ IPë¥¼ ì§€ì›Œë²„ë ¸ìŠµë‹ˆë‹¤. ê·¸ë¦¬ê³ ë‚˜ì„œ ë‹¤ì‹œ, ë„ì¦ˆì–¸ğŸŠ í•˜ë‹ˆ ì˜ ë˜ë„¤ìš”! 123456789101112131415161718192021222324$ ssh -p 22022 root@172.16.8.236The authenticity of host '[172.16.8.236]:22022 ([172.16.8.236]:22022)' can't be established.ECDSA key fingerprint is SHA256:XFFyjB4g0y4cJzd08AV2nDfxGxzcm8qBoS5n7VRc9fo.Are you sure you want to continue connecting (yes/no)? yesWarning: Permanently added '[172.16.8.236]:22022' (ECDSA) to the list of known hosts.root@172.16.8.236's password: Welcome to Ubuntu 18.04.2 LTS (GNU/Linux 4.9.125-linuxkit x86_64) * Documentation: https://help.ubuntu.com * Management: https://landscape.canonical.com * Support: https://ubuntu.com/advantageThis system has been minimized by removing packages and content that arenot required on a system that users do not log into.To restore this content, you can run the 'unminimize' command.The programs included with the Ubuntu system are free software;the exact distribution terms for each program are described in theindividual files in /usr/share/doc/*/copyright.Ubuntu comes with ABSOLUTELY NO WARRANTY, to the extent permitted byapplicable law.[~] # ì´ìƒìœ¼ë¡œ 3ë²ˆì— ê±¸ì¹œ Docker Tutorialì„ ëª¨ë‘ ë§ˆì¹˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.ì½ì–´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤. ğŸ™‡ References ruo91 - GitHub Gist dockerì˜ ubuntu containerì— sshë¡œ ì ‘ì†í•˜ê¸° HOW TO CREATE A DOCKER IMAGE FROM A CONTAINER document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","link":"/2019/05/25/docker-103/"},{"title":"Hi, Docker! :) (1)","text":"Introduction to Docker. Docker ê°œë…, ì„¤ì¹˜, ìœ ìš©í•œ ëª…ë ¹ì–´ ì‚¬ìš©í•´ë³´ê¸°. Docker? ğŸ˜¶ ê·€ì—¬ìš´ ê³ ë˜ ì•„ì´ì½˜ğŸ³ìœ¼ë¡œ ë§ì€ ì‚¬ë‘ì„ ë°›ê³  ìˆëŠ” Dockerì— ëŒ€í•´ ê°„ë‹¨íˆ ì•Œì•„ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. DockerëŠ” ê¸°ì¡´ì˜ Virtual Machineë“¤ê³¼ ê°™ì´ Host OS ìœ„ì— Guest OSë¥¼ ì˜¬ë¦¬ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ë³„ë„ì˜ OSë¥¼ ë§Œë“¤ì§€ ì•Šê³  ë‹¨ìˆœíˆ í”„ë¡œì„¸ìŠ¤ë§Œ ê²©ë¦¬ì‹œì¼œì„œ ë™ì‘í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤. ê·¸ë˜ì„œ í›¨ì”¬ ë” ë¹ ë¥´ê²Œ ê°€ìƒí™˜ê²½ì„ ì¦ê¸¸ ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤! ê·¸ë˜ì„œ CPUë‚˜ ë©”ëª¨ë¦¬ëŠ” í”„ë¡œì„¸ìŠ¤ê°€ í•„ìš”í•œ ë§Œí¼ë§Œ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì— ì„±ëŠ¥ë„ ì‹¤ì œ Hostì—ì„œ ëŒì•„ê°€ëŠ” ë‹¤ë¥¸ Processë“¤ê³¼ ë¹„êµí•´ì„œ í° ì°¨ì´ê°€ ì—†ë‹µë‹ˆë‹¤. ğŸ˜‰ Container ì•ˆì— ë‹¤ ìˆì–´ìš”! Dockerê°€ í•«í•œ ì´ìœ ëŠ” ì´ê²Œ ë‹¤ê°€ ì•„ë‹ˆê² ì£ . ë¨¸ì‹ ëŸ¬ë‹ì„ ìœ„í•œ í™˜ê²½êµ¬ì¶•ì„ í•´ë³´ì‹  ë¶„ë“¤ì€ ë‹¤ë“¤ ê³µê°í•˜ì‹¤ ìˆ˜ ë¹¡ì³ ë³´ì‹  ì ğŸ‘¿ìˆìœ¼ì‹¤ ê²ë‹ˆë‹¤. ë‚´ê°€ ê·¸ë ‡ê²Œ ìˆ˜ë§ì€ ì—ëŸ¬ë“¤ê³¼ StackOverflowë¥¼ í—¤ë§¤ê°€ë©° ì„¤ì •í•œ ê·¸ í™˜ê²½ ë§ì´ì£ . (Anarconda + Tensorflow + Pytorch + R + R Studio + cuDNN + ì˜¨ê°– Python Packages + ë“±ë“±..) ì´ì œ Dockerë¥¼ ì“°ë©´, ê·¸ë ‡ê²Œ ë§Œë“  í™˜ê²½ì„ Dockerê³„ì˜ Githubì¸ Docker Hubì— Imageí™” í•œ ë’¤ ì˜¬ë¦¬ë©´, ì–´ë””ì„œë‚˜ ë°›ì•„ì„œ ì“¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ ë‚¨ë“¤ì´ ì—´ì‹¬íˆ ë§Œë“¤ì–´ì„œ ê³µìœ í•´ ì¤€, ì¸ì„± ê±°ì˜ ì‚°íƒ€ğŸ… í™˜ê²½ì„ ë°›ì•„ í¸í•˜ê²Œ ì“¸ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ë„ˆë¬´ ì¢‹ì£ ? ê·¸ë ‡ê²Œ ê³µìœ í•˜ëŠ” (Githubì˜ Private Repositoryì²˜ëŸ¼ Docker Hubì—ë„ Privateê³„ì •ì„ ì œê³µí•©ë‹ˆë‹¤.) íŒŒì¼ì„ Imageë¼ê³  í•˜ê³ , ê·¸ Imageë¥¼ ë°›ì•„ì„œ ìƒì„±í•˜ê²Œ ë˜ëŠ” í•˜ë‚˜í•˜ë‚˜ì˜ Process ê°€ìƒí™˜ê²½ì„ ìš°ë¦¬ëŠ” Containerë¼ê³  ë¶€ë¦…ë‹ˆë‹¤. Dockerë¼ëŠ” ì´ë¦„ì— ê±¸ë§ê²Œ í•­ë§Œì—ì„œ ìˆ˜ë§ì€ ì»¨í…Œì´ë„ˆë“¤ì´ ê³µìœ ë˜ëŠ” í™˜ê²½ì´ Docker Hubì´ë¼ê³  ìƒê°í•˜ì‹œë©´ ë˜ê² ë„¤ìš”. ê·¸ëŸ¼ ì´ì œ Dockerë¥¼ ì„¤ì¹˜í•´ ë³´ì‹¤ê¹Œìš”! InstallationLinux Ubuntu í™˜ê²½ë§Œ ì„¤ëª…í•˜ìë©´, ì•„ë˜ì™€ ê°™ì€ ëª…ë ¹ì–´ë¡œ ê°„í¸í•˜ê²Œ ì„¤ì¹˜ í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ëª…ë ¹ì–´ ìœ„ì— ì£¼ì„ì²˜ë¦¬ëœ ë¶€ë¶„ì€ 2019ë…„ 5ì›” í˜„ì¬ Ubuntu í™˜ê²½ì˜ Prerequisitesì´ë‹ˆ ì°¸ê³ í•˜ì„¸ìš” :) 12345678# OS requirements# To install Docker CE, you need the 64-bit version of one of these Ubuntu versions:# Cosmic 18.10# Bionic 18.04 (LTS)# Xenial 16.04 (LTS)$ sudo apt-get update$ sudo apt-get install docker-ce docker-ce-cli containerd.io ë‹¤ë¥¸ Linux í™˜ê²½ì€ ì—¬ê¸°ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”. Mac & Windows Macê³¼ Windows í™˜ê²½ì€ ë‹¤ìŒê³¼ ê°™ì€ ê¸°ì¤€ì— ë”°ë¼ ì„¤ì¹˜ ë°©ë²•ì´ ë‘ ê°€ì§€ë¡œ ë‚˜ëˆ„ì–´ ì§‘ë‹ˆë‹¤. Windows: Windows 10 Pro ì´ìƒ ëª¨ë¸ (10 Home ì•ˆë¨) â†’ Docker for WindowsMac: OSê°€ Sierra 10.12 í˜¹ì€ ê·¸ ì´ìƒ â†’ Docker for Mac Windows & Mac: 1ë²ˆ ì¡°ê±´ì„ ë§Œì¡±í•˜ì§€ ëª»í•˜ëŠ” ê²½ìš° â†’ Docker ToolBox ì°¸ê³  ì‚¬í•­ ê¸°ë³¸ì ìœ¼ë¡œ Dockerì— íšŒì›ê°€ì…ì„ í•˜ì‹œê³  IDë¥¼ ìƒì„±í•˜ì…”ì•¼ ì„¤ì¹˜ íŒŒì¼ì„ ë‹¤ìš´ì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. Windowsì—ì„œëŠ” [ì‘ì—… ê´€ë¦¬ì > ì„±ëŠ¥] ì— ë“¤ì–´ê°€ \"ê°€ìƒí™” : ì‚¬ìš©\" ì„ í™•ì¸ì„ í•˜ì‹œê³  ì•ˆë˜ì–´ìˆë‹¤ë©´, í™œì„±í™”ë¥¼ í•´ì¤˜ì•¼ í•©ë‹ˆë‹¤. ê°œì¸ì ì¸ ê²½í—˜ìƒ, Windows í™˜ê²½ì—ì„œ 1ë²ˆì˜ í™˜ê²½ì´ ì¶©ì¡±ë˜ì–´ Docker for Windowsë¥¼ ì„¤ì¹˜í•˜ì˜€ëŠ”ë°ë„, Linux Containerë¡œ Switchë¥¼ ëª»í•œë‹¤ ë˜ê°€ í•˜ëŠ” ì—ëŸ¬ê°€ ë°œìƒë˜ì–´ ì‚¬ìš©ì´ í˜ë“¤ ë•Œ$\\to$ ê·¸ëƒ¥ 2ë²ˆìœ¼ë¡œ Docker ToolBoxë¥¼ ì„¤ì¹˜í•˜ê³ , Docker Quickstart Terminalì„ ì‚¬ìš©, Dockerë¥¼ ì‹¤í–‰í•˜ê¸°ë„ í–ˆìŠµë‹ˆë‹¤. ë˜ê¸°ë§Œí•˜ë©´ ì¥ë•¡ì´ë‹ˆê¹Œìš” ì„¤ì¹˜ í™•ì¸ docker version ì´ë¼ê³  Terminalì— ì³¤ì„ ë•Œ, ì•„ë˜ì™€ ê°™ì´ version ì •ë³´ê°€ ì˜ ë‚˜ì˜¨ë‹¤ë©´ ì„¤ì¹˜ê°€ ì˜ ëœ ê²ƒì…ë‹ˆë‹¤. :) 123456789101112131415161718Client: Docker Engine - Community Version: 18.09.2 API version: 1.39 Go version: go1.10.8 Git commit: 6247962 Built: Sun Feb 10 04:12:39 2019 OS/Arch: darwin/amd64 Experimental: falseServer: Docker Engine - Community Engine: Version: 18.09.2 API version: 1.39 (minimum version 1.12) Go version: go1.10.6 Git commit: 6247962 Built: Sun Feb 10 04:13:06 2019 OS/Arch: linux/amd64 Experimental: true Docker versionì„ í™•ì¸í•´ë³´ë‹ˆ, Client-Serverë¡œ ë‚˜ë‰˜ì–´ì ¸ ìˆëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. Dockerê°€ ì‹¤ì œë¡œ ì–´ë–»ê²Œ ë™ì‘í•˜ëŠ”ì§€ ë³¼ ìˆ˜ ìˆëŠ” ë¶€ë¶„ì…ë‹ˆë‹¤. ğŸ˜‰ ì‚¬ìš©ìê°€ Docker ëª…ë ¹ì„ ë‚´ë¦¬ë©´ Clientì—ì„œ ê¸°ë³¸ì ìœ¼ë¡œ Docker Serverë¥¼ ë°”ë¼ë³´ê³  ìˆê¸° ë•Œë¬¸ì—, ì‚¬ìš©ìëŠ” ë°”ë¡œ ëª…ë ¹ë§Œ ë‚´ë¦° ê²ƒ ê°™ì§€ë§Œ, ì‹¤ì œë¡œëŠ” Serverê°€ Clientë¡œ ë¶€í„° ì „ì†¡ì„ ë°›ì•„, ì²˜ë¦¬í•œ ê²°ê³¼ë¥¼ ë‹¤ì‹œ Clientì—ê²Œ ëŒë ¤ì£¼ê³  ìˆëŠ” ê²ƒì´ì£ . ì, ì´ì œ ì„¤ì¹˜ë¥¼ ì˜ ë§ˆì³¤ìœ¼ë©´ ë³¸ê²©ì ìœ¼ë¡œ Dockerë¥¼ ì‚¬ìš©í•´ ë³¼ê¹Œìš”? Practice ì•„ë˜ì™€ ê°™ì€ ìˆœì„œë¡œ ì‹¤ìŠµì„ í•˜ë©´ì„œ í•„ìš”í•œ ëª…ë ¹ì–´ë“¤ì„ ì •ë¦¬í•´ ë³´ê² ìŠµë‹ˆë‹¤ ğŸ˜‰ 1231. Anacondaê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ” Ubuntu Imageë¥¼ ë‹¤ìš´ë°›ê¸°. 2. ê·¸ ì´ë¯¸ì§€ë¡œ ìƒì„±í•œ ì»¨í…Œì´ë„ˆì—ì„œ Jupyter notebookì„ ë„ì›Œë†“ê¸°.3. Host Browserë¡œ ì ‘ê·¼í•´ì„œ ì‚¬ìš©. 1. ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ í•˜ê¸° (pull, images) Docker Hubì— ì ‘ì†í•´ì„œ jupyter-python3ë¡œ ê²€ìƒ‰ì„ í•˜ë‹ˆ, ì²œë§Œ ë‹¤ìš´ë¡œë“œì— ë¹›ë‚˜ëŠ” ì´ë¯¸ì§€ê°€ ë‚˜ì˜¤ë„¤ìš”. ì•„ë˜ì˜ ëª…ë ¹ì–´ë¥¼ ì…ë ¥í•˜ë©´, Anaconda3ë¥¼ í’ˆì€ Ubuntu 18.04 Imageë¥¼ ë‹¤ìš´ë¡œë“œ ë°›ê²Œ ë©ë‹ˆë‹¤. ë‹¤ìš´ë¡œë“œì— ì•½ê°„ì˜ ì‹œê°„ì´ ì†Œìš”ë©ë‹ˆë‹¤. 1$ docker pull civisanalytics/civis-jupyter-python3 ë³´ì‹œë‹¤ì‹œí”¼, ê¸°ë³¸ì ìœ¼ë¡œ Docker ëª…ë ¹ì–´ëŠ” dockerë¡œ ì‹œì‘í•˜ê³ , Gitì„ ì“°ì‹  ë¶„ë“¤ì€ ìµìˆ™í•œ ë‹¨ì–´ì´ì‹¤ pullì´ë¼ëŠ” ëª…ë ¹ì–´ë¡œ ì›í•˜ëŠ” ì´ë¯¸ì§€ë¥¼ ê°€ì ¸ ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê°€ì ¸ì˜¨ ì´ë¯¸ì§€ëŠ” ëª…ë ¹ì–´ 1$ docker images ë¥¼ í†µí•´ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 2. ì»¨í…Œì´ë„ˆ ëª©ë¡ ì¡°íšŒ & ì‚­ì œ (ps, rm, stop) ì»¨í…Œì´ë„ˆ ì‹¤ìŠµì— ì•ì„œì„œ, ê¹”ë”í•œ ì§„í–‰ì„ ìœ„í•´ í˜„ì¬ Docker ì„¤ì¹˜ì‹œì— Defaultë¡œ ê°€ì§€ê³  ìˆëŠ” ì»¨í…Œì´ë„ˆë“¤ì„ í•œ ë²ˆ ì‹¹ ë¹„ìš°ê³  ì‹œì‘í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤ğŸ˜. ì•„ë˜ ëª…ë ¹ì–´ë¥¼ ì…ë ¥í•˜ì‹œë©´ í˜„ì¬ ë©ˆì¶°ìˆëŠ” ì»¨í…Œì´ë„ˆê¹Œì§€ í¬í•¨í•œ ëª©ë¡ë“¤ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 1$ docker ps -a docker psëŠ” í˜„ì¬ ë™ì‘í•˜ê³  ìˆëŠ” ì»¨í…Œì´ë„ˆë¥¼ ëª¨ë“  ì»¨í…Œì´ë„ˆë“¤ì„ ì¡°íšŒí•˜ëŠ” ëª…ë ¹ì–´ ì…ë‹ˆë‹¤. -a ì˜µì…˜ì€ ë©ˆì¶˜ ì»¨í…Œì´ë„ˆê¹Œì§€ ëª¨ë‘ ì¡°íšŒí•©ë‹ˆë‹¤. ì•„ì§ ì»¨í…Œì´ë„ˆ ìƒì„±ì€ í•˜ì§€ë„ ì•ŠëŠ”ë° ëª©ë¡ì— ë©ˆì¶°ìˆëŠ” ë‹¤ë¥¸ ì»¨í…Œì´ë„ˆë“¤ì´ ë³´ì´ì‹¤ ê²ƒì…ë‹ˆë‹¤. ë‹¤ ì§€ì›Œë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.ğŸ˜ˆ 1$ docker rm $(docker ps -a -q) docker rmëŠ” ë©ˆì¶°ìˆëŠ” ì»¨í…Œì´ë„ˆë¥¼ ì‚­ì œí•˜ëŠ” ëª…ë ¹ì´ê³ , -q ì˜µì…˜ì€, PORT, STATUS, NAMEë“±ì˜ ì •ë³´ëŠ” ì œì™¸í•˜ê³  ì»¨í…Œì´ë„ˆ IDë§Œ í™•ì¸í•˜ê²Œ í•´ì£¼ëŠ” ì˜µì…˜ì…ë‹ˆë‹¤. ë”°ë¼ì„œ ë°”ë¡œ ìœ„ì—ì„œ ë°°ì› ë˜ docker ps -a -qì˜ ê²°ê³¼ë¡œ ë‚˜ì˜¤ëŠ” IDì— í•´ë‹¹í•˜ëŠ” ëª¨ë“  ì»¨í…Œì´ë„ˆë“¤ì„ ì‚­ì œí•´ë¼ëŠ” ëª…ë ¹ì´ ë©ë‹ˆë‹¤. ì»¨í…Œì´ë„ˆê°€ ì•„ë‹ˆë¼ ì´ë¯¸ì§€ë¥¼ ì‚­ì œí•˜ê³  ì‹¶ìœ¼ë©´ docker rmië¡œ ië§Œ ì¶”ê°€í•´ì£¼ì„¸ìš”! í˜¹ì‹œ ì»¨í…Œì´ë„ˆê°€ ì •ì§€ ìƒíƒœê°€ ì•„ë‹Œë° docker rm container_IDë¥¼ ì‹¤í–‰í•˜ì‹œë©´ í•´ë‹¹ ì»¨í…Œì´ë„ˆëŠ” ì‚­ì œë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë¨¼ì € docker stop container_IDë¡œ ì‚­ì œí•˜ê³ ì í•˜ëŠ” ì»¨í…Œì´ë„ˆì˜ ë™ì‘ì„ ë©ˆì¶˜ ë’¤ì— ì‹¤í–‰í•´ì•¼í•©ë‹ˆë‹¤. 3. ì»¨í…Œì´ë„ˆ ìƒì„± & í¬íŠ¸ ì„¤ì • & ì´ë¦„ì§€ì–´ì£¼ê¸° (run -p, â€“name) ì´ì œ ìš°ë¦¬ê°€ ì‚¬ìš©í•  ìš°ë¶„íˆ¬ ì»¨í…Œì´ë„ˆë¥¼ ìƒì„±í•˜ê³  ì ‘ì†í•´ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. 123$ docker run -it --name docker101 \\ -p 8888:8888 civisanalytics/civis-jupyter-python3 \\ /bin/bash runëª…ë ¹ì–´ë¡œ, ê°€ì§€ê³  ì´ë¯¸ì§€ë¥¼ ì‹¤í–‰í•˜ë¼ê³  í•˜ë©´ì„œ -it ì˜µì…˜ì„ ì£¼ì–´ì„œ(-tië„ ê°™ìŠµë‹ˆë‹¤) í„°ë¯¸ë„(t)ì— ì…ë ¥(i) ì„ ë°›ì„ ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤. -iì™€ -tì˜µì…˜ì„ í•¨ê»˜ ì“´ ê±°ì£ . ì œì¼ ë§ˆì§€ë§‰ì— í„°ë¯¸ë„ì˜ ê²½ë¡œë¥¼ /bin/bash ë¡œ ì „ë‹¬í•´ì¤ë‹ˆë‹¤. --name ì˜µì…˜ì„ ì¤˜ì„œ ì›í•˜ëŠ” ì´ë¦„ì„ ë¶€ì—¬í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ì´ë¦„ì„ ë”°ë¡œ ì£¼ì§€ ì•Šìœ¼ë©´ ìœ ëª…í•œ ê³¼í•™ìì˜ ì´ë¦„ì— ìˆ˜ì‹ì–´ë¥¼ ë¶™ì—¬ì„œ ëœë¤ìƒì„±í•©ë‹ˆë‹¤.(ì¥ì˜ì‹¤ë„ í¬í•¨ë˜ì–´ìˆë‹¤ê³  í•˜ë„¤ìš”!) -p ì˜µì…˜ì€ í¬ì›Œë”© í•´ì¤„ portë²ˆí˜¸ë¥¼ ì˜ë¯¸í•˜ëŠ”ë°ìš”, ì•ì— 8888ì€ í˜¸ìŠ¤íŠ¸ port, ë’¤ì˜ 8888ì€ ì»¨í…Œì´ë„ˆ portë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤. ì ‘ì†ì´ ì˜ ë˜ì—ˆë‹¤ë©´ ì•„ë˜ì™€ ê°™ì´ sudo modeë¡œ rootê¶Œí•œì„ ê°€ì§„ ìƒíƒœì˜ bashë¥¼ ì“¸ ìˆ˜ ìˆê²Œ ëìŠµë‹ˆë‹¤! ê°„ë‹¨í•œ ls -aì´ë‚˜ pwdê°™ì€ ëª…ë ¹ì–´ë“¤ë¡œ ê°€ìƒí™˜ê²½ Ubuntuë¥¼ ëŠê»´ë³´ì„¸ìš”.ğŸ˜. apt updateë¡œ ìš°ë¶„íˆ¬ë¥¼ ì—…ë°ì´íŠ¸ í•´ì¤ë‹ˆë‹¤. 1$ [work] # apt update ì‚¬ì‹¤ runëª…ë ¹ì–´ëŠ” ì‹¤í–‰í•˜ë¼ê³  í•œ ì´ë¯¸ì§€ê°€ ë¡œì»¬ì— ì—†ì„ ê²½ìš°, ê°€ì¥ ìµœì‹  ë²„ì „ìœ¼ë¡œ ë‹¤ìš´ì„ ë°›ê¸° ë•Œë¬¸ì—, ì´ë¯¸ì§€ë¥¼ ë‹¤ìš´ë°›ìœ¼ë©´ì„œ ë™ì‹œì— ì»¨í…Œì´ë„ˆë¥¼ ë§Œë“œëŠ” ëª…ë ¹ì–´ì´ê¸°ë„ í•©ë‹ˆë‹¤. í•˜ì§€ë§Œ, í•œ ë²ˆ ë‹¤ìš´ ë°›ê³  ë‚œ ë’¤ì—ëŠ” í•´ë‹¹ ì´ë¯¸ì§€ê°€ ì—…ë°ì´íŠ¸ê°€ ë˜ì–´ë„ ê°€ì§€ê³  ìˆëŠ” ì´ë¯¸ì§€ë§Œ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì—, ê°€ì¥ ìµœì‹  ë²„ì „ì„ ë‹¤ìš´ ë°›ê²Œ í•´ì£¼ëŠ” pullë„ ë©”ë¦¬íŠ¸ê°€ ìˆëŠ” ê²ƒì´ì£ . ë‹¤ì‹œ ë³¸ë¡ ìœ¼ë¡œ ëŒì•„ì™€, ì ‘ì†í•œ ì»¨í…Œì´ë„ˆ ìš°ë¶„íˆ¬ í™˜ê²½ì—ì„œ pythonì„ ì…ë ¥í•´ë³´ë©´, Acaconda3-python 3.7ì´ ì„¤ì¹˜ ë˜ì–´ìˆìŒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¡œì¨ Anacondaë¥¼ ì„¤ì¹˜í•œ ì ë„ ì—†ì§€ë§Œ, ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” í™˜ê²½ì„ Getí•˜ê²Œ ëìŠµë‹ˆë‹¤.ğŸ˜Š 12345[work] # pythonPython 3.7.1 | packaged by conda-forge | (default, Feb 18 2019, 01:42:00) [GCC 7.3.0] :: Anaconda, Inc. on linuxType \"help\", \"copyright\", \"credits\" or \"license\" for more information.>>> ì´ ìƒíƒœì—ì„œ jupyter notebookì„ ë°”ë¡œ ì‹¤í–‰ì„ ì‹œí‚¬ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ë‹¤ë¥¸ ëª…ë ¹ì–´ë“¤ì„ ë” ìµíˆê¸° ìœ„í•´ exitë¡œ ì¼ë‹¨ ë‚˜ì˜¤ë„ë¡ í•©ë‹ˆë‹¤. 4. ì»¨í…Œì´ë„ˆ ì‹œì‘, ëª…ë ¹ì–´ ì‹¤í–‰ì‹œí‚¤ê¸° (start, exec -d) Jupyter notebookì„ ì‹¤í–‰ì‹œí‚¤ë„ë¡ í•´ë³´ê² ìŠµë‹ˆë‹¤! ë¨¼ì € docker ps -aì„ ì…ë ¥í•´ì„œ, ë°©ê¸ˆ ë‚˜ì™”ë˜ ì»¨í…Œì´ë„ˆì˜ ì´ë¦„ì„ í™•ì¸í•´ë´…ë‹ˆë‹¤. exitëª…ë ¹ì–´ë¡œ í™˜ê²½ì„ ë‚˜ì˜¤ë©´, ê¸°ë³¸ì ìœ¼ë¡œ ì»¨í…Œì´ë„ˆëŠ” Stopped(Exited)ì¸ ìƒíƒœì…ë‹ˆë‹¤. 123chayesol-ui-MacBook-Pro:Blog chayesol$ docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES57ca32782e7e civisanalytics/civis-jupyter-python3 \"/tini -- /bin/bash\" 9 minutes ago Exited (0) 6 minutes ago docker101 ì œê°€ ìƒì„±í•  ë•Œ ì´ë¦„ìœ¼ë¡œ ì£¼ì—ˆë˜ docker101ì´ ì´ë¦„ìœ¼ë¡œ ì˜ ë³´ì´ë„¤ìš”! ì´ ì»¨í…Œì´ë„ˆëŠ” ì§€ê¸ˆ Stopped ìƒíƒœ(Exited)ì´ê¸° ë•Œë¬¸ì— ìƒˆë¡œ ë™ì‘ì„ ì‹œì¼œ ì¤˜ì•¼í•©ë‹ˆë‹¤. docker startëª…ë ¹ì–´ë¡œ ë‹¤ì‹œ ì‘ë™ì‹œí‚¨ ë’¤, Jupyter notebookì„ ì‹¤í–‰í•©ë‹ˆë‹¤. 123$ docker start docker101$ docker exec docker101 jupyter notebook \\ --ip=0.0.0.0 --port=8888 --allow-root exec ëª…ë ¹ì–´ëŠ” í•´ë‹¹ ì»¨í…Œì´ë„ˆ ì´ë¦„(or ID) ë’¤ì— ë‚˜ì—´ëœ ëª…ë ¹ì–´ë“¤ì„ ì‹¤í–‰í•˜ê²Œ í•´ì¤ë‹ˆë‹¤. ipëŠ” 0.0.0.0ìœ¼ë¡œ ë¡œì»¬í˜¸ìŠ¤íŠ¸ë¥¼ ì§€ì¹­í•˜ê³ , í¬íŠ¸ëŠ” ìš°ë¦¬ê°€ ì»¨í…Œì´ë„ˆ ìƒì„±í•  ë•Œ ì‘ì„±í•œ 8888ë¡œ ì£¼ì—ˆìŠµë‹ˆë‹¤. ì‹¤í–‰ í›„, ë‚˜ì˜¤ëŠ” tokenê°’ì„ ë³µì‚¬í•œ ë’¤, í˜¸ìŠ¤íŠ¸ì˜ ë¸Œë¼ìš°ì € ì°½ì— localhost:8888ì„ ì…ë ¥í•˜ì‹œë©´ tokenì„ ì ê²Œ ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ê·¸ ê²°ê³¼, ì•„ë˜ì™€ ê°™ì´ ìš°ë¦¬ëŠ” ì»¨í…Œì´ë„ˆì— ìˆëŠ” Jupyter notebookì„ ë„ì»¤ë¥¼ í†µí•´ ë¡œì»¬í˜¸ìŠ¤íŠ¸ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤!ğŸ˜† exec -d? execëª…ë ¹ì„ ì¤„ ë•Œ, -dì˜µì…˜ì„ ì¶”ê°€í•˜ë©´, detached mode, ì¦‰ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì»¨í…Œì´ë„ˆê°€ ì‹¤í–‰ë˜ë„ë¡ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (-dì˜µì…˜ì€ runì—ë„ ì“¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.) ìš°ë¦¬ ì˜ˆì‹œì—ì„œëŠ” ë³´ì•ˆìƒ Jupyter notebookì˜ tokenì„ ì¶œë ¥ë°›ê³  ì‚¬ìš©í•´ì•¼í•˜ê¸° ë•Œë¬¸ì— -dì˜µì…˜ì„ ì‚¬ìš©í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë³´ì•ˆìƒ ê¶Œì¥ì‚¬í•­ì€ ì•„ë‹ˆì§€ë§Œ, exec -d ì˜µì…˜ì„ ì‚¬ìš©í•´ì„œ í¸í•˜ê³  ë¹ ë¥´ê²Œ, â€˜ê·€ì°®ì€ tokenì…ë ¥ ì—†ì´ jupyter notebookë§Œ ë‚´ê°€ ë„ìš°ê³  ì‹¶ë‹¤!â€™ í•˜ì‹œë©´ ì•„ë˜ì™€ ê°™ì€ ëª…ë ¹ì–´ë¥¼ ì‚¬ìš©í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. 1234$ docker exec -d docker101 \\ jupyter notebook --NotebookApp.token='' \\ --ip=0.0.0.0 --port=8888 --allow-root$ ì‹¤í–‰ í›„ì—ëŠ” ì•„ë¬´ ì¼ë„ ì—†ë‹¤ëŠ” ë“¯ì´ ê·¸ ë‹¤ìŒ lineì„ ì¶œë ¥í•˜ì§€ë§Œ, localhost:8888ë¡œ ì ‘ì†í•˜ì‹œë©´ ë˜‘ê°™ì´ Jupyter notebookì„ ì‚¬ìš©í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. 5. ì»¨í…Œì´ë„ˆ ì¬ì ‘ì† & ì¬ì‹œì‘ (attach, restart) Jupyter notebookì€ ì„±ê³µì ìœ¼ë¡œ ë„ì› ìœ¼ë‚˜, ì»¨í…Œì´ë„ˆì— ë‹¤ì‹œ ì ‘ì†í•´ì„œ íŒ¨í‚¤ì§€ë¥¼ ë” ì„¤ì¹˜í•˜ê±°ë‚˜ í™˜ê²½ì„ ì„¸íŒ…í•´ì¤˜ì•¼ í•  ê²½ìš°, ì¬ì ‘ì† í•˜ëŠ” ë°©ë²•ì€ exec ë¥¼ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ê³¼ attach ë¥¼ ì‚¬ìš©í•˜ëŠ” ë°©ë²•, ë‘ ê°€ì§€ê°€ ìˆìŠµë‹ˆë‹¤. ë˜ ë‹¤ë¥¸ Terminalì„ ë„ìš°ì‹  ë’¤ì—, 123$ docker exec -it container_name /bin/bashor$ docker attach container_name ë‘˜ ì¤‘ í•˜ë‚˜ë¥¼ ì…ë ¥í•˜ì‹œë©´ ë©ë‹ˆë‹¤! ì»¨í…Œì´ë„ˆë¥¼ ì¬ì‹œì‘ í•´ì£¼ê³  ì‹¶ì€ ê²½ìš°ëŠ” docker restart ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. 1$ docker restart contatiner_name ì´ìƒ, Dockerì˜ ê°œë…ê³¼ ì„¤ì¹˜, ê·¸ë¦¬ê³  ê°„ë‹¨í•œ ê¸°ë³¸ ëª…ë ¹ì–´ë“¤ì— ëŒ€í•´ ì•Œì•„ë³´ì•˜ìŠµë‹ˆë‹¤. ë‹¤ìŒ Hi, Docker!:) (2)ì—ì„œëŠ” ì»¨í…Œì´ë„ˆì™€ ë¡œì»¬ì €ì¥ì†Œ ì—°ê²°í•˜ê¸° ì™€ ë‚´ ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ë¡œ ì—…ë¡œë“œí•˜ê¸° ë¼ëŠ” ë‘ê°€ì§€ ì£¼ì œë¥¼ ë‹¤ë¤„ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤ ğŸ˜Œ References ì´ ê¸€ì€ ì•„ë˜ ë‘ ê¸€ì„ ê¸°ë°˜ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤ğŸ˜„. ë” ìì„¸í•œ ì •ë³´ëŠ” â†“ ì´ˆë³´ë¥¼ ìœ„í•œ ë„ì»¤ ì•ˆë‚´ì„œ - ë„ì»¤ë€ ë¬´ì—‡ì¸ê°€? ì´ˆë³´ë¥¼ ìœ„í•œ ë„ì»¤ ì•ˆë‚´ì„œ - ì„¤ì¹˜í•˜ê³  ì»¨í…Œì´ë„ˆ ì‹¤í–‰í•˜ê¸° document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","link":"/2019/04/24/docker-intro/"},{"title":"L1 & L2","text":"L1, L2 loss, regularization, and norm. Machine Learningì„ ê³µë¶€í•˜ê¸° ì‹œì‘í•˜ë©´, ê¼­ ë§ˆì£¼ì¹˜ëŠ” L1, L2. L1, L2 lossë¼ê³ ë„ í•˜ê³  L1, L2 Regularizationì´ë¼ê³ ë„ í•˜ëŠ”ë°, ëª…í™•íˆ ê·¸ ê°ê°ì˜ ê°œë…ê³¼ ê·¸ ì°¨ì´ë¥¼ ì§šê³  ë„˜ì–´ê°€ë ¤, Lossë¡œì¨ ì“°ì¼ ë•Œì™€ Regularizationìœ¼ë¡œì¨ ì“°ì¼ ë•Œë¥¼ ì •ë¦¬í•´ ë³´ì•˜ë‹¤. As an Error Function ëª¨ë¸ì˜ Loss, ì¦‰ Costë¥¼ êµ¬í•˜ëŠ” ë°©ë²•ìœ¼ë¡œ ì‚¬ìš©í•˜ê² ë‹¤ í•˜ë©´ L1, L2 loss functionì€ ì•„ë˜ì™€ ê°™ì€ ì‹ì„ ì‚¬ìš©í•œë‹¤. L1 lossL1 lossë¶€í„° ì‚´í´ë³´ë©´, ì‹ì—ì„œ ë³´ëŠ” ê²ƒê³¼ ê°™ì´ ì‹¤ì œ ê°’($y_i$)ê³¼, ì˜ˆì¸¡ê°’($f(x_i)$)ì˜ ê·¸ ì°¨ì´ê°’ì— ì ˆëŒ€ê°’ì„ ì·¨í•´, ê·¸ ì˜¤ì°¨ í•©ì„ ìµœì†Œí™”í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ lossë¥¼ êµ¬í•œë‹¤.Least Absolute Deviationsë¼ê³  í•˜ê³  ì¤„ì—¬ì„œ, LADë¼ê³  í•œë‹¤. $$L = \\sum\\limits_{i=1}^{n}|y_i - f(x_i)|$$ L2 lossL2 lossëŠ” MSE (Mean Sqaured Error)ë¥¼ ì•ˆë‹¤ë©´ ì•„ì£¼ ìµìˆ™í•œ ê°œë…ìœ¼ë¡œ, target valueì¸ ì‹¤ì œê°’($y_i$)ê³¼ ì˜ˆì¸¡ê°’($f(x_i)$) ì‚¬ì´ì˜ ì˜¤ì°¨ë¥¼ ì œê³±í•œ ê°’ë“¤ì„ ë‹¤ í•©í•´ì„œ Lossë¡œ ì‚°ì •í•œë‹¤.Least squares errorë¼ê³  í•˜ê³ , ì¤„ì—¬ì„œ LSEë¼ê³  í•œë‹¤. $$L = \\sum\\limits_{i=1}^n(y_i - f(x_i))^2$$ L1 lossì™€ L2 loss ë¹„êµ L1 lossì™€ L2 lossëŠ” ì•„ë˜ì™€ ê°™ì€ ì°¨ì´ì ì„ ê°€ì§€ê³  ìˆë‹¤. 1. Robustness: $$L1 > L2$$ ì—¬ê¸°ì„œ ë§í•˜ëŠ” RobustnessëŠ” outlier, ì¦‰ ì´ìƒì¹˜ê°€ ë“±ì¥í–ˆì„ ë•Œ, loss function ì–¼ë§ˆë‚˜ ì˜í–¥ì„ ë°›ëŠ”ì§€ë¥¼ ëœ»í•˜ëŠ” ìš©ì–´ë‹¤. L2 lossëŠ” outlierì˜ ì •ë„ê°€ ì‹¬í•˜ë©´ ì‹¬í•  ìˆ˜ë¡, ì§ê´€ì ìœ¼ë¡œ ì œê³±ì„ í•˜ê¸° ë•Œë¬¸ì— ê·¸ ê³„ì‚° ê°’ì´ L1ë³´ë‹¤ëŠ” ë” í° ìˆ˜ì¹˜ë¡œ ì‘ìš©ì„ í•  ìˆ˜ ë°–ì— ì—†ê¸° ë•Œë¬¸ì— Roubustnessì—ì„œ L1ë³´ë‹¤ ë” ê·¸ ì„±ì§ˆì´ ì‘ë‹¤ê³  ë§í•  ìˆ˜ ìˆë‹¤. ê·¸ë ‡ê¸° ë•Œë¬¸ì—, outliersê°€ íš¨ê³¼ì ìœ¼ë¡œ ì ë‹¹íˆ ë¬´ì‹œë˜ê¸¸ ì›í•œë‹¤ë©´, ë¹„êµì  ì´ìƒì¹˜ì˜ ì˜í–¥ë ¥ì„ ì‘ê²Œ ë°›ëŠ” L1 lossë¥¼, ë°˜ëŒ€ë¡œ, ì´ìƒì¹˜ì˜ ë“±ì¥ì— ì£¼ì˜ ê¹Šê²Œ ì£¼ëª©ì„ í•´ì•¼í•  í•„ìš”ê°€ ìˆëŠ” ê²½ìš°ë¼ë©´ L2 lossë¥¼ ì·¨í•˜ëŠ” ì„ íƒì„ í•  ìˆ˜ ìˆê² ë‹¤. 2. Stability: $$L1 < L2$$ StabilityëŠ” ëª¨ë¸ì´ ë¹„ìŠ·í•œ ë°ì´í„°ì— ëŒ€í•´ì„œ ì–¼ë§ˆë‚˜ ì¼ê´€ì ì¸ ì˜ˆì¸¡ì„ í•  ìˆ˜ ìˆëŠ”ê°€ ì •ë„ë¼ê³  ìƒê°í•˜ë©´ ëœë‹¤. ì´í•´ë¥¼ ë•ê¸° ìœ„í•´, ì•„ë˜ animationì„ ì°¸ê³ í•˜ì. ìœ„ ì• ë‹ˆë©”ì´ì…˜ ê·¸ë˜í”„ëŠ” ì‹¤ì œ ë°ì´í„°(ê²€ì€ ì )ì™€, Outlier pointì¸ ì£¼í™©ìƒ‰ ì ì´ ì›€ì§ì„ì— ë”°ë¼ì„œ ì–´ë–»ê²Œ ê·¸ ì˜ˆì¸¡ ëª¨ë¸ì´ ë‹¬ë¼ì§€ëŠ”ì§€ ì‹¤ì œë¡œ ì‹¤í—˜ì„ í•´ ë³¸ ê²°ê³¼ë‹¤. Outlier pointê°€ ê²€ì€ ì ë“¤ê³¼ ë¹„êµì  ë¹„ìŠ·í•œ ìœ„ì¹˜ì— ìœ„ì¹˜í•´ì„œ ëœ(?) ì´ìƒì¹˜ ì¼ë•Œ, L1 loss ê·¸ë˜í”„ëŠ” ë³€í™”ê°€ ìˆê³  ì›€ì§ì´ì§€ë§Œ, L2 loss ê·¸ë˜í”„ì—ëŠ” ì—†ë‹¤ëŠ” ê²ƒì„ ê´€ì°° í•  ìˆ˜ ìˆë‹¤. ì´ëŸ° ì„±ì§ˆì„ ë³´ê³  L1ì´ L2ë³´ë‹¤ëŠ” Unstableí•˜ë‹¤ê³  í‘œí˜„í•œë‹¤. ì´ ì• ë‹ˆë©”ì´ì…˜ì—ì„œ ìœ„ì—ì„œ ì‚´í´ë³¸ Robustnessë„ ì‚´ì§ ê´€ì°°í•  ìˆ˜ ìˆëŠ”ë°, Outlier pointê°€ ê²€ì€ ì ë“¤ì´ êµ¬ì„±í•˜ëŠ” ë³´ì´ì§€ ì•ŠëŠ” ì„ ì„ ê¸°ì¤€ìœ¼ë¡œ ë°–ì—ì„œ ì•ˆìœ¼ë¡œ ë“¤ì–´ì˜¬ ë•Œ, í™•ì‹¤íˆ L2 error lineì´ ë¨¼ì € ë°˜ì‘í•˜ëŠ” ê²ƒë„ ê´€ì°°í•  ìˆ˜ ìˆë‹¤. As Regularization Machine learningì—ì„œ Regularizationì€ Overfittingì„ ë°©ì§€í•˜ëŠ” ì¤‘ìš”í•œ ê¸°ë²•ì´ë‹¤. ê·¸ë˜ì„œ ìˆ˜ì‹ì ìœ¼ë¡œ L1, L2 Regularizationì„ ë§í•˜ìë©´, ëª¨ë¸ì„ êµ¬ì„±í•˜ëŠ” ê³„ìˆ˜(coefficients)ë“¤ì´ í•™ìŠµ ë°ì´í„°ì— ë„ˆë¬´ ì™„ë²½í•˜ê²Œ Overfitë˜ì§€ ì•Šë„ë¡, ê·¸ì € ì •ê·œí™” ìš”ì†Œ(regularization term)ë¥¼ ë”í•´ì£¼ëŠ” ê²ƒì´ë‹¤. L1 regularization$$cost(W, b) = \\frac{1}{m}\\sum\\limits_{i}^mL(\\hat y_i, y_i) + \\lambda\\frac{1}{2}|w|$$ L2 regularization$$cost(W, b) = \\frac{1}{m}\\sum\\limits_{i}^mL(\\hat y_i, y_i) + \\lambda\\frac{1}{2}|w|^2$$ ìœ„ì™€ ê°™ì´, ë”í•´ì£¼ëŠ” ì •ê·œí™” ìš”ì†Œë¡œ L1 errorë•Œ ë´¤ë˜ ì ˆëŒ€ê°’ì„ ì·¨í•˜ëŠ” ê¸°ë²•ì„ ì“°ëƒ, L2 errorì—ì„œì²˜ëŸ¼ ì œê³±ì„ ì·¨í•˜ëŠ” ê°’ì„ ì£¼ëƒì— ë”°ë¼ L1 ì •ê·œí™”ì´ëƒ L2 ì •ê·œí™”ë¡œ ë‚˜ë‰œë‹¤. ì•„ë˜ëŠ” ë”¥ëŸ¬ë‹ì—ì„œ ì“°ëŠ” Loss functionì— ê°ê°ì˜ ì •ê·œí™”ë¥¼ ì·¨í•œ ì‹ì´ë‹¤. $\\lambda$ëŠ” ì–¼ë§ˆë‚˜ ë¹„ì¤‘ì„ ì¤„ ê²ƒì¸ì§€ ì •í•˜ëŠ” ìƒìˆ˜ë‹¤. 0ì— ê°€ê¹Œìš¸ ìˆ˜ë¡ ì •ê·œí™”ì˜ íš¨ê³¼ëŠ” ì—†ì–´ì§„ë‹¤. ìš°ë¦¬ëŠ” ì ì ˆí•œ $\\lambda$ê°’ì„ k-fold cross validationê³¼ ê°™ì€ ë°©ë²•ìœ¼ë¡œ ì°¾ì„ ìˆ˜ ìˆë‹¤. L1, L2 Regularization ì°¨ì´ ë¹„êµ ë‘ ì •ê·œí™” ë°©ì‹ì—ëŠ” ì–´ë–¤ ì°¨ì´ì ì´ ìˆì„ê¹Œ? ìš°ì„  ê·¸ ì°¨ì´ë¥¼ í™•ì‹¤íˆ ì•Œê¸° ìœ„í•´ ì´ì œ ì–¸ê¸‰ë  Normì´ë¼ëŠ” ê°œë…ì— ëŒ€í•´ ì ê¹ ì–¸ê¸‰í•˜ê³  ë„˜ì–´ê°€ë„ë¡ í•˜ê² ë‹¤. Norm Normì€ ë²¡í„°ì˜ ê¸¸ì´ í˜¹ì€ í¬ê¸°ë¥¼ ì¸¡ì •í•˜ëŠ” ë°©ë²•(í•¨ìˆ˜)ì´ë‹¤. $$L_p = \\big(\\sum\\limits_i^n|x_i|^p\\big)^{\\frac{1}{p}}$$ $p$ëŠ” Normì˜ ì°¨ìˆ˜ë¥¼ ì˜ë¯¸í•œë‹¤. ë”°ë¼ì„œ, $p$ê°€ 1ì´ë©´ L1 normì´ê³ , $p$ê°€ 2ì´ë©´ L2 normì´ë‹¤. $n$ì€ ëŒ€ìƒ ë²¡í„°ì˜ ìš”ì†Œì˜ ìˆ˜ë‹¤. ë³´í†µ Normì€ $||x||_1$ í˜¹ì€ $||x||_2$ì™€ ê°™ì´ L1 Normì´ëƒ, L2 Normì´ëƒë¥¼ êµ¬ë³„í•˜ëŠ”ë°, ì•„ë¬´ëŸ° í‘œì‹œê°€ ì—†ëŠ” $||x||$ì™€ ê°™ì´ ì°¨ìˆ˜ê°€ ìƒëµì´ ë˜ì—ˆë‹¤ë©´, L2 Normì„ ì˜ë¯¸í•œë‹¤. Norm ê³„ì‚°ì˜ ê²°ê³¼ë¡œ ë‚˜ì˜¤ëŠ” ìˆ˜ì¹˜ëŠ” ì›ì ì—ì„œ ë²¡í„° ì¢Œí‘œê¹Œì§€ì˜ ê±°ë¦¬ê³ , Magnitudeë¼ê³  ë¶€ë¥¸ë‹¤. L1, L2 ì •ê·œí™”ëŠ” ì´ê°™ì€ L1, L2 Normì„ ì‚¬ìš©í•œ ê°’ì„ ë”í•´ì£¼ëŠ” ê²ƒì´ë‹¤. ê·¸ë˜ì„œ ì‹¤ì œë¡œ ë„ˆë¬´ Overfittingì´ ë°œìƒí•  ìˆ˜ ìˆëŠ” ê°€ëŠ¥ì„ ê°€ì§„ ìˆ˜ì¹˜ì— Penaltyë¥¼ ë¶€ì—¬í•œë‹¤ê³  ìƒê°í•˜ë©´ ëœë‹¤. 1. Solution uniqueness & Computational efficiency. $$L2$$ ë‹¤ì‹œ ë³¸ë¡ ìœ¼ë¡œ ëŒì•„ì™€ì„œ L1, L2 ì •ê·œí™”ì˜ ì°¨ì´ì ì„ ì•Œì•„ë³´ìë©´, L1, L2 ì •ê·œí™”ëŠ” L1, L2 Normì„ ê³„ì‚°í•¨ì— ìˆì–´ì„œ ì•„ë˜ì™€ ê°™ì€ íŠ¹ì§•ì„ ì§€ë‹ˆê²Œ ëœë‹¤. ì´ˆë¡ìƒ‰ì´ L2 Normì¸ë°, Squareì—°ì‚°ì— ì˜í•´ ìœ ì¼í•œ Shortest pathë¥¼ ê°€ì§€ëŠ” ë°˜ë©´, L1 Normì„ ì˜ë¯¸í•˜ëŠ” ë¹¨ê°•, íŒŒë‘, ë…¸ë‘ìƒ‰ pathë“¤ì€ ë‹¤ ê°™ì€ ê¸¸ì´ë¥¼ ê°€ì§€ì§€ë§Œ ì œê°ê° ë‹¤ë¥¸ ëª¨ì–‘ì„ í•˜ê³  ìˆë‹¤. ì´ëŸ° íŠ¹ì§• ë•Œë¬¸ì— Computational efficiencyì—ì„œëŠ” L2 Normì´ íš¨ìœ¨ì ì¸ ê³„ì‚°ëŸ‰ì„ ì œê³µí•œë‹¤ê³  ë³¼ ìˆ˜ ìˆë‹¤. 2. Sparsity & Feature Selection $$L1$$ $L1$ ì •ê·œí™”ì˜ Sparsityë¥¼ ì„¤ëª…í•˜ê¸° ìœ„í•´, ë‹¤ìŒê³¼ ê°™ì€ ë‘ Vectorê°€ ìˆë‹¤ê³  ìƒê°í•´ë³´ì. a = (0.25, 0.25, 0.25, 0.25)b = (-0.5, 0.5, 0.0, 0.0) ì´ ë‘ ë²¡í„°ì˜ $L1 \\text{ norm}$ì„ êµ¬í•˜ë©´, $||a||_1 = |0.25| + |0.25| + |0.25| + |0.25| = 1$ $||b||_1 = |-0.5| + |0.5| + |0.0| + |0.0| = 1$ ê³¼ ê°™ì´ ê°™ì€ 1ì´ë¼ëŠ” ìˆ«ìê°€ ë‚˜ì˜¤ì§€ë§Œ, $L2 \\text{ norm}$ì„ êµ¬í•˜ë©´, $||a||_2 = \\sqrt{0.25^2 + 0.25^2 + 0.25^2 + 0.25^2} = 0.5$ $||b||_2 = \\sqrt{(-0.5)^2 + (0.5)^2 + 0^2 + 0^2} = 0.707$ ê³¼ ê°™ì´ ë‹¤ë¥¸ ìˆ˜ê°€ ë‚˜ì˜¨ë‹¤. ì´ëŸ° L1ê³¼ L2ì˜ ì°¨ì´ì ì€ ìœ„ì—ì„œ ì‚´í´ë³¸ L2ì˜ Solution uniquenessì˜ ì„±ì§ˆê³¼ ë§ë¬¼ë ¤ ìƒê°í•  ìˆ˜ ìˆëŠ”ë°, L2ëŠ” ì´ì²˜ëŸ¼ ê°ê°ì˜ Vectorì— ëŒ€í•´ ìœ ë‹ˆí¬í•œ ê°’ì„ ì¶”ì¶œí•˜ëŠ” ë°˜ë©´, L1ì€ ê²½ìš°ì— ë”°ë¼ íŠ¹ì • Feature(Vectorì˜ ìš”ì†Œ)ì—†ì´ë„ ê°™ì€ ê°’ì„ ë‚¼ ìˆ˜ ìˆë‹¤ëŠ” ë§ì´ ëœë‹¤. ì´ëŸ° íŠ¹ì§•ìœ¼ë¡œ L1 normì€ Feature Selectionì„ í•˜ëŠ” ë° ì‚¬ìš©í•  ìˆ˜ ìˆê³ , íŠ¹ì • Featureë“¤ì„ 0ìœ¼ë¡œ ì²˜ë¦¬í•´ë²„ë¦¬ëŠ” ê²ƒì´ ê°€ëŠ¥í•˜ê¸° ë•Œë¬¸ì— ê²°ê³¼ì ìœ¼ë¡œ ê·¸ Coefficientë“¤ì´ Sparseí•œ í˜•íƒœë¥¼ ê°€ì§ˆ ìˆ˜ ìˆë‹¤. ë§Œì•½ $\\beta = [\\beta_0, \\beta_1]$ì´ë¼ëŠ” ë²¡í„°ê°€ ìˆì„ ë•Œ, ê·¸ L1, L2 Normì˜ ê°’ì´ ë˜‘ê°™ì´ 1ì´ë¼ê³  í–ˆì„ ë•Œ, L1ê³¼ L2ì—ì„œ ê°€ëŠ¥í•œ ì˜ì—­ì„ í‘œì‹œë¥¼ í•˜ìë©´ ì•„ë˜ ê·¸ë¦¼ê³¼ ê°™ë‹¤. $$\\text{L1: }||\\beta||_1 = |\\beta_0| + |\\beta_1| = 1$$ $$\\text{L2: }||\\beta||_2 = \\sqrt{(\\beta_0)^2 + (\\beta_1)^2} = 1$$ ìœ„ì˜ ê·¸ë¦¼- L2ì˜ ì´ëŸ° ì›ì„ Unit Circleì´ë¼ê³  í•œë‹¤ - ìœ„ì˜ ì˜ˆì‹œì—ì„œ ë³¸ ê²ƒê³¼ ê°™ì´ â€˜íŠ¹ì • ìš”ì†Œê°€ 0ì¼ ìˆ˜ ìˆëŠ” ê²½ìš°ì˜ ìˆ˜ / ì „ì²´ ê²½ìš°ì˜ ìˆ˜â€™ ë¡œ L1 Normê³¼ L2 Normì„ ë¹„êµí•œë‹¤ê³  ìƒê°í•˜ë©´ â€˜L1 normì˜ ê²½ìš° ì¢€ë” Î²ì˜ ìš”ì†Œ ì¤‘ 0ì´ ë“¤ì–´ê°ˆ ìˆ˜ ìˆëŠ” ê°€ëŠ¥ì„±ì´ ë” ë†’ë‹¤â€™ê³  ë§í•  ìˆ˜ ìˆë‹¤. ì´í•´ë¥¼ ë•ê¸°ìœ„í•´ ë³¸ í¬ìŠ¤íŒ…ì˜ ëŒ“ê¸€ë¡œ C Bë‹˜ì´ ì•Œë ¤ì£¼ì‹  ê²ƒì²˜ëŸ¼, ë§ˆë¦„ëª¨ì˜ ë‘˜ë ˆëŠ” í•œ ë³€ì˜ ê¸¸ì´ê°€ $\\sqrt{2}$ ì´ë‹ˆ ëŒ€ëµ 5.6568â€¦ ì´ ë˜ê³ , ë°˜ì§€ë¦„ì´ 1ì´ë‹ˆ ì›ì˜ ë‘˜ë ˆëŠ” 6.28â€¦ì •ë„ ëœë‹¤ëŠ” ì ì„ ìƒê°í•´ë³´ë©´ ëœë‹¤. ì´ëŸ° íŠ¹ì§•ì´ L1ì˜ Sparsity, í˜¹ì€ Feature Selectionì´ë¼ëŠ” ê°œë…ì„ ê°€ì§ˆ ìˆ˜ ìˆê²Œ í•´ì¤€ë‹¤ê³  ìƒê°í•  ìˆ˜ ìˆë‹¤. Featureê°€ ë„ˆë¬´ ë§ì€ ë°ì´í„°ì…‹ì„ ë‹¤ë£° ë•Œ ìœ ìš©í•˜ê²Œ ì“¸ ìˆ˜ ìˆë‹¤. ì´ëŸ¬í•œ Feature Selectionì˜ íŠ¹ì§• ë•Œë¬¸ì— L1 normì€ convex optimisationì„ í•  ë•Œ ìœ ìš©í•˜ê²Œ ì“°ì¸ë‹¤ê³  í•œë‹¤. ì°¸ê³  L1 regularizationì„ ì“°ëŠ” Regression modelì„ Lasso(Least Absolute Shrinkage and Selection Operator) Regression. L2 regularizationì„ ì“°ëŠ” Regression modelì„ Ridge Regression ì´ë¼ê³  ë¶€ë¥¸ë‹¤. Reference Quora Garbled Notes Anuja Nagpal TAEWAN.KIM ë¸”ë¡œê·¸ document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","link":"/2018/09/24/l1l2/"},{"title":"Pseudo Labelling","text":"ì¤€ì§€ë„í•™ìŠµì¸ Pseudo Labelingì— ëŒ€í•´ ì•Œì•„ë´…ë‹ˆë‹¤. Semi-Supervised Learning, Pseudo Labeling Pseudo-Label: The Simple and Efficient Semi-Supervised Learning Method for Deep Neural NetworksPeter Chaì´ í¬ìŠ¤íŒ…ì€ SHUBHAM JAINì˜ ê¸€ì„ ë ˆí¼ëŸ°ìŠ¤ë¡œ ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤. ì´ë²ˆ í¬ìŠ¤íŒ…ì—ì„œ ì‚´í´ ë³¼, Pseudo Labelì€ Semi-supervised Learningì˜ ì—¬ëŸ¬ ë°©ë²• ì¤‘ í•œ ê°€ì§€ ì…ë‹ˆë‹¤. ë¨¼ì €, Semi Supervised Learningì´ ë¬´ì—‡ì¸ì§€ ì‚´í´ë³´ê¸°ë¡œ í•˜ê² ìŠµë‹ˆë‹¤. 1. Semi-Supervised Learningë€? ìš°ë¦¬ëŠ” ë³´í†µ labelled data (supervised learning)ì™€ unlabelled data(unsupervised learning) ì–‘ìª½ ëª¨ë‘ë¥¼ ì‚¬ìš©í•˜ëŠ” ë°©ì‹ì˜ í•™ìŠµì„ Semi-Supervised Learning(ì´í•˜ SSL)ë¼ê³  ì •ì˜í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë©´, ì–´ë– í•œ ìƒí™©ì— SSLì´ í•„ìš”í• ê¹Œìš”? ë³´í†µ ë‹¤ìŒê³¼ ê°™ì€ ë‘ ê°€ì§€ ìƒí™©ì´ ìˆìŠµë‹ˆë‹¤. ë§Œë“¤ê³ ì í•˜ëŠ” Modelì— ì“¸, Training dataê°€ ì ˆëŒ€ì ìœ¼ë¡œ ë¶€ì¡±í•  ë•Œ. Large datasetì´ ë  ìˆ˜ë¡ ìƒˆë¡œ ìƒì„±ë˜ëŠ” dataë“¤ì— ëŒ€í•œ Human annotationì´ í˜ë“¤ê³ , ë¹„ìŒ€ ë•Œ. ê·¸ë˜ì„œ, ë³´í†µì€ â€˜ë°ì´í„°ê°€ ë¶€ì¡±í•  ë•Œ ì“°ëŠ” ë°©ë²•â€˜ìœ¼ë¡œë§Œ ì•Œê³  ìˆì§€ë§Œ, SSLì„ ì•„ë˜ì™€ ê°™ì€ ì´ìœ ë¡œ ì‚¬ìš©í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. Labeled dataë§Œìœ¼ë¡œëŠ” ë„ë‹¬ í•  ìˆ˜ ìˆëŠ” ì„±ëŠ¥ì— í•œê³„ê°€ ìˆì„ ë•Œ, Unlabelled dataë¥¼ ì‚¬ìš©í•˜ì—¬ ì „ë°˜ì ì¸ ì„±ëŠ¥ì„ ë” ë†’ì´ê¸° ìœ„í•´. ë…¼ë¬¸ì—ì„œ ë§í•˜ê³  ìˆëŠ” Semi Supervised Learningì˜ ëª©ì ê³¼, ì´ ê¸€ í›„ë°˜ë¶€ì— ë‚˜ì˜¬ í•„ìì˜ Pseudo Labelì‹¤í—˜ë„ ì´ ì„¸ ë²ˆì§¸ ì´ìœ ì— ëŒ€í•œ ê²ƒì…ë‹ˆë‹¤. Image from Dataiku hadoop summit. 2. Unlabeled dataëŠ” ì–´ë–»ê²Œ ë„ì›€ì´ ë ê¹Œ? ê·¸ë ‡ë‹¤ë©´ Unlabeled dataë¥¼ ì“´ë‹¤ëŠ” ê²ƒì€ ì–´ë–¤ ì´ì ì´ ìˆì„ê¹Œìš”? Labelled data ëŠ” ë¹„ì‹¸ê³  ì–»ê¸° í˜ë“¤ì§€ë§Œ unlabelledëŠ” ê·¸ ì–‘ì´ í’ë¶€í•˜ê³  ê°’ì´ ì‹¸ê¸° ë•Œë¬¸ì— ë°ì´í„° íšë“ì´ ìš©ì´í•˜ë‹¤. Unlabeled dataëŠ” Modelì˜ Decision boundaryë¥¼ ë” ì •í™•í•˜ê²Œ ì¡ì•„ì£¼ëŠ” ì—­í• ì„ í•´ì¤Œìœ¼ë¡œì¨, ëª¨ë¸ì˜ Robustnessë¥¼ í–¥ìƒì‹œí‚¨ë‹¤. ë‘ ë²ˆì§¸ ì¥ì ì„ ì²˜ìŒ ì½ìœ¼ë©´ ì¡°ê¸ˆ ì¶”ìƒì ìœ¼ë¡œ ë‹¤ê°€ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ë¦¼ìœ¼ë¡œ ì¡°ê¸ˆ ë” ì„¤ëª…í•˜ìë©´ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤. ë‹¨ìˆœíˆ 2ê°€ì§€ì˜ Classë¥¼ êµ¬ë³„í•´ì•¼í•˜ëŠ” ëª¨ë¸ì˜ ê²½ìš°, Labeled dataë§Œ ê°€ì§€ê³  ê·¸ Decision Boundaryë¥¼ ê²°ì •í•˜ê²Œ ë˜ë©´ ì„ í˜•ìœ¼ë¡œ ê·¸ Decision Boundaryê°€ ê·¸ì–´ì§„ë‹¤ê³  ìƒê°í•´ ë´…ì‹œë‹¤. ê°€ì§€ê³  ìˆëŠ” Labeled Dataì—ì„œ ê²½ê³„ë¼ê³  íŒë‹¨í•  ë§Œí•œ ì •ë³´ê°€ ì €ê²ƒë°–ì— ì—†ê¸° ë•Œë¬¸ì— ê°€ì§€ê³  ìˆëŠ” Dataë¡œ í•™ìŠµì‹œí‚¬ ìˆ˜ ìˆëŠ” ëª¨ë¸ì˜ í•œê³„ë¼ê³ ë„ ìƒê°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ Unlabeled Dataë¥¼ ì‚¬ìš©í•˜ë©´ì„œ í•™ìŠµì„ í•˜ë©´, ê²½ê³„ë¥¼ ê·¸ì„ ë•Œ, ë” ë§ì€ Caseë“¤ì„ ê³ ë ¤í•˜ë©´ì„œ ì •êµí•˜ê²Œ ê²½ê³„ë¥¼ ê¸‹ê¸° ì‹œì‘í•©ë‹ˆë‹¤. ì´ëŠ” ìì—°ìŠ¤ëŸ½ê²Œ, ë‚˜ì¤‘ì— ëª¨ë¸ì´ Test setì„ ë§Œë‚¬ì„ ë•Œ, í˜¹ì€ ì²˜ìŒë³´ëŠ” ë‹¤ë¥¸ Dataë¥¼ ë§Œë‚¬ì„ ë•Œë„, â€˜ë‹¹í™©í•˜ì§€ ì•Šê³  ëŒ€ì‘í•  ìˆ˜ ìˆëŠ”â€™ í˜ì„ ê°€ì§€ê²Œ í•´ì¤€ë‹¤ê³  ì´í•´í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ê·¸ë˜ì„œ ë‘ ë²ˆì§¸ ì¥ì ì—ì„œ ë§í•˜ê³  ìˆëŠ” ëª¨ë¸ì˜ Robustness(ê²¬ê³ í•¨)ëŠ” ì´ë¥¼ ëœ»í•©ë‹ˆë‹¤. ìš°ë¦¬ê°€ ì˜ ì•Œê³  ìˆëŠ” Overfittingë„ ì´ Robustnessì˜ ì •ë„ê°€ ë‚®ì•„ì„œ ë°œìƒí•˜ëŠ” ê²ƒì´ë¼ê³  ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. Images from A Tutorial on Graph based Semi-Supervised Learning Algorithms for NLP. 3. Pseudo Labelingì„ ì†Œê°œí•©ë‹ˆë‹¤ :) Pseudo Labellingì˜ ê°œë…ì€ ì•„ì£¼ ê°„ë‹¨í•©ë‹ˆë‹¤. Labeled Dataì²˜ëŸ¼ ì¼ì¼íˆ labelì„ í•˜ê¸°ë³´ë‹¤, ì´ë¯¸ ê°€ì§€ê³  ìˆëŠ” Labeled dataì— ê¸°ë°˜í•˜ì—¬ ëŒ€ëµì ì¸ Labelì„ ì£¼ëŠ” ê²ƒì„ Pseudo Labellingì´ë¼ê³  í•©ë‹ˆë‹¤. ê·¸ë˜ì„œ Pseudo Labelingì˜ ìˆœì„œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. Labeled Dataë¡œ Modelì„ ë¨¼ì € í•™ìŠµì‹œí‚¨ë‹¤. ê·¸ë ‡ê²Œ í•™ìŠµëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬, Unlabeled Dataë¥¼ ì˜ˆì¸¡í•˜ê³  ê·¸ ê²°ê³¼ë¥¼ Labelë¡œ ì‚¬ìš©í•˜ëŠ” Pseudo-labeled dataë¥¼ ë§Œë“ ë‹¤. Pseudo-labeled dataì™€ Labeled dataë¥¼ ëª¨ë‘ ì‚¬ìš©í•˜ì—¬ ë‹¤ì‹œ ê·¸ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¨ë‹¤. Images from Data, what now?3.1. Pseudo Labeled data Pseudo Labelì€ ì•„ë˜ì™€ ê°™ì€ ì‹ìœ¼ë¡œ, ê°ê°ì˜ sampleì— ëŒ€í•´, ì˜ˆì¸¡ëœ í™•ë¥ ì´ ê°€ì¥ ë†’ì€ ê²ƒìœ¼ë¡œ ì •í•©ë‹ˆë‹¤. ì˜ˆì¸¡ëœ í™•ë¥ ì´ ê°€ì¥ ë†’ì€ ê²ƒì„ Labelë¡œ ì„ ì •í•œë‹¤ê³  í–ˆì„ ë•Œ, ì œëŒ€ë¡œ í•™ìŠµì„ ë§ˆì¹˜ì§€ ëª»í•œ ëª¨ë¸ë¡œ ì´ ì‘ì—…ì„ í•˜ì˜€ì„ ê²½ìš°ì—ëŠ” ìƒì‹ì ìœ¼ë¡œ ë” í•™ìŠµì„ ì €í•´í•˜ëŠ” ë°ì´í„°ë¥¼ ë§Œë“¤ ë¿ì…ë‹ˆë‹¤. ê·¸ë˜ì„œ Pseudo Labelì€ í•™ìŠµì„ Labeled dataë¡œ ì¼ì • ìˆ˜ì¤€ê¹Œì§€ ë§ˆì¹œ ë’¤ì˜, fine-tuning phaseì— ì‹œí–‰í•©ë‹ˆë‹¤. 3.2. Loss Function for Pseudo Labelling ë…¼ë¬¸ì—ì„œ Pseudo Labelë¡œ í•™ìŠµì„ í•  ë•ŒëŠ”, ë‹¤ìŒê³¼ ê°™ì€ Loss functionì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ì ì ˆí•œ ìˆ˜ì¹˜ì˜ $\\alpha(t)$ê°€ ë„¤íŠ¸ì›Œí¬ ì„±ëŠ¥ì— ìˆì–´ì„œ ë§¤ìš° ì¤‘ìš”í•œ ìš”ì†Œì…ë‹ˆë‹¤. $\\alpha(t)$ê°€ ë„ˆë¬´ ë†’ìœ¼ë©´ labeled dataì˜ trainingì„ ë°©í•´í•  ê²ƒì´ê³ , ë°˜ëŒ€ë¡œ ë„ˆë¬´ ê·¸ ìˆ˜ì¹˜ê°€ ì‘ìœ¼ë©´ unlabeled dataì˜ ìœ ìµì„ ì·¨í•  ìˆ˜ ì—†ê²Œ ë˜ê² ì£ . ê·¸ë˜ì„œ ì•„ë˜ì™€ ê°™ì´ ì ì§„ì ìœ¼ë¡œ ê·¸ ë¹„ìœ¨ì„ ëŠ˜ë ¤ì£¼ëŠ” ì‹ìœ¼ë¡œ $\\alpha(t)$ë¥¼ ì¡°ì ˆí•˜ì—¬ì„œ local minimaì— ë¹ ì§€ëŠ” ë¬¸ì œë¥¼ ì ì°¨ í”¼í•  ìˆ˜ ìˆë„ë¡í•˜ì—¬, Processë¥¼ ìµœì í™”ì‹œí‚µë‹ˆë‹¤. 4. Pseudo-Labelë¡œ ì„±ëŠ¥í–¥ìƒì´ ì™œ ê°€ëŠ¥í•œê±°ì£ ? ë…¼ë¬¸ì—ì„œëŠ” ì´ Pseudo Labelì´ ì™œ ì˜ ë™ì‘í•˜ëŠ”ì§€ì— ëŒ€í•´ ì•„ë˜ì™€ ê°™ì´ ì„¤ëª…í•©ë‹ˆë‹¤. 4.1. Low-Density Separation between Classes. Cluster Assumption (Chapelle et al., 2005)ì— ì˜í•˜ë©´, Modelì˜ ì „ë°˜ì ì¸ ì„±ëŠ¥ì„ ë†’ì´ê¸° ìœ„í•´ì„œëŠ” Modelì˜ Decision boundaryëŠ” Low-densidy regionsì— ìœ„ì¹˜í•´ì•¼í•œë‹¤ê³  ë§í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì¦‰, ì•ì—ì„œ ì‚´í´ë³¸ Decision Boundaryë¥¼ ê²°ì •í•  ë•Œ, ê·¸ ê²½ê³„ë¥¼ êµ¬ë¶„í•˜ëŠ” ì§€ì ì˜ ë°ì´í„°ê°€ ëª°ë ¤ìˆëŠ” ë°€ë„ê°€ ë‚®ìœ¼ë©´ ë‚®ì„ìˆ˜ë¡, ë” ë¯¸ì„¸í•œ ì°¨ì´ì ë„ êµ¬ë³„í•œë‹¤ê³  ìƒê°í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì—, ì „ì²´ì ì¸ ì„±ëŠ¥ì„ ë†’ì¼ ìˆ˜ ìˆë‹¤ê³  ë§í•˜ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ° ì ì—ì„œ, Pseudo Labelì´ ì•„ë‹Œ ë‹¤ë¥¸ SSLë“¤ì¸, Semi-Supervised Embedding (Weston et al., 2008)ì´ë‚˜, Manifold Tangent Classifier (Rifai et al., 2011b)ë„ ê°™ì€ ëª©ì ì„ ë‹¬ì„±í•œ ë°©ì‹ì´ë¼ê³  ì†Œê°œí•˜ê³  ìˆìŠµë‹ˆë‹¤. Pseudo Labelë„ ë§ˆì°¬ê°€ì§€ë¡œ Low-Density Separation íš¨ê³¼ë¥¼ ê°€ì ¸ì˜¤ëŠ” ë°©ë²•ì´ë¼ëŠ” ê²ƒì´ì£ . 4.2. Entropy Regularization Entropy Regularization (Grandvalet, Yoshua Bengio, 2006)ì€ Baysianì—ì„œ ë§í•˜ëŠ” Maximum posteriori estimation(or Maximum a posteriori, MAP) ê´€ì ì—ì„œ Unlabelled dataì˜ ì´ì ì„ ì–»ëŠ” ìˆ˜ë‹¨ì…ë‹ˆë‹¤. ì´ ë°©ì‹ì€ Unlabeled dataê°€ ê°€ì§€ëŠ” classë³„ í™•ë¥ ì— ëŒ€í•œ Entropyë¥¼ ìµœì†Œí™”ì‹œí‚´ìœ¼ë¡œì¨, ìœ„ì—ì„œ ì–¸ê¸‰í•œ Classë“¤ ê°„ì˜ Low-Density separationì„ ì¶”êµ¬í•©ë‹ˆë‹¤. ì•„ë˜ì— ë‚˜ì˜¤ëŠ” MAPì‹ë“¤ê³¼ í•¨ê»˜ ë” ìì„¸íˆ ì„¤ëª…í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. ìœ„ì™€ ê°™ì€ MAPì‹ì—ì„œ $\\sum\\limits_{m = 1}^{n}\\text{log}P(y^{m}|x^{m};\\theta)$ë¥¼ ì²«ë²ˆì§¸ í•­, $-\\lambda H(y|x^{â€˜};\\theta)$ë¥¼ ë‘ ë²ˆì§¸ í•­ì´ë¼ê³  ì§€ì¹­í•  ë•Œ, ì²« ë²ˆì§¸ í•­ì¸ labeled dataì˜ log-likelihoodì„ ìµœëŒ€í™”ì‹œí‚¤ë©´ì„œ, ë‘ ë²ˆì§¸ í•­ì¸ unlabeled dataì˜ entropyë¥¼ ìµœì†Œí™”ì‹œí‚¤ê¸° ë•Œë¬¸ì—, ìš°ë¦¬ëŠ” ì¢€ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ì–»ì„ ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤. ë‘ë²ˆì§¸ í•­ì—ì„œ ìµœì†Œí™” ì‹œí‚¨ë‹¤ëŠ” EntropyëŠ” Classê°„ì˜ ê·¸ ê²½ê³„ì¹˜ê°€ Overlapì´ ë˜ëŠ” ì •ë„ë¥¼ ëœ»í•˜ëŠ”ë°ìš”, Class Overlapì´ ì‘ì•„ì§ˆìˆ˜ë¡, dataë“¤ì˜ ë°€ì§‘ëœ ë¶€ë¶„ì´ ë” ë‚®ì€ decision boundaryë¥¼ ê°€ì§€ê²Œ ë©ë‹ˆë‹¤. ì´ê²ƒì´ ìœ„ì—ì„œ ì„¤ëª…í•œ, classë³„ í™•ë¥ ì— ëŒ€í•œ Entropyë¥¼ ìµœì†Œí™”ì‹œí‚´ìœ¼ë¡œì¨, ìœ„ì—ì„œ ì–¸ê¸‰í•œ Classë“¤ ê°„ì˜ Low-Density separationì„ ì¶”êµ¬í•©ë‹ˆë‹¤. ì˜ ì˜ë¯¸ì…ë‹ˆë‹¤. ë”°ë¼ì„œ, ìœ„ì—ì„œ ì„¤ëª… í•˜ì˜€ë˜ Pseudo-Labelì˜ Loss functionì—ì„œ ë‚˜ì˜¤ëŠ” $\\alpha$ëŠ” Entropy Regularizationì˜ $\\lambda$ì™€ ê°™ì€ ì—­í• ì„ í•˜ê³  ìˆë‹¤ëŠ” ê²ƒì„ ê´€ì°°í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê²°ë¡ ì ìœ¼ë¡œ ì´ ë…¼ë¬¸ì—ì„œ ë§í•˜ê³  ìˆëŠ” ë°”ëŠ”, ìš°ë¦¬ê°€ ì·¨í•œ Loss functionì€ Entropy Regularzationê³¼ ë™ì¼í•˜ë‹¤! ê·¸ë˜ì„œ, Pseudo-Labelì„ Entropy Regularizationìœ¼ë¡œ Trainingí•˜ëŠ” ê²ƒì´ íš¨ê³¼ê°€ ìˆë‹¤. ë¡œ ì •ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 4.3. ë…¼ë¬¸ ì‹¤í—˜ ê²°ê³¼ ë…¼ë¬¸ì˜ ì €ìëŠ” MNIST test dataë¡œ t-SNE (Van der Maaten et al., 2008) 2-D embedding resultsë¥¼ ì²¨ë¶€í•˜ì—¬ ê·¸ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ê³  ìˆìŠµë‹ˆë‹¤. train dataëŠ” 600ê°œ ë°–ì— ì“°ì§€ ì•Šì•˜ê³ , 60000ê°œì˜ unlabeled dataë¥¼ ì‚¬ìš©í–ˆë‹¤ê³  í•˜ë„¤ìš”. Pseudo-Label (ì´í•˜ PL)ì„ ì“°ì§€ ì•Šì€ DropNN ëª¨ë¸ê³¼, ê±°ê¸°ì— PLì„ ì“´ +PL ëª¨ë¸ì˜ Conditional Entropyë¥¼ ë¹„êµí•´ ë³´ë©´, Trainì—ì„œëŠ” +PLì´ í™•ì‹¤íˆ ê·¸ Entropyê°€ ë” ë†’ê²Œ ë‚˜íƒ€ë‚˜ì§€ë§Œ, Unlabeled dataë‚˜, Test setì—ì„œ ë‚˜ì˜¤ëŠ” EntropyëŠ” ì›”ë“±íˆ ë‚®ìŒì„ ë³¼ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. ì‹œê°ì ìœ¼ë¡œë„ ê·¸ êµ¬ë¶„í•˜ëŠ” ê²½ê³„ ì¦‰, Decision boundaryê°€ ì–´ë–¤ ëª¨ë¸ì´ ë” ì„¬ì„¸í•˜ê²Œ ì‘ìš©í•˜ê³  ìˆëŠ”ì§€(=ë” í™•ì‹¤íˆ êµ¬ë³„í•˜ê³  ìˆëŠ”ì§€) í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","link":"/2018/08/22/pseudo-label/"},{"title":"Tensorpack tutorial","text":"Tensorflow Wrapperì¸ Tensorpackì„ ì†Œê°œí•©ë‹ˆë‹¤. Tensorflow, Tensorpack ModelDescì™€ Trainerë¥¼ ì¤‘ì‹¬ìœ¼ë¡œPeter ChaTensorpackì„ ê³µë¶€í•˜ë©´, ìš°ì„  ëª¨ë¥´ëŠ” ê²ƒë“¤ íˆ¬ì„±ì´ë‹¤. ì•Œê³ ë‚˜ë©´ ë„ˆë¬´ ì“°ê¸° í¸í•˜ì§€ë§Œ, ì²˜ìŒ ì ‘í•  ë•ŒëŠ” ë„ˆë¬´ ë§ì´ ì¶”ìƒí™” ëœ APIì— â€˜ì´ê²Œ tensorflowëŠ” ë§ëŠ”ì§€..â€™í•  ì •ë„ë‹ˆê¹Œ. ìš°ì„  ì´ íŠœí† ë¦¬ì–¼ì„ ë³´ê¸° ì „, í•„ìì˜ tensorpack_tutorial.ipynbë¥¼ ì‹¤í–‰í•´ ë³´ê¸¸ ë°”ë€ë‹¤. ëŒ€ëµì ì¸ dataflowëŠ” ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ë¶€ë¶„ìœ¼ë¡œ ì´í•´ë¥¼ ë§ˆì³¤ë‹¤ê³  ìƒê°ì„ í•˜ê³ , dataflowë¶€ë¶„ì€ ìƒëµí•˜ê³  ì„¤ëª…ì„ ì§„í–‰í•˜ë„ë¡ í•˜ê² ë‹¤. ì´ë²ˆì—ëŠ” Modelì˜ ì„ ì–¸í•˜ê²Œ ë  ë•Œ ìƒì†ë°›ì€ ModelDesc classì™€, í•™ìŠµì„ ì‹¤í–‰í•˜ëŠ” Trainerë“¤ì˜ ëª¨íƒœê°€ ë˜ëŠ” TowerTrainer ì— ëŒ€í•´ ì•Œì•„ë³´ê³ ì í•œë‹¤.tensorpack_tutorial.ipynbì—ì„œ ì„¤ëª…ì— í•´ë‹¹í•˜ëŠ” ë¶€ë¶„ì„ í•¨ê»˜ ì°¾ì•„ë³´ë©´ ì´í•´ì— ë„ì›€ì´ ë” ë  ê²ƒ ê°™ë‹¤. ì´ Tutorialì€ Tensorpack documentationì„ ì°¸ê³ í•´ì„œ ë§Œë“¤ì—ˆë‹¤. 1. Class ModelDescBase Base class for a model descriptionì´ë‹¤. ModelDescëŠ” ModelDescBaseë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë§Œë“¤ì–´ì¡Œê¸° ë•Œë¬¸ì—, ModelDescBaseë¥¼ ë¨¼ì € ì„¤ëª…í•œë‹¤. 1.1. build_graph(*args) ëª¨ë“  symbolic graph (Modelì˜ í˜•íƒœ)ë¥¼ Buildí•œë‹¤. ì´ í•¨ìˆ˜ê°€ ë’¤ì—ì„œ ì„¤ëª…í•  TowerTrainerì—ì„œ tower functionì˜ ì¼ë¶€ë¶„ì´ë‹¤. ê·¸ ë‹¤ìŒ ì„¤ëª…í•  inputs()ì—ì„œ ì •ì˜ëœ input listì— ë§ëŠ” tf.Tensorë¥¼ parameterë¡œ ë°›ëŠ”ë‹¤. ì•„ë¬´ê²ƒë„ ë¦¬í„´í•˜ì§€ ì•ŠëŠ”ë‹¤. 1.2. inputs() Modelì—ì„œ inputìœ¼ë¡œ ë°›ì„ í…ì„œë“¤ì˜ placeholderë“¤ì„ ì •ì˜í•˜ëŠ” í•¨ìˆ˜ë‹¤. í›„ì— InputDescë¡œ ë³€í™˜ë , tf.placeholderë“¤ì„ return í•œë‹¤. 1.3. get_inputs_desc ì´ë¦„ì—ì„œ ì•Œ ìˆ˜ ìˆë“¯ì´, inputs()ì—ì„œ ì •ì˜ëœ ëª¨ì–‘ëŒ€ë¡œ ìƒê¸´ InputDescë¥¼ listë¡œ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜ë‹¤. 2. Class ModelDesc ì£¼ì˜ì‚¬í•­: build_graph()ë¥¼ ê¼­ costë¥¼ returní•˜ë„ë¡ ì½”ë”©í•´ì•¼ í•œë‹¤. ì•ì—ì„œ ì„¤ëª…í•œ ModelDescBaseë¥¼ ìƒì†ë°›ì€ í„°ë¼, ìœ„ì˜ 3ê°€ì§€ëŠ” í•¨ìˆ˜ëŠ” ë‚´ì¥í•˜ê³  ìˆë‹¤. 2.1. optimizer() tf.train.Optimizerë¥¼ ì—¬ê¸°ì— ì„ ì–¸í•´ì£¼ê³  Returní•˜ê²Œë” í•¨ìˆ˜ë¥¼ ì§œì¤€ë‹¤. 2.2. get_optimizer() optimizer()ë¥¼ í˜¸ì¶œí•˜ë©´, ê³„ì† ìƒˆë¡œ optimizerë¥¼ ë§Œë“¤ì–´ì„œ ìƒì„±í•˜ëŠ”ë°, ì´ í•¨ìˆ˜ë¥¼ ì“°ë©´ ì´ë¯¸ optimizer()ë¥¼ í†µí•´ ìƒê¸´ optimizerë¥¼ ê¸°ë¡í•´ ë†“ì•˜ë‹¤ê°€ ë°˜í™˜ì‹œì¼œì¤€ë‹¤. 3. Class TowerTrainerTensorpackì—ì„œëŠ”, ìš°ë¦¬ê°€ í”íˆ ë§í•˜ëŠ” Modelì„ ê³„ì† Towerë¼ê³  ì§€ì¹­í•œë‹¤.(ì™œ ê·¸ëŸ°ì§€ ëª¨ë¥´ê² ë‹¤.ğŸ˜¶) ê·¸ë˜ì„œ ì•„ë˜ì—ì„œ ë‚˜ì˜¤ëŠ” TowerTrainerëŠ” ë§Œë“  ëª¨ë¸ì„ í•™ìŠµì„ ì‹œí‚¤ëŠ” Trainerê³ , ê·¸ íŠ¸ë ˆì´ë„ˆê°€ ì–´ë–¤ íŠ¹ì§•ë“¤ì„ ê°€ì§„ í•¨ìˆ˜ë“¤ì„ ë“¤ê³  ë‹¤ë‹ˆëŠ”ì§€ ì´í•´í•˜ë©´ ì´í•´ê°€ ì‰½ë‹¤. ê¸°ë³¸ì ìœ¼ë¡œ Tensorpackì— ë‚˜ì˜¤ëŠ” ëª¨ë“  Trainerë“¤ì€ TowerTrainerì˜ subclassë‹¤. ì´ ê°œë…ì´ ê·¸ë˜ì„œ ê¶ê·¹ì ìœ¼ë¡œëŠ” ëª¨ë“  neural-network trainingì„ ê°€ëŠ¥í•˜ê²Œ í•´ì¤€ë‹¤. 3.1. get_predictor(input_names, output_names, device=0) Returns a callable predictor built under TowerContext(is_training=False). ì´ í•¨ìˆ˜ê°€ í˜¸ì¶œë˜ë©´, ê°€ì§€ê³  ìˆëŠ” TowerContext(ëª¨ë¸)ê°€ training modeê°€ ì•„ë‹Œ ìƒíƒœ(is_training=False)ë¡œ ëŒë ¤ì¤€ë‹¤. ê·¸ëŸ¬ë‹ˆê¹Œ Test dataë¡œ ì‹œí—˜í•  ë•Œë§Œ ë¶€ë¥´ëŠ” í•¨ìˆ˜. ê·¸ë˜ì„œ ì´ë¦„ë„ predictor. Parameters: input_names (list), output_names (list), device (int) â€“ build the predictor on device â€˜/gpu:{device}â€™ or use -1 for â€˜/cpu:0â€™. íŒŒë¼ë¯¸í„°ë¡œ ë“¤ì–´ê°€ëŠ” input, outputì´ë¦„ì€ ëª¨ë¸ ì•ˆì—ì„œ ì„ ì–¸ëœ ì´ë¦„ì´ ì•„ë‹ˆë©´ ì•ˆ ëŒì•„ê°€ë‹ˆê¹Œ ì¡°ì‹¬. 3.2. inputs_desc Returns â€“ list[InputDesc]: metainfo about the inputs to the tower. ë§ ê·¸ëŒ€ë¡œ, ëª¨ë¸ì— ë“¤ì–´ê°ˆ Inputì˜ í¬ê¸°ì™€ ê°™ì€ ì •ë³´ê°€ ë“¤ì–´ìˆëŠ” listë¥¼ ë°˜í™˜í•´ì¤€ë‹¤. 3.3. tower_func Build Model. ì´ ì¹œêµ¬ê°€ ì‹¤ì œ ëª¨ë¸ì„ ì •ì˜í•˜ê³ , Buildí•  ìˆ˜ ìˆëŠ” í•¨ìˆ˜ë¥¼ ì„¸íŒ…í•˜ëŠ” ë¶€ë¶„! ModelDesc interfaceë¡œ ì •ì˜ëœ modelì„ trainerë¡œ ëŒë ¤ì•¼ í•˜ëŠ” ìƒí™©ì´ ìì£¼ ë°œìƒí•  ìˆ˜ ìˆëŠ”ë°, ì´ ë•Œ, ModelDescì—ì„œ ì„ ì–¸ëœ build_graph í•¨ìˆ˜ê°€ ì´ ì—­í• ì„ ëŒ€ì‹ í•´ ì¤„ ìˆ˜ ìˆë‹¤. 3.4. towers Returns â€“ a TowerTensorHandles object, to access the tower handles by either indices or names. ëª¨ë¸ ë° Train ì „ë°˜ì— ê±¸ì³ ê´€ë ¨ëœ ë³€ìˆ˜ë“¤ì— ì ‘ê·¼í•˜ê³  ì‹¶ì„ ë•Œ ì‚¬ìš©í•œë‹¤! ê·¸ë˜ì„œ ì´ í•¨ìˆ˜ëŠ” Transfer learningì„ í•  ë•Œ ìœ ìš©í•  ê±° ê°™ë‹¤. ì´ë¯¸ ëª¨ë¸ ê·¸ë˜í”„ê°€ Set upì´ ëë‚œ ë’¤ì—ë§Œ ì´ í•¨ìˆ˜ëŠ” í˜¸ì¶œë  ìˆ˜ ìˆë‹¤. ê°ê°ì˜ layerì™€ attributesì— ì´ towersí•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ë©´ ì ‘ê·¼í•  ìˆ˜ ìˆê²Œ ëœë‹¤! ì•„ë˜ëŠ” ì˜ˆì‹œ. 12# Access the conv1/output tensor in the first training towertrainer.towers.training()[0].get_tensor('conv1/output') 4. Class Trainer Base class for a trainer. ë¶„ëª…íˆ ìœ„ì—ì„œ ê¸ˆë°©, â€œê¸°ë³¸ì ìœ¼ë¡œ Tensorpackì— ë‚˜ì˜¤ëŠ” ëª¨ë“  Trainerë“¤ì€ TowerTrainerì˜ subclassë‹¤ â€œ ë¼ê³  í–ˆëŠ”ë°, ì´ TowerTrainerê°€ ìƒì†ì„ ë°›ëŠ” classê°€ ìˆì—ˆìœ¼ë‹ˆ, ì´ë¦„í•˜ì—¬ TowerTrainerë³´ë‹¤ ë” ë‹¨ìˆœí•œ Trainer ë‹¤. ë‹¤ë¥¸ TowerTrainerë¥¼ ìƒì† ë°›ì€ Trainerë“¤ì„ ì‚¬ìš©í•  ë•Œ, ì¢…ì¢… TowerTrainerì—ì„œ ë³¸ ì  ì—†ëŠ” ì¹œêµ¬ë“¤ì´ ë‚˜íƒ€ë‚˜ëŠ”ë°, ê·¸ ì¹œêµ¬ë“¤ì´ Trainerì˜ ê²ƒì¸ ê²½ìš°ê°€ ìˆë‹¤. í•˜ì§€ë§Œ, Trainer ê³ ìœ  í•¨ìˆ˜ë‚˜ ìš”ì†Œì— ì§ì ‘ì ìœ¼ë¡œ ì ‘ê·¼í•  ì¼ì´ ë³„ë¡œ ì—†ì–´ì„œ ì•„ë˜ì˜ 3ê°€ì§€ ì •ë„ë§Œ ì•Œê³  ìˆìœ¼ë©´ ë  ê²ƒ ê°™ë‹¤. ë‚˜ë¨¸ì§€ëŠ” ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì. ì•„ë˜ 1, 2ë²ˆì˜ max_epochê³¼, steps_per_epochì€ TrainConfigì—ì„œ ìì£¼ ë§Œë‚˜ëŠ” í‚¤ì›Œë“œë“¤ì¸ë°, ì´ ì¹œêµ¬ë“¤ì´ Trainerì˜ ìš”ì†Œì˜€ë‹¤. 4.1. max_epoch Epochì€ ëª‡ ë²ˆ ëŒë¦´ ê²ƒì¸ì§€ 4.2. steps_per_epoch í•œ ì—í­ë‹¹ stepsì€ ì´ ëª‡ ë²ˆì¸ì§€. 4.3. register_callback(cb) Register callbacks to the trainer. It can only be called before Trainer.train(). Trainerê°€ ëª¨ë¸ì„ ëŒë¦´ ë•Œë§ˆë‹¤(epochì´ ì§„í–‰ ë¨ì— ë”°ë¼), ìˆ˜í–‰í•˜ê²Œ ë  ë¶€ê°€ì ì¸ ê¸°ëŠ¥ë“¤ì„ Tensorpackì—ì„œëŠ” callbackì´ë¼ê³  ë¶€ë¥´ê³ , ëŒ€í‘œì ì¸ callbackìœ¼ë¡œ ModelSaver() ê°€ ìˆë‹¤. ì´ Callbackì„ ëª…ì‹œì ìœ¼ë¡œ ì „ë‹¬í•˜ì—¬ Trainer Objectì— ì„¸íŒ…í•  ìˆ˜ ìˆëŠ” ê¸°ëŠ¥ì´ë‹¤. ì£¼ë¡œ ëª¨ë¸ì„ íŠœë‹í•  ë•Œ, ì„¤ì •í•˜ë©´ì„œ ì¢…ì¢… ì“°ëŠ” ê²ƒì„ ì½”ë“œ ìƒì—ì„œ í™•ì¸í•  ìˆ˜ ìˆë‹¤. 5. TowerContext TowerContext ëŠ” Trainingê³¼ Validation í˜¹ì€ Testì‹œì— ë™ì‘ì´ ë‹¬ë¼ì•¼ í•˜ëŠ” BatchNormì´ë‚˜, Dropoutì„ ì œì–´í•˜ê¸° ìœ„í•´ì„œ ë§Œë“¤ì–´ì§„ functionì´ë‹¤. tensorpack_tutorial.ipynbì—ì„œëŠ” ì´ ì¹œêµ¬ë¥¼ ì°¾ì•„ë³¼ ìˆ˜ ì—†ëŠ”ë°, SimpleTrainer ì†ŒìŠ¤ì½”ë“œë¥¼ ë³´ë‹ˆ, ìì²´ì ìœ¼ë¡œ ì•ˆì—ì„œ train/test timeì— ë§ì¶°ì„œ TrainTowerContextë¼ëŠ” ê²ƒìœ¼ë¡œ ì¡°ì ˆí•˜ê³  ìˆê¸° ë•Œë¬¸ì´ì—ˆë‹¤. ì‚¬ìš©ë²•ì€ ê°„ë‹¨í•˜ë‹¤. 1234567# trainingwith TowerContext('', is_training=True): # call any tensorpack layer# testwith TowerContext('name or empty', is_training=False): # build the graph again ê·¸ë˜ì„œ, ë‚´ê°€ ì„¸ìš´ ëª¨ë¸ì„ ì™¸ë¶€ì—ì„œ ì‚¬ìš©í•˜ê³  ì‹¶ì„ ë•Œ, ì¦‰, ë‚˜ë§Œì˜ Trainerë¥¼ ìƒˆë¡œ ì •ì˜í•´ì„œ train/test timeë•Œ, ë‹¤ë¥´ê²Œ ë™ì‘ì„ í•´ì•¼í•˜ëŠ” ìƒí™©ì´ë¼ë©´, TowerContextë¥¼ ì ì ˆíˆ ì¨ì„œ ë¶„ê¸°ì‹œì¼œì¤˜ì•¼ í•œë‹¤. ì•„ë˜ëŠ” Tensorpack Githubì—ì„œ ì œê³µí•˜ëŠ” GANTrainerì—ì„œ ì‹¤ì œë¡œ TowerContextë¥¼ ì–´ë–»ê²Œ ì„¤ì •í•´ì£¼ëŠ”ì§€ ë³´ì—¬ì£¼ëŠ” ì˜ˆì‹œë‹¤. 1234567891011class GANTrainer(TowerTrainer): def __init__(self, input, model): .. ... # Build the graph self.tower_func = TowerFuncWrapper(model.build_graph, inputs_desc) with TowerContext('', is_training=True): self.tower_func(*input.get_input_tensors()) opt = model.get_optimizer() ... Thank you :) document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","link":"/2018/08/18/Tensorpack-tutorial/"},{"title":"Basic Deep learning 01","text":"Deep Learning ê°œë… ë° ìš©ì–´ë“¤ì„ ì•Œì•„ë´…ë‹ˆë‹¤. Optimizer, Loss function, Back propagation Peter ChaIntro Deep Learningì„ ì‚¬ìš©í•´ì„œ ìš°ë¦¬ê°€ í•˜ê³ ì í•˜ëŠ” ì¼ë ¨ì˜ ê³¼ì •ì€ ê²°êµ­, ìš°ë¦¬ê°€ ë§Œë“  AI(model)ê°€ íŠ¹ì • ë°ì´í„°ë¥¼ ì–¼ë§ˆë‚˜ ì˜, ë°ì´í„°ë¥¼ êµ¬ë³„(classification), í˜¹ì€ ê°ì§€(detection)í•  ìˆ˜ ìˆê²Œ í•  ê²ƒì¸ê°€? í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ë¬¼ë¡ , GANê³¼ ê°™ì€ Unsupervised Learningì—ì„œëŠ” ë§ì´ ë‹¬ë¼ ì§ˆ ìˆ˜ ìˆì§€ë§Œ, ì„¤ëª…ì„ ìœ„í•´ í¸ì˜ìƒ ê·¸ë ‡ë‹¤ê³  ìƒê°í•´ë´…ì‹œë‹¤. AIë¥¼ í•™ìŠµì‹œí‚¤ê³ ì í•˜ëŠ” ë°ì´í„°ë§Œ ì£¼ë©´, model ìŠ¤ìŠ¤ë¡œ â€˜ì•„, AëŠ” ì´ë ‡ê²Œ ìƒê²¼êµ¬ë‚˜, ì´ë ‡ê²Œ ìƒê¸°ë©´ Bë¼ê³  í•˜êµ¬ë‚˜â€™í•˜ê³  ê·¸ ë°ì´í„°ê°€ ê°€ì§€ê³  ìˆëŠ” íŠ¹ì§•(feature)ì„ ìŠ¤ìŠ¤ë¡œ ê¹¨ìš°ì¹˜ê¸° ì›í•˜ëŠ” ê±°ì£ . ê·¸ë ‡ê²Œ ì˜ í•™ìŠµì´ ì˜ ë˜ë©´, í•œ ë²ˆë„ ë³¸ ì ì€ ì—†ì§€ë§Œ ì—¬íƒœê» ë´ì™”ë˜ íŠ¹ì§•ì„ ê°€ì§€ê³  ìˆëŠ” ìƒˆë¡œìš´ ì´ë¯¸ì§€ë¥¼ ë´¤ì„ ë•Œ, â€˜ì•„, ì´ê±´ Aì•¼.â€™í˜¹ì€, â€˜Bì•¼â€™í•˜ê³  ë§ì¶œ ìˆ˜ ìˆê²Œ ë˜ëŠ” ê²ƒì´êµ¬ìš”. ë” ì‰½ê²Œ ì´ì•¼ê¸° í•´ë³´ì£ . ìš°ë¦¬ëŠ” ê°•ì•„ì§€ì™€ ê³ ì–‘ì´ê°€ ì–´ë–»ê²Œ ìƒê²¼ëŠ”ì§€ ìš°ë¦¬ modelì—ê²Œ ì•Œë ¤ì£¼ê³ , ì²˜ìŒë³´ëŠ” ê°•ì•„ì§€ë‚˜ ê³ ì–‘ì´ë¥¼ ë´ë„ ê·¸ ê²ƒì´ ê°•ì•„ì§€ì¸ì§€, ê³ ì–‘ì´ì¸ì§€ ì˜ êµ¬ë³„í•  ìˆ˜ ìˆì—ˆìœ¼ë©´ ì¢‹ê² ìŠµë‹ˆë‹¤. ì•„ë˜ ê·¸ë¦¼ì²˜ëŸ¼ ê°•ì•„ì§€ì™€, ê³ ì–‘ì´ ê·¸ë¦¼ì„ ì—„ì²­ë‚˜ê²Œ ë§ì´ ì£¼ê³  ìš°ë¦¬ëŠ” ìš°ë¦¬ê°€ ë§Œë“  Modelì—ê²Œ â€˜ê°•ì•„ì§€ëŠ” ì´ë ‡ê²Œ ìƒê¸´ê±°ì•¼â€™, â€˜ê³ ì–‘ì´ëŠ” ì´ë ‡ê²Œ ìƒê²¼ë‹¨ë‹¤.â€™í•˜ê³  ì•Œë ¤ì¤ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì´ ê³¼ì •ì„ í•™ìŠµ, í˜¹ì€ training - learningì´ë¼ê³  ë¶€ë¦…ë‹ˆë‹¤. ê·¸ë ‡ê²Œ ì˜ í•™ìŠµëœ ëª¨ë¸ì€, í›ˆë ¨í•  ë•Œ ë³¸ ì ì€ ì—†ì§€ë§Œ, ì²˜ìŒ ë³¸ ê°•ì•„ì§€ ì‚¬ì§„(test)ì„ ë´ë„ â€˜ì–˜ëŠ” ê°•ì•„ì§€ë„¤ìš”. ê³ ì–‘ì´ëŠ” ì•„ë‹ˆì—ìš”â€™ë¼ê³  ë§í•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤. (Image from KDnuggets) The purpose of deep learning is all about the question, â€œHow can we let our AI classify or detect the certain image or something?â€ Of course, there are exceptions like GAN, unspervised learning area, letâ€™s simplify the concept for the explanation. What we want to do is to create the model knowing the characteristics or feature of a particular class of data, so it can answer which class the data in. Letâ€™s talk more easily. We want to tell our model how puppies or cats look like and wish it can distinguish whether it is a puppy or a cat when it sees another puppy or another cat for the first time. As shown in the picture above, we give a lot of puppies and cats pictures to our model, and we teach the model, â€˜puppy looks like thisâ€™, and â€˜cat looks like this.â€™ This is called, learning or training. Then, as the process progresses, the model can distinguish the cat from the dog. Thatâ€™s all what we are going to talk about. In this post, Deep Learningì„ ì´í•´í•˜ê³ , ì§ì ‘ Deep Learningì„ êµ¬í˜„í•˜ê³ ì í–ˆì„ ë•Œ í•„ìš”í•œ ê¸°ë³¸ ê°œë…ë“¤ì„ ì •ë¦¬í•´ ë³´ì•˜ìŠµë‹ˆë‹¤. í•™ìŠµì´ë€ ë¬´ì—‡ì„ ì˜ë¯¸í•˜ëŠ”ì§€, OptimizerëŠ” ì–´ë–¤ ì—­í• ì„ í•˜ëŠ” ê²ƒì¸ì§€, Loss functionì€ ë¬´ì—‡ì¸ì§€, ê·¸ë¦¬ê³  ë§ˆì§€ë§‰ìœ¼ë¡œ Back propagationì€ ì–´ë–»ê²Œ ì§„í–‰ë˜ëŠ”ì§€, ê°„ë‹¨í•œ ì˜ˆì‹œë¥¼ í†µí•´ ì•Œì•„ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. :) In this post, I will talk about the basic concepts of deep learning. Letâ€™s start to learn what Learning means, Optimizer does, Loss function is, and How the Back propagation works via a simple example. Learning íŠ¹ì •í•œ ê°’ì„ ì˜ˆì¸¡ì„ í•˜ê³  ì‹¶ë‹¤ê³  í•˜ë©´, ìš°ë¦¬ëŠ” ë¨¼ì € ì‹¤ì œë¡œ ê·¸ëŸ¬í•œ ì˜ˆì¸¡ì„ í•  ìˆ˜ ìˆëŠ” Modelì´ í•„ìš”í•©ë‹ˆë‹¤. ê·¸ë¦¬ê³ , ê·¸ ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ê°’(prediction)ê³¼ ì‹¤ì œ ê°’(grounth truth or answer)ê³¼ì˜ ê°’ì˜ ì°¨ì´ë¥¼ lossë¼ê³  ë§í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ê°„ë‹¨í•œ ì„ í˜• ëª¨ë¸ì¸ y = wxì„ ìš°ë¦¬ê°€ ëª¨ë¸ë¡œ ê°€ì§€ê³  ìˆë‹¤ê³  í•©ë‹ˆë‹¤. yëŠ” ì‹¤ì œ ì •ë‹µì´ê³  xëŠ” inputê°’ ì…ë‹ˆë‹¤. ì´ ë•Œ, wë¥¼ ìš°ë¦¬ëŠ” weightë¼ê³  ë¶€ë¦…ë‹ˆë‹¤. ë³´í†µ ë§¨ ì²˜ìŒì—” ì´ wë¥¼ ëœë¤í•˜ê²Œ ê³ ë¦…ë‹ˆë‹¤. wê°€ ë§¤ìš° ì ì ˆí•˜ê²Œ ì˜ ì •í•´ì ¸ì„œ ì‹¤ì œ ì •ë‹µì¸ yì™€ wxê°€ ë˜‘ê°™ì€ ê°’ì´ ë˜ì—ˆë‹¤ë©´ $loss$ëŠ” 0ì´ ë˜ê² ì£ ! ê·¸ë˜ì„œ Inputì¸ xë¥¼ ì£¼ë©´ ì •ë‹µì¸ yë¥¼ ì˜ ë§ì¶”ë ¤ë©´, ë‹¹ì—°íˆ ìš°ë¦¬ëŠ” ì´ wë¥¼ ì˜ ë§ì¶œ í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤. ê·¼ë° ìœ„ì—ì„œ ë§í•œ ê²ƒ ì²˜ëŸ¼ wë¥¼ ëœë¤í•˜ê²Œ ì‹œì‘í•´ì„œëŠ” ê³¤ë€í•˜ì£ . í•œ ë²ˆ ë§Œì— ì˜ ë§ì¶˜ë‹¤ëŠ” ê±´ í˜ë“­ë‹ˆë‹¤. ê·¸ë˜ì„œ ìš°ë¦¬ëŠ” í•™ìŠµì„ ì§„í–‰ì„ í•¨ì— ë”°ë¼, ìš°ë¦¬ëŠ” ë¬´ì—‡ì´ ëì„ì§€ ëª¨ë¥´ëŠ” ì´ wê°’ì„ ë°˜ë³µì ìœ¼ë¡œ updateë¥¼ ì‹œì¼œì„œ, $loss$ë¥¼ ìµœì†Œí™” í•  ìˆ˜ ìˆê²Œë” ë§Œë“­ë‹ˆë‹¤. ê·¸ë˜ì„œ í•™ìŠµì´ë¼ëŠ” ê²ƒì€ lossë¥¼ ìµœì†Œí™” ì‹œí‚¤ëŠ” w ì°¾ê¸°! ë¼ê³  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. When we predict some values, firstly we need a model that can actually do predict, and we call the difference with a prediction and an actual value, ground truch, loss. For example, if we have a linear model y = wx, y is the answer, and x is input. Then, we call the w weight. If the weight is set very properly, then the loss will be 0! We often choose the inital value of w randomly. As the training proceeds, we repeatedly update this w so that we can find minimizes the loss. Therefore, Learning is finding w that minimizes the loss! Optimizer Weight update ì,ìš°ë¦¬ëŠ” $loss$ë¥¼ ìµœì†Œí™”ì‹œí‚¤ëŠ” $w$ë¥¼ ì•Œê³  ì‹¶ìŠµë‹ˆë‹¤. ê·¸ëŸ´ ë•Œ, $w$ê°€ ê°’ì—ë”°ë¼, ê·¸ë¦¼ê³¼ ê°™ì´ $loss$ì™€ $w$ì˜ ê°’ìœ¼ë¡œ ê·¸ë˜í”„ë¥¼ ê·¸ë ¸ë‹¤ê³  í–ˆì„ ë•Œ, Uìë¡œ í˜•ì„±ëë‹¤ê³  ìƒê°í•˜ê³ , $loss$ë¥¼ ìµœì†Œí™”í•˜ëŠ” $w$ì˜ ê°’ìœ¼ë¡œ $w$ë¥¼ updateí•˜ê³  ì‹¶ìŠµë‹ˆë‹¤. ì‹œì‘ì ì€ í¸ì˜ìƒ, ëœë¤í•˜ê²Œ ì •í•´ì¡Œë‹¤ê³  í•©ì‹œë‹¤. wê°’ì„ updateì‹œí‚¤ê¸° ìœ„í•´ì„œ, ìš°ë¦¬ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ê³µì‹ì„ ì”ë‹ˆë‹¤. ì—¬ê¸°ì„œ $\\alpha$ê°€ ëœ»í•˜ëŠ” ê²ƒì€ learning rateë¼ê³  í•˜ëŠ” ê²ƒì¸ë°ìš”, ë³´í†µ 0.001ê°™ì€ ì•„ì£¼ ì‘ì€ ê°’ì´ê³ , ê·¸ë˜ì„œ ë‹¤ìŒ í•™ìŠµí•  ë•Œ ì“¸ wëŠ” ì§€ê¸ˆ wì™€ ì–¼ë§ˆë§Œí¼ ë–¨ì–´ì ¸ìˆëŠ”ì§€ì •ë„ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤. $w = w - \\alpha \\cdot \\frac {\\partial loss}{\\partial w}$ ì´ wê°’ì€ ë¯¸ë¶„ì„ í•˜ë©´ êµ¬í•  ìˆ˜ ìˆëŠ”ë°ìš”, ë¯¸ë¶„ì˜ ì˜ë¯¸ëŠ” ê²°êµ­ ì•„ì£¼ ì‘ì€ êµ¬ê°„ì—ì„œì˜ ìˆœê°„ë³€í™”ìœ¨ì´ë¼ê³  ìš°ë¦¬ê°€ ì•Œê³  ìˆëŠ” ë§Œí¼, ì´ëŠ” ë¯¸ë¶„ì€ ê³§, ê¸°ìš¸ê¸°ì˜ ì •ë„ë¥¼ í‘œí˜„í•œë‹¤ê³  í•  ìˆ˜ ìˆì£ . ì´ $w$ê°’ì„ êµ¬í•˜ê¸° ìœ„í•œ ë¯¸ë¶„ ë°©ë²•ì€ ì•„ë˜ì— ë‚˜ì˜¤ëŠ” Back Propagationì„ ì†Œê°œí•˜ë©´ì„œ ë‹¤ì‹œ ì´ì•¼ê¸° í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. ì‘ì€ ì˜ˆì‹œë¡œ, Back Propagationì´ â€˜ë‚´ê°€ ì§€ê¸ˆ ì•Œê³  ìˆëŠ” ì§€ì‹ì„ ê°€ì§€ê³  ëŒ€í•™êµ ì¡¸ì—… í›„ì˜ ë‚˜ë¡œ ëŒì•„ ê°ˆ ìˆ˜ ìˆë‹¤ë©´, í›¨ì”¬ ë” ì¢‹ì€ ì„ íƒê³¼ ê²°ì •ì„ í•˜ë©´ì„œ ì‚´ ìˆ˜ ìˆì„ ê²ƒì´ë‹¤.â€™ ê°™ì€ ê²ë‹ˆë‹¤. ì—¬ê¸°ì„œ, ê·¼ë° ì´ learning rateì„ ë„ˆë¬´ í¬ê²Œ ì„¤ì •í•´ì¤˜ì„œ, í•„ìš”ì´ìƒìœ¼ë¡œ êµ° ì…ëŒ€ í•˜ë£¨ ì „ìœ¼ë¡œ ëŒì•„ê°„ë‹¤ë©´ ë”ì°í•˜ê² ì£ ? ê·¸ ê³¼ê±°ë¡œ â€˜ì ì ˆíˆâ€™ ëŒì•„ê°€ì•¼ ì§€ê¸ˆ ê°€ì§€ê³  ìˆëŠ” ì •ë³´ë¥¼ ì‹­ë¶„ í™œìš©í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì—, ì´ learning rateë¼ëŠ” ìˆ˜ì¹˜ê°€ ì¤‘ìš”í•©ë‹ˆë‹¤. Let me think we want to know the value of weigh which minimizes the loss. If we draw a graph consists of loss and w, let us consider it looks like a bowl like the image above. Then, we want to update the weight to the point which becomes the value minimizing the loss. Of course, the starting point is randomly selected. To update the w value, we use follwing equation. alpha means learning rate which is usually very small number like 0.001, so it means that How far the next step w is from where now w is. $w = w - \\alpha \\cdot \\frac {\\partial loss}{\\partial w}$ As we know, the meaning of derivative is Instantaneous rate of change, inclination. Let me introduce the way how to calculate the derivative of w, later on the Back propagation part. SGD ë¯¸ë¶„ì„ ì´ìš©í•˜ì—¬, ë§Œì•½ ë¯¸ë¶„ ê²°ê³¼ê°’ì´ -ì¸ ê²½ìš°, wëŠ” ì¢€ë” ì–‘ìˆ˜ìª½ìœ¼ë¡œ ê°€ê²Œ ë˜ê³ , ë°˜ëŒ€ë¡œëŠ” ìŒìˆ˜ë¡œ ê°€ëŠ” ë°©ì‹ìœ¼ë¡œ ìš°ë¦¬ëŠ” wë¥¼ updateí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŸ° update ë°©ë²•ì„ Stochastic Gradient Descent ìµœì í™” - í•œêµ­ì–´ë¡œëŠ” ê²½ì‚¬í•˜ê°•ë²• -, ë˜ëŠ” ì¤„ì—¬ì„œ SGDë¼ê³  ë¶€ë¦…ë‹ˆë‹¤. SGD ì´ì™¸ì— ìµœì í™” ê¸°ë²•ìœ¼ë¡œ Adam, Adamx ë“±ë“± ë‹¤ì–‘í•œ ê¸°ë²•ë“¤ì´ ìˆìŠµë‹ˆë‹¤ë§Œ, í´ë˜ì‹í•œ ì´ëŸ° ê²½ì‚¬í•˜ê°•ë²•ì˜ ë°©ì‹ì˜ ë‹¤ë¥¸ ë°©ì‹ì´ë¼ê³  ì´í•´í•´ë„ í¬ê²Œ í‹€ë¦¬ì§€ ì•ŠìŠµë‹ˆë‹¤. By using derivative, We can update the w in this way: if the drivative value(=gradient) is minus, then w will be move toward the posivie side, and visa versa. This kind of update approach is called Stochastic Gradient Descent Optimization, or SGD for short. There are other more various different Optimizers like Adam, Adamax and so on, but you might think that those are different to classical stochastic gradient descent. Loss function ì, ê·¸ëŸ¬ë©´ ìœ„ì—ì„œ ì„¤ëª…í•œ lossë¼ëŠ” ê²ƒì„ ê³„ì‚°í•˜ê¸° ìœ„í•´ì„œëŠ” ì–´ë–¤ ë°©ë²•ì„ ì‚¬ìš©í• ê¹Œìš”? Loss functionì„ ì„¤ëª…í•˜ê¸° ìœ„í•´ì„œ, ì‰¬ìš´ loss function í•˜ë‚˜ë¥¼ ì˜ˆì‹œë¡œ ë“¤ì–´ë´…ì‹œë‹¤. MSEëŠ” ëª¨ë¸ì˜ lossë¥¼ ì‚°ì¶œí•˜ëŠ” ë°©ë²• ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤. MSEëŠ” Mean Squared Errorì˜ ì¤€ ë§ë¡œ, ë¬¸ì ê·¸ëŒ€ë¡œ ì•„ë˜ì— ë³´ì´ëŠ” ìˆ˜ì‹ - ì˜ˆì¸¡í•œ ê°’ì—ì„œ ì‹¤ì œ ê°’ì„ ë¹¼ê³  ê·¸ ì°¨ì´ë¥¼ ì œê³±í•˜ì—¬ í‰ê· ì„ ë‚´ëŠ” ë°©ì‹ - ìœ¼ë¡œ ëª¨ë¸ì˜ lossë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. Here, what should we do to get the loss mentioned before? To explain loss function, letâ€™s take an easy loss function as an example. MSE is an one of ways to measure the loss of a model. The Acronym for the Mean Square Error which is following equation. y hat is a prediction of our model, and y is a real value. So, it means simply the sum of differences between forecasts and actual values. Binary classì— ëŒ€í•œ lossë¥¼ êµ¬í•´ì¤˜ì•¼ í•  ë•ŒëŠ”, MSE ë³´ë‹¤ëŠ” BCElossë¥¼ ë” ì˜ ì”ë‹ˆë‹¤. ì´ë ‡ê²Œ ë” ë‹¤ì–‘í•œ loss functionë“¤ì´ ìˆìŠµë‹ˆë‹¤. There are various other loss functions like BCEloss for binary loss, and so on. Back Propagation ì—­ì „íŒŒë¼ê³ ë„ í•˜ëŠ”, Back Progagationì€ lossë¥¼ weightë¡œ ë¯¸ë¶„í•œ ê°’ì„ ê³„ì‚°í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ìš°ë¦¬ì˜ ëª¨ë¸ì´ ì„ í˜•íšŒê¸°ì‹ì¸, Linear modelì´ë¼ê³  í•˜ê³ , ìš°ë¦¬ì˜ loss functionì´ MSEë¼ê³  í•©ì‹œë‹¤. ê·¸ëŸ¬ë©´ ìš°ë¦¬ ëª¨ë¸ì´ lossë¥¼ êµ¬í•  ë•Œ ê±°ì³ê°€ê²Œ ë  ê³µì‹ì€, $loss = (\\hat y - y)^2$ ì´ê¸° ë•Œë¬¸ì—, ì¦‰ $(x*w - y)^2$ì´ ë í…Œê³ , ì´ ì‹ì€ ì•„ë˜ì˜ ê·¸ë¦¼ê³¼ ê°™ì´ ë„ì‹í™” í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. Back propagation is the way to calculate the derivate value of loss by w. For example, our model is a linear model, and we use MSE as a loss function. Then, the gates of our model will look like following. x = 1, y = 2, ê·¸ë¦¬ê³  w = 1ì´ë¼ê³  í•©ì‹œë‹¤. ê·¸ëŸ¬ë©´ lossë¥¼ êµ¬í•˜ëŠ” forward pathëŠ” ëª…ë°±í•©ë‹ˆë‹¤. Letâ€™s assume that x = 1, y = 2, and w = 1. Then, the forward path is obvious. Derivate Computation Chain Ruleì— ì˜í•´ì„œ, ìš°ë¦¬ëŠ” ì°¨ê·¼ ì°¨ê·¼ wì˜ ë¯¸ë¶„ê°’ì„ ê³„ì‚°í•´ ë‚˜ê°ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. $loss\\text{ } function$ ê³µì‹ì—ì„œ ì‚¬ìš©í•˜ëŠ” operator í•˜ë‚˜ë¥¼, í•˜ë‚˜ì˜ gateë¼ê³  ìƒê°í•  ë•Œ, ê° gateë§ˆë‹¤ inputìœ¼ë¡œ ë“¤ì–´ì˜¤ê²Œ ë˜ëŠ” ê·¸ ê°’ì´ ìµœì¢… $loss$ ê°€ ì‚°ì¶œë˜ëŠ”ë° ì–¼ë§ˆë§Œí¼ì´ë‚˜ ê¸°ì—¬ë¥¼ í•˜ë‚˜. í•˜ëŠ” ì •ë„ê°€ ê³§ ìš°ë¦¬ê°€ ë¯¸ë¶„ì„ í•˜ëŠ” ì´ìœ ì…ë‹ˆë‹¤. ê·¸ë˜ì„œ ê²°êµ­ì€ ê·¸ë ‡ê²Œ wê°€ $loss\\text{ } function$ì—ì„œ inputìœ¼ë¡œ ë“¤ì–´ê°€ê²Œ ë  ë•Œì˜ ë¯¸ë¶„ê°’ì„ êµ¬í•˜ë©´, ê·¸ ê²ƒì€ ì¦‰, wê°€ lossë¥¼ êµ¬í•˜ëŠ”ë° ì–¼ë§ˆë‚˜ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ê°€(= ê¸°ìš¸ê¸°)ë¼ëŠ” ì˜ë¯¸ê°€ ë©ë‹ˆë‹¤. :D Back Propagationì€ ê°€ì¥ ìš°ì¸¡ì˜ gateì™€ í•¨ê»˜ lossë¡œë¶€í„° ì‹œì‘í•©ë‹ˆë‹¤. By using Chain Rule, we can calculate the derivative value of w, step by step. Let us consider the each operator in the loss function is a gate, then, we are going to calculate how much this input of each gate contributes to the loss. Thatâ€™s the reason why we do the derivative calculation. So, at last, we can get the derivative of w as an input of a gate, it means the amount of contribution of w to the final loss value. :D The back propagation starts from the loss with rightmost local gate. $x^2$ gate $loss$ì¸ 1ì€ sì¸ -1ì„ ì œê³±í•´ì„œ ë‚˜ì˜¨ ê°’ì´ë‹ˆê¹Œìš”, $loss = s^2$ ìœ¼ë¡œ ìƒê°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. lossë¥¼ ì œê³± gateë¡œ ë¯¸ë¶„í•œ ë‹¤ëŠ” ì˜ë¯¸ì˜ $\\frac{\\partial loss} {\\partial s}$ë¼ëŠ” ì‹ì€ ê³§, $\\frac{\\partial s^2} {\\partial s}$ë¼ëŠ” ì‹ê³¼ ê°™ë‹¤ê³  ìƒê°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. $\\frac{\\partial loss} {\\partial s}$ = $\\frac{\\partial s^2} {\\partial s}$ $s^2$ì„ $s$ë¡œ ë¯¸ë¶„í•œê±°ì£ ! ê·¸ëŸ¬ë©´ $\\frac{\\partial s^2} {\\partial s} = 2s$ ì´ê¸° ë•Œë¬¸ì—, ìš°ë¦¬ê°€ ì•Œê³  ìˆëŠ” s = -1ë¥¼ ëŒ€ì…í•˜ë©´, $x^2$gateì˜ local gradientëŠ” -2ê°€ ë©ë‹ˆë‹¤. $loss$ is 1, and s is -1, so, the local derative of square gate is -2. $\\frac{\\partial loss} {\\partial s}$ = $\\frac{\\partial s^2} {\\partial s} = 2s$ Again, s is -1. Therefore, the local gradient of - gate is -2. $-$ gate $x^2$gateì—ì„œ -2ê°€ - gateì— $loss$ë¡œ ë“¤ì–´ì™”ìŠµë‹ˆë‹¤. ê·¸ë¦¬ê³  ê·¸ - gateì˜ ê³„ì‚°ê²°ê³¼ëŠ” sì¸, -1 ì´ì—ˆêµ¬ìš”. ì, ì´ì œ Chain Ruleì„ ì‚¬ìš©í•´ì„œ - gateì˜ local gradientë¥¼ êµ¬í•´ë³¼ê¹Œìš”? ìš°ë¦¬ëŠ”, Chain Ruleì— ì˜í•´ì„œ, - gateì˜ local gradientë¥¼ ì•„ë˜ì™€ ê°™ì€ ì‹ìœ¼ë¡œ í‘œí˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. $\\frac{\\partial loss} {\\partial \\hat y} = \\frac{\\partial loss}{\\partial s}\\frac {\\partial s}{ \\partial \\hat y} \\Rightarrow -2\\cdot\\frac {\\partial \\hat y - \\partial y}{\\partial \\hat y} = -2\\cdot1 = -2$ $\\frac{\\partial loss}{\\partial s}$ì€ -2ë¼ëŠ” ê²ƒì„ $x^2$ gateì—ì„œ ì´ë¯¸ ì•Œê³  ìˆê¸°ë•Œë¬¸ì—, ë‚˜ë¨¸ì§€, së¥¼, $\\hat y$ë¡œ ë¯¸ë¶„í•œ ê²°ê³¼ë§Œ ê³„ì‚°í•´ì„œ ê³±í•˜ë©´ ëë‚©ë‹ˆë‹¤. sëŠ” $\\hat y - y$ ë¼ëŠ” ì‹ì˜ ê²°ê³¼ë‚˜ ë§ˆì°¬ê°€ì§€ì—ˆìœ¼ë‹ˆ, ì¹˜í™˜í•´ì„œ ìƒê°í•˜ë©´ í¸í•˜êµ¬ìš”. ê·¸ë˜ì„œ ê²°ê³¼ëŠ” -gateì—ì„œë„ ì—¬ì „íˆ local gradientëŠ” -2ê°€ ë˜êµ°ìš”! -2 is passed to the - gate as loss. In the - gate, $y$ is a constant value and $\\hat y$ is 1, so the derivative is -2. We already know that $\\frac{\\partial loss}{\\partial s}$ = -2, so, the thing we need to do is to calculate the $\\frac {\\partial \\hat y - \\partial y}{\\partial \\hat y}$.$\\frac{\\partial loss} {\\partial \\hat y} = \\frac{\\partial loss}{\\partial s}\\frac {\\partial s}{ \\partial \\hat y} \\Rightarrow -2\\cdot\\frac {\\partial \\hat y - \\partial y}{\\partial \\hat y} = -2\\cdot1 = -2$ $*$ gate ì ì´ì œ ë§ˆì§€ë§‰ìœ¼ë¡œ, wê°€ inputìœ¼ë¡œ ë“¤ì–´ê°„ * gateì˜ local gradientë¥¼ ê³„ì‚°í•˜ê³  wì˜ gradientë¥¼ ê³„ì‚°í•˜ëŠ” ê³¼ì •ì„ ëëƒ…ì‹œë‹¤. -gateì—ì„œ -2ê°€ $loss$ë¡œ ë„˜ì–´ì™”ê³ , ë˜ ë‹¤ì‹œ, ìš°ë¦¬ëŠ” ìœ„ì™€ ê°™ì€ ë°©ë²•ìœ¼ë¡œ Chain Ruleì„ ì“°ë©´, $\\frac {\\partial loss}{\\partial w} = \\frac{\\partial loss}{\\partial \\hat y}\\frac{\\partial \\hat y}{\\partial w}$ ë¡œ, í‘œí˜„í•  ìˆ˜ ìˆê³ , ë˜ ìš°ë¦° ì´ë¯¸ $\\frac{\\partial loss}{\\partial \\hat y}$ = -2 ë¼ëŠ” ê²ƒì„ ì•Œê³  ìˆìŠµë‹ˆë‹¤. ê·¸ë˜ì„œ ì—¬ê¸°ì„œ $\\hat y$ë¥¼ ì˜ë¯¸í•˜ëŠ” ì‹ì¸ $wx$ë¥¼ $w$ë¡œ ë¯¸ë¶„í•œ ê°’ë§Œ ì•Œë©´ë˜ëŠ”ë°, ê·¸ ê°’ì€ $x$ì´ë¯€ë¡œ ê·¸ëƒ¥ xì˜€ë˜, 1ë¥¼ ë„£ì–´ì£¼ë©´, $loss$ì— ëŒ€í•œ wì˜ ë¯¸ë¶„ê°’ì´ -2ë¼ëŠ” ê²°ê³¼ë¥¼ ì–»ìŠµë‹ˆë‹¤. ì´ëŸ° ì‹ìœ¼ë¡œ ìš°ë¦¬ëŠ” wì˜ ë¯¸ë¶„ê°’ì„ ê³„ì‚°í•´ ë‚˜ê°€ë©´ì„œ, $loss$ê°€ ìµœì†Œê°€ ë˜ëŠ” wë¥¼ ì°¾ìŠµë‹ˆë‹¤. Letâ€™s finish this process with calculating the local gradient of the * gate. As we know, -2 is given from the - gate, so, as the same way, using the Chain Rule again, we can write the equation like following.$\\frac {\\partial loss}{\\partial w} = \\frac{\\partial loss}{\\partial \\hat y}\\frac{\\partial \\hat y}{\\partial w}$ We already know the value of $\\frac{\\partial loss}{\\partial \\hat y}$ is -2, so, we just put the value of derivative of $wx$ with $w$, 1. Then, at last, we can know the derivative value of w is -2. In this way, we can find the weight point where the loss becomes minimum. Update weight ê·¸ë ‡ê²Œ ê³„ì‚°ì´ ëë‚œ Wì˜ lossë¥¼ ì–´ë–»ê²Œ updateí•´ì¤„ê¹Œìš”? ì•„ë˜ ë³´ì‹œëŠ” ê²ƒì²˜ëŸ¼ ë‹¨ìˆœíˆ $w = w - learning{:} rate * w.loss$ ë¡œ Updateë¥¼ í•˜ê²Œ ë©ë‹ˆë‹¤. ì•„ë˜ ì˜ˆì‹œì—ì„œëŠ” learning rateë¡œ 0.01ì„ ì¤¬ë„¤ìš”. ì´ê²ƒìœ¼ë¡œ Back Propagationì— ëŒ€í•œ ì„¤ëª…ì„ ë§ˆì¹˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. Then, how to update calculated weightâ€™s loss? Simply we can calculate simply like this. $w = w - learning{:} rate * w.loss$ . In the example above, it used 0.01 as a learning rate. document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","link":"/2018/02/06/Basic-Deep learning-01/"},{"title":"Hi, Docker! :) (2)","text":"ë¡œì»¬ ì €ì¥ì†Œ ì»¨í…Œì´ë„ˆë¡œ ë§ˆìš´íŠ¸í•˜ê¸° ë‚´ ì»¨í…Œì´ë„ˆ í™˜ê²½ ì´ë¯¸ì§€ë¡œ Uploadí•˜ê¸° ì•ˆë…•í•˜ì„¸ìš” :) Docker Tutorial, ë‘ ë²ˆì§¸âœŒì…ë‹ˆë‹¤! ì»¨í…Œì´ë„ˆë¥¼ ë§Œë“¤ê³  ì‘ì—…ì„ ì—´ì‹¬íˆ í–ˆëŠ”ë°, ê·¸ ì»¨í…Œì´ë„ˆê°€ ì‹¤ìˆ˜ë¡œ ì§€ì›Œì§„ë‹¤ë©´, ê·¸ ì»¨í…Œì´ë„ˆ ì•ˆì— ìˆë˜ ëª¨ë“  ìë£Œë“¤ì´ ì‚­ì œë˜ì—ˆë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤ ë™ê³µì§€ì§„ğŸ‘€ ê·¸ëŸ° ì¼ì„ ë¯¸ì—°ì— ë°©ì§€í•˜ê¸° ìœ„í•´ì„œ, ì €ì¥ì†Œë¥¼ ì»¨í…Œì´ë„ˆ ì™¸ë¶€ì— ë‘ëŠ” ê²ƒì´ ì•ˆì „í•˜ì£ ! ê·¸ë˜ì„œ, ì²« ë²ˆì§¸ë¡œ ìƒì„±í•œ Docker ì»¨í…Œì´ë„ˆì— ë‚´ ë¡œì»¬ í´ë” ì—°ë™í•˜ê¸°ë¥¼ í•¨ê»˜ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤. ë˜ ë‚´ê°€ ì“°ë˜ ê°œë°œí™˜ê²½ì„ ë– ë‚˜, ìƒˆë¡œìš´ ê³³ìœ¼ë¡œ ê°”ì„ë•Œì´ì§ ì¼ì¼íˆ í™˜ê²½ì„¤ì •ì„ ê·¸ ë•Œ í™˜ê²½ìœ¼ë¡œ ë‹¤ í•  í•„ìš” ì—†ì´ ìš°ë¦¬ëŠ” ë„ì»¤ë¥¼ ì“¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‘ ë²ˆì§¸ë¡œ ë‚´ê°€ ì‘ì—…í•˜ê³  ìˆëŠ” ì»¨í…Œì´ë„ˆì˜ ì„¤ì •ì„ Imageë¡œ Docker Hub or Registryì— ì—…ë¡œë“œí•´ì„œ ë‹¤ë¥¸ ê³³ì—ì„œë„ ì“¸ ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ë°©ë²•ì„ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤! Local Directory Mount (run -v) ë‚´ê°€ ê°€ì§€ê³  ìˆëŠ” Host OSìˆëŠ” í´ë”ë¥¼ ìƒì„±í•œ ì»¨í…Œì´ë„ˆì™€ ê³µìœ í•˜ë ¤ë©´ run ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•  ë•Œ -v ì˜µì…˜ì„ ì‚¬ìš©í•˜ë©´ ë©ë‹ˆë‹¤! í¬íŠ¸ ì„¤ì •ì„ í•  ë•Œì™€ ê°™ì´ :ì„ ê¸°ì¤€ìœ¼ë¡œ ì¢Œì¸¡ì—ëŠ” ë§ˆìš´íŠ¸í•˜ê³ ì í•˜ëŠ” í´ë”ê²½ë¡œë¥¼, ìš°ì¸¡ì—ëŠ” ë§ˆìš´íŠ¸ì‹œí‚¬ ì»¨í…Œì´ë„ˆ ê²½ë¡œë¥¼ ì ì–´ì£¼ë©´ ë©ë‹ˆë‹¤.123$ docker run -it \\ -v /path/to/folder:/root/work \\ image_ID_or_name /bin/bash Example ì œ ì»´í“¨í„° ë°”íƒ•í™”ë©´ì— Dataë¼ëŠ” í´ë”ì—ëŠ” CNN í•™ìŠµì„ ìœ„í•œ ì´ë¯¸ì§€ë“¤ì´ ë‹´ê²¨ìˆëŠ” trainì´ë¼ëŠ” í´ë”ê°€ ìˆìŠµë‹ˆë‹¤. ì´ í´ë”ë¥¼ ì´ì „ í¬ìŠ¤íŒ…ì—ì„œ ë‹¤ìš´ ë°›ì•˜ë˜ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•œ ì»¨í…Œì´ë„ˆì™€ ì—°ë™ì‹œì¼œë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. ë¨¼ì € ê°€ì§€ê³  ìˆëŠ” imagesì˜ IDë¥¼ í™•ì¸í•´ë³´ë‹ˆ, a8928a6d6eaaì´ë„¤ìš”. 12REPOSITORY TAG IMAGE ID CREATED SIZEcivisanalytics/civis-jupyter-python3 latest a8928a6d6eaa 8 days ago 3.37GB í•´ë‹¹ ì´ë¯¸ì§€ë¡œ ì»¨í…Œì´ë„ˆë¥¼ ìƒì„±í•˜ë©´ì„œ ë§ˆìš´íŠ¸ë¥¼ í•´ë³´ë©´, 123$ docker run -it -p 8888:8888 \\ -v /Users/chayesol/Desktop/Data:/root/work \\ a8928a6d6eaa /bin/bash ì‹¤ì œë¡œ 1.jpg, 2.jpgê°€ ë“¤ì–´ìˆëŠ” train í´ë”ê°€ /root/work/trainë¡œ ì˜ ë§ˆìš´íŠ¸ ëœ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. 1234567[work] # ls -a. .. train[work] # cd train [train] # ls -a. .. 1.jpg 2.jpg[train] # pwd/root/work/train ì´ í´ë”ëŠ” ì‹¤ì œë¡œ ê³µìœ ë˜ê³  ìˆëŠ” í´ë”ì´ê¸° ë•Œë¬¸ì—, ì´ í´ë” ì•ˆì— íŒŒì¼ì„ ì§€ìš°ë©´ ë‹¹ì—°íˆ ì»¨í…Œì´ë„ˆ ìƒì—ì„œë„ ì§€ì›Œì§‘ë‹ˆë‹¤. (Vise Versa) DockerëŠ” ë¡œì»¬ ë¿ë§Œì•„ë‹ˆë¼ AWS S3 Bucketê³¼ ì—°ë™ì‹œí‚¬ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ì‹œê°„ë‚˜ë©´..ì¿¨ëŸ­..ğŸ˜·ë‹¤ì‹œ í¬ìŠ¤íŒ…í•˜ê² ìŠµë‹ˆë‹¤.. ë‚´ ì»¨í…Œì´ë„ˆ í™˜ê²½ Uploadí•˜ê¸°!Layer? ì»¨í…Œì´ë„ˆëŠ” ì´ë¯¸ì§€ ê¸°ë°˜ìœ¼ë¡œ ìƒì„±ë˜ê¸° ë•Œë¬¸ì—, ë‚´ ì»¨í…Œì´ë„ˆ í™˜ê²½ì„ ì—…ë¡œë“œí•œë‹¤ëŠ” ê²ƒì€, ë‚´ ì»¨í…Œì´ë„ˆ í™˜ê²½ì˜ ì´ë¯¸ì§€ë¥¼ ë§Œë“ ë‹¤ê³  ìƒê°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. DockerëŠ” ì´ë¯¸ì§€ë¥¼ ë§Œë“¤ ë•Œ, ìµœì¢… ì´ë¯¸ì§€ë¥¼ ë§Œë“¤ê¸° ìœ„í•œ ëª…ë ¹ì–´ë“¤ì„ í•œë•€í•œë•€ ì‹¤í–‰í•©ë‹ˆë‹¤. ì´íƒœë¦¬ì¥ì¸ ì¦‰, ìµœì¢… ì´ë¯¸ì§€ë¥¼ ë§Œë“¤ê¸° ì‹œì‘í•œ ë§¨ì²˜ìŒ ê¸°ë°˜ì´ ë˜ì–´ì£¼ëŠ” ì´ë¯¸ì§€ë¡œ ì»¨í…Œì´ë„ˆë¥¼ ë§Œë“  ë‹¤ìŒ, ê·¸ ì»¨í…Œì´ë„ˆì—ì„œ ê·¸ ë‹¤ìŒ ë¶€í’ˆ(ëª…ë ¹ì–´)ì„ ê°€ì ¸ë‹¤ê°€ ì„¤ì¹˜í•´ì„œ ë‹¤ì‹œ ì´ë¯¸ì§€ë¥¼ ë§Œë“¤ê³ , ë˜ ê·¸ ë‹¤ìŒ ë¶€í’ˆ, ê·¸ ë‹¤ìŒ, ê·¸ ë‹¤ìŒ.. ì‹ì´ë¼ëŠ” ê±°ì£ . ì´ë ‡ê²Œ í•œ ê²¹, í•œ ê²¹ ì‹¸ì´ëŠ” êµ¬ì¡° ë•Œë¬¸ì—, ê·¸ ë¶€í’ˆì´ ë˜ëŠ” ëª…ë ¹ì–´ í•˜ë‚˜í•˜ë‚˜ë¥¼ layerë¼ê³  ë¶€ë¦…ë‹ˆë‹¤. ì—…ë¡œë“œ í•  ì´ë¯¸ì§€ ë§Œë“¤ê¸°(Dockerfile) DockerëŠ” ì´ë¯¸ì§€ íŒŒì¼ì„ Dockerfile ì´ë¼ëŠ” íŒŒì¼ì„ ë³´ê³  ìƒì„±í•©ë‹ˆë‹¤. Dockerfileì„ ì‘ì„±í•˜ê¸° ìœ„í•´ì„œëŠ” Dockerfile ëª…ë ¹ì–´ë“¤ì„ ì‚¬ìš©í•´ì„œ ë‚´ í™˜ê²½ì— ë§ê²Œ ì˜ ì ì–´ì¤˜ì•¼í•©ë‹ˆë‹¤. ì‹¤ìŠµì„ ìœ„í•´, ì—¬íƒœê¹Œì§€ëŠ” Tensorflowë§Œ ì‚¬ìš©í–ˆì§€ë§Œ, Pytorchë„ ì‚¬ìš©í•˜ê³  ì‹¶ì€ ì‚¬ìš©ìê°€ ìˆë‹¤ê³  ê°€ì •í•©ì‹œë‹¤. ê·¸ë ‡ë‹¤ë©´ ë‹¤ìŒê³¼ ê°™ì€ ì‹œë‚˜ë¦¬ì˜¤ë¡œ ì´ë¯¸ì§€ë¥¼ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. 1231. Jupyter notebookê³¼ Tensorflowê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ” ì´ë¯¸ì§€ë¥¼ Base Imageë¡œ ì‚¬ìš©2. Pytorchë¥¼ ì¶”ê°€ë¡œ ì„¤ì¹˜ (layer ì¶”ê°€)3. ì»¨í…Œì´ë„ˆ ìƒì„±ì‹œ, Jupyter notebook ìë™ ì‹¤í–‰í•˜ë„ë¡ ì„¸íŒ…. ì´ ì‹œë‚˜ë¦¬ì˜¤ì— í•´ë‹¹í•˜ëŠ” Dockerfileì„ ë¨¼ì € ë³´ê³ , í•˜ë‚˜ì”© ì„¤ëª…í•´ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. Dockerfile ìš°ë¦¬ê°€ ë§Œë“¤ Imageì˜ Dockerfileì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. ì›í•˜ì‹œëŠ” ê²½ë¡œì—ì„œ ë‹¤ìŒê³¼ ê°™ì€ Dockerfileì„ ë§Œë“¤ì–´ ì£¼ì„¸ìš”. (íŒŒì¼ ì´ë¦„ì„ â€œDockerfileâ€ë¡œ) 123456789101112131415161718# Base ImageFROM civisanalytics/civis-jupyter-python3LABEL maintainer=\"petercha90@gmail.com\"# Pytorch ì„¤ì¹˜RUN apt-get -y -qq update && \\ conda install -y pytorch-cpu torchvision-cpu -c pytorch# Data í´ë” ë³µì‚¬COPY ./Data /root/work/Data/# ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•  ë””ë ‰í† ë¦¬ ì„¤ì •WORKDIR /root/work# Jupyter notebook ê°€ë™EXPOSE 8888 22CMD jupyter notebook --NotebookApp.token='' \\ --ip=0.0.0.0 --port=8888 --allow-root FROM: 1FROM civisanalytics/civis-jupyter-python3:1.11.0 â€˜ì´ë¯¸ì§€ì˜ Baseë¥¼ ì–´ë””ë¡œë¶€í„° ê°€ì ¸ì˜¤ê² ëŠëƒâ€™ëŠ” ë§ì…ë‹ˆë‹¤. ì €ëŠ” Jupyter notebookê³¼ Tensorflowê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ” ì´ë¯¸ì§€ë¥¼ Base Imageë¡œ ì‚¬ìš©í•˜ë ¤ ì´ì „ í¬ìŠ¤íŒ…ì—ì„œ ì‚¬ìš©í•œ ì´ë¯¸ì§€ë¥¼ Baseë¡œ ì‚¼ê³  ìˆìŠµë‹ˆë‹¤. :ì•ì—ëŠ” ì´ë¯¸ì§€ ì´ë¦„ì´, ë’¤ì—ëŠ” ë²„ì „ì •ë³´ë¼ê³  ë³¼ ìˆ˜ ìˆëŠ” Tag ë¥¼ ì ì–´ì¤ë‹ˆë‹¤. LABEL: 1LABEL maintainer=\"petercha90@gmail.com\" ë³´í†µ MAINTANERë¼ëŠ” ëª…ë ¹ì–´ë¥¼ ì“°ì§€ë§Œ, ê³§ â€˜will be deprecatedâ€™ë¼ê³  í•˜ì—¬, ìì²´ì ìœ¼ë¡œ ì¶”ì²œí•˜ëŠ” LABELì„ ì‚¬ìš©í•´ ë´¤ìŠµë‹ˆë‹¤. LABELì˜ keyê°’ìœ¼ë¡œ maintainerë¥¼ ì£¼ê³ , valueë¡œ ì œ e-mailì„ ì¨ì„œ, ì´ ì´ë¯¸ì§€ì˜ ê´€ë¦¬ìê°€ ëˆ„êµ¬ì¸ì§€ ë°íˆê³  ìˆìŠµë‹ˆë‹¤. - ì¶”ê°€ ì •ë³´ê¸° ë•Œë¬¸ì— Buildí•˜ëŠ”ë° ì˜í–¥ì„ ì£¼ì§€ëŠ” ì•ŠìŠµë‹ˆë‹¤. RUN: 12RUN apt-get -y -qq update && \\ conda install -y pytorch-cpu torchvision-cpu -c pytorch ê°€ì¥ ë§ì´, ìì£¼ ì“°ëŠ” ëª…ë ¹ì–´ì…ë‹ˆë‹¤. RUN ë‹¤ìŒ ì íˆëŠ” ëª…ë ¹ì–´ë¥¼ ê·¸ëŒ€ë¡œ ì‹¤í–‰í•˜ê²Œ í•´ì¤ë‹ˆë‹¤. ë¨¼ì € ubuntu ë‹¤ìš´ì„ ìœ„í•´ apt-get updateë¥¼ í•´ì¤ë‹ˆë‹¤. -yëŠ” update ë„ì¤‘ ìƒê¸°ëŠ” yes/noë¥¼ ë¬»ëŠ” ì§ˆë¬¸ì— ë§‰í˜€ì„œ ë©ˆì¶”ì§€ ì•Šë„ë¡ ë¯¸ë¦¬ ëª¨ë‘ yesë¥¼ ì£¼ê¸° ìœ„í•¨ì´ê³ , -qqëŠ” ì„¤ì¹˜ ë‚´ì—­ ë“±ì˜ log ì¶œë ¥í•˜ì§€ ì•Šë„ë¡í•˜ëŠ” quiet ì˜µì…˜ì…ë‹ˆë‹¤. ê·¸ ë‹¤ìŒ, Pytorchë¥¼ ì„¤ì¹˜í•˜ëŠ” ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ë„ë¡ í•˜ê³  ìˆìŠµë‹ˆë‹¤. COPY: 1COPY ./Data /root/work/Data/ COPY ë‹¤ìŒì— ë‚˜ì˜¤ëŠ” ì²«ë²ˆì§¸ ê²½ë¡œì— ìˆëŠ” íŒŒì¼ì„ ë‘ë²ˆì§¸ë¡œ ì íŒ ì»¨í…Œì´ë„ˆ ìƒì˜ ê²½ë¡œë¡œ ë³µì‚¬í•©ë‹ˆë‹¤. ì €ëŠ” ë°”íƒ•í™”ë©´ì— ìˆëŠ” Data í´ë”(í˜„ì¬ Dockerfileì´ ìˆëŠ” ê²½ë¡œê°€ ë°”íƒ•í™”ë©´ì´ë¼ì„œ ./Data)ë¥¼ /root/work/Data/ë¡œ ë³µì‚¬í•˜ê²Œ í–ˆìŠµë‹ˆë‹¤. ë‘ ë²ˆì§¸ ê²½ë¡œì— í•´ë‹¹í•˜ëŠ” ë””ë ‰í† ë¦¬ê°€ ì—†ë‹¤ë©´ ìë™ ìƒì„±í•©ë‹ˆë‹¤. ì‹¤ì œë¡œ /root/work/ì—ëŠ” Dataë¼ëŠ” ì´ë¦„ì˜ í´ë”ê°€ ì—†ì§€ë§Œ ì´ë²ˆ ì´ë¯¸ì§€ Buildê³¼ì •ì„ í†µí•´ ìƒì„±í•˜ê²Œ ë©ë‹ˆë‹¤. WORKDIR: 1WORKDIR /root/work RUN, COPY, CMD ë“±ì˜ ëª…ë ¹ì–´ë“¤ì„ ì‹¤í–‰í•  ê²½ë¡œë¥¼ ì§€ì •í•´ì¤ë‹ˆë‹¤. ì ‘ì†í–ˆì„ ë•Œ, ë§¨ ì²˜ìŒ ìœ„ì¹˜í•˜ê²Œ ë˜ëŠ” ê²½ë¡œì´ê¸°ë„ í•©ë‹ˆë‹¤. ê·¸ ë‹¤ìŒ ëª…ë ¹ì–´ ìƒì—ì„œ ê²½ë¡œ ì´ë™ì´ ìƒê¸°ë”ë¼ë„, ê·¸ ë‹¤ìŒ ëª…ë ¹ì–´ì—ì„œ ìë™ìœ¼ë¡œ ì—¬ê¸° ì ì€ ê²½ë¡œë¡œ ìœ„ì¹˜ê°€ ì´ˆê¸°í™”ë©ë‹ˆë‹¤. EXPOSE: 1EXPOSE 8888 22 ì»¨í…Œì´ë„ˆ ì‹¤í–‰ì‹œ, ìš”ì²­ì„ ê¸°ë‹¤ë¦¬ëŠ” portë¥¼ ë¯¸ë¦¬ ì—´ì–´ì¤ë‹ˆë‹¤. ì—¬ëŸ¬ê°œë¥¼ ì„¤ì • í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ì €ëŠ” ê·¸ ë‹¤ìŒ í¬ìŠ¤íŒ…ì—ì„œ ë‚˜ì˜¬ ê°œë…ì¸ sshì ‘ì†ì„ ìœ„í•´ì„œ 22ë²ˆ portë„ ì—´ì–´ì£¼ê¸°ë¡œ í–ˆìŠµë‹ˆë‹¤. CMD: 12CMD jupyter notebook --NotebookApp.token='' \\ --ip=0.0.0.0 --port=8888 --allow-root ì»¨í…Œì´ë„ˆê°€ ì‹¤ì œë¡œ ì‹¤í–‰ë˜ì—ˆì„ ë•Œ, CMDì— ì íŒ ëª…ë ¹ì–´ë“¤ì„ ì‹¤í–‰í•©ë‹ˆë‹¤. ìœ„ì—ì„œ ë§í–ˆë“¯ì´, ì»¨í…Œì´ë„ˆ ìƒì„±ì‹œ Jupyter notebookì„ ìë™ ì‹¤í–‰í•˜ë„ë¡ ì„¸íŒ…í•˜ê¸° ìœ„í•´ ë¯¸ë¦¬ CMDë¡œ í•´ë‹¹ ëª…ë ¹ì–´ë¥¼ ì ì–´ë†“ì•˜ìŠµë‹ˆë‹¤. ê·¸ ì™¸ì—ë„ ìì£¼ ì“°ëŠ” ëª…ë ¹ì–´ë¡œ ADD, VOLUME, ENV ë“±ì´ ìˆìŠµë‹ˆë‹¤. ë” ë§ì€ ì •ë³´ëŠ” ê³µì‹ë¬¸ì„œë¥¼ ì°¸ê³ í•´ì£¼ì„¸ìš”. ### Build! ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” ëª…ë ¹ì–´ buildì™€ ì´ë¦„ì„ ì„¤ì •í•´ì£¼ëŠ” -t(tag)ì˜µì…˜ì„ ì‚¬ìš©í•œ ì•„ë˜ ëª…ë ¹ì–´ë¡œ Dockerfileì„ ì‹¤í–‰ ì‹œí‚¤ë©´, 1$ docker build -t docker101 . ì‹œê°„ì´ ê½¤ ê±¸ë¦½ë‹ˆë‹¤..â³ 123456...Removing intermediate container a39920cdab45 ---> 547c429ef2eeSuccessfully built 547c429ef2eeSuccessfully tagged docker101:latest$ ë¼ëŠ” ë©”ì„¸ì§€ê°€ ë‚˜ì˜¤ë©´ ì„±ê³µì ìœ¼ë¡œ Imageë¥¼ ìƒì„±í•œ ê²ƒì…ë‹ˆë‹¤! docker imagesë¡œ ìƒì„±í•œ ì´ë¯¸ì§€ë¥¼ í™•ì¸í•´ë´…ë‹ˆë‹¤. ì™€ìš°â€¦ 3.37GB Base-imageì— Pytorchë¥¼ ì„¤ì¹˜í•´ì„œ 4.71GB SIZEê°€ ë¼ë²„ë¦° ëš ëš ì´ğŸ· docker101 Imageê°€ ë³´ì´ë„¤ìš”! 1234$ docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEdocker101 latest 547c429ef2ee 13 minutes ago 4.71GBcivisanalytics/civis-jupyter-python3 latest a8928a6d6eaa 10 days ago 3.37GB ê·¸ë ‡ë‹¤ë©´â€¦! ë–¨ë¦¬ëŠ” ë§˜ìœ¼ë¡œ Jupyter notebookì„ ìë™ ì‹¤í–‰ë˜ë„ë¡ ì„¤ì •í•œ ê²ƒê¹Œì§€ ì˜ ë˜ëŠ”ì§€ í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤! íŒì½˜ê°ğŸŸ 1$ docker run --name first_one -d -p 8888:8888 docker101 ì—­ì‹œ localhost:8888ë¡œ ì ‘ì†ì„í•˜ë‹ˆ ë°”ë¡œ Jupyter notebookìœ¼ë¡œ ì ‘ì†ì´ ë˜ë„¤ìš”! ì˜ë„í•œ CMD ì„¸íŒ…ì´ ì˜ ë˜ì–´ ìˆë‹¤ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ğŸ˜ ë§¨ì²˜ìŒ COPYë¡œ ë³µì‚¬í–ˆë˜ Data í´ë”ê°€ ë¨¼ì € í™˜ì˜í•´ ì£¼ë„¤ìš” :) ê·¸ ì•ˆì— í•™ìŠµìš© ë°ì´í„°ë“¤ë„ ì˜ ë³µì‚¬ê°€ ë˜ì–´ìˆëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìƒˆ Python notebookì„ ë§Œë“¤ì–´ Pytorchê¹Œì§€ ì˜ ì„¤ì¹˜ë˜ì–´ìˆëŠ”ì§€ í™•ì¸í•´ ë³´ë©´..ë§™ì†Œì‚¬â€¦ Pytorchì™€ Tensorflow, ë‘˜ ë‹¤ ì˜ ì‘ë™í•˜ëŠ”êµ°ìš”! ì„±ê³µì ì…ë‹ˆë‹¤!ğŸ‚ğŸ‰ğŸŠğŸ…ğŸ Upload ì˜ë§Œë“  ì´ë¯¸ì§€ë¥¼ ê³µìœ í•˜ëŠ” ë°©ë²•ìœ¼ë¡œ ì•„ë˜ì™€ ê°™ì€ ë‘ ê°€ì§€ ë°©ë²•ì´ ìˆìŠµë‹ˆë‹¤. Docker Registry ë¥¼ ì„¤ì¹˜í•˜ì—¬ ì—…ë¡œë“œí•œë‹¤. (like Git) Docker Hub ì— ì—…ë¡œë“œ í•œë‹¤. (like Github) Docker Registry Docker RegistryëŠ” gitì²˜ëŸ¼ ì„¤ì¹˜í˜•ìœ¼ë¡œ, ë§Œë“  ì´ë¯¸ì§€ë¥¼ Registry ì„œë²„ë¡œ pushí•˜ê³ , ë‹¤ë¥¸ ì„œë²„ì—ì„œ pullì„ ë°›ì•„ì„œ ì‚¬ìš©í•©ë‹ˆë‹¤. Docker Hub Docker HubëŠ” ë„ì»¤ì—ì„œ ì œê³µí•˜ëŠ” ê¸°ë³¸ ì´ë¯¸ì§€ ì €ì¥ì†Œë¡œ, íšŒì›ê°€ì…ë§Œí•˜ë©´, ëŒ€ìš©ëŸ‰ì˜ ì´ë¯¸ì§€ë„ ë¬´ë£Œë¡œ ì—…ë¡œë“œí•˜ê³  ë‹¤ìš´ë¡œë“œ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë§ˆì¹˜ Githubì²˜ëŸ¼ ì›¹ìƒì—ì„œ ë‹¤ìš´ë°›ì„ ìˆ˜ë„ ìˆê³ , docker ëª…ë ¹ì–´ë¡œ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œ í•˜ê³ , ë‹¤ìš´ ë°›ì„ ìˆ˜ ìˆëŠ” ê³µê°„ì…ë‹ˆë‹¤. ì´ë²ˆ í¬ìŠ¤íŒ…ì—ì„œëŠ” Docker Hubë¥¼ ì‚¬ìš©í•˜ì—¬ ì—…ë¡œëŠ” í•˜ëŠ” ë°©ë²•ë§Œ ë‹¤ë¤„ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤! Docker Hub Uploading Docker Hubì— ë§Œë“  ì´ë¯¸ì§€ë¥¼ ì˜¬ë¦¬ëŠ” ê²ƒì€ 3ê°€ì§€ ë‹¨ê³„ë§Œ ê±°ì¹˜ë©´ ëì…ë‹ˆë‹¤. 1. Login 2. Renaming 3 Push. Login (login) ë¨¼ì € Docker Hub í™ˆí˜ì´ì§€ì—ì„œ íšŒì›ê°€ì…ì„ í•˜ì‹œê³  ì•„ë˜ ëª…ë ¹ì–´ë¥¼ ì…ë ¥í•˜ë©´ Docker Hub ê³„ì •ì— ë¡œê·¸ì¸ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 12345$ docker loginLogin with your Docker ID to push and pull images from Docker Hub. If you don't have a Docker ID, head over to https://hub.docker.com to create one.Username: petercha90Password:Login Succeeded Renaming (tag) Docker Hubì— ì˜¬ë¦´ ì´ë¯¸ì§€ëŠ”, [User_ID]/[Image_name]:[tag]* ë¼ëŠ” ê·œì¹™ìœ¼ë¡œ ì´ë¦„ì„ êµ¬ì„±í•©ë‹ˆë‹¤. tag ëª…ë ¹ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ ê¸ˆë°© ë§Œë“¤ì—ˆë˜ docker101 ì´ë¯¸ì§€ì˜ ì´ë¦„ì„ ê·œì¹™ì— ë§ê²Œ ë°”ê¿”ì£¼ë©´ì„œ, ë²„ì „ ì •ë³´(1.0)ë„ ì…ë ¥í•´ë³´ê² ìŠµë‹ˆë‹¤. 1$ docker tag docker101 petercha90/peter-tensorflow-pytorch:1.0 docker imagesë¡œ í™•ì¸í•´ë³´ë‹ˆ, docker101ê³¼ ìš©ëŸ‰ë„ ê°™ì€ë° ì´ë¦„ì´ petercha90/peter-tensorflow-pytorchì´ê³ , TAGê°€ 1.0ì¸ ì´ë¯¸ì§€ë¥¼ í™•ì¸í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. 1234 $ docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEdocker101 latest 34bbb1c093da 20 minutes ago 4.71GBpetercha90/peter-tensorflow-pytorch 1.0 34bbb1c093da 20 minutes ago 4.71GB Push (push) ì´ì œ pushëª…ë ¹ì–´ë¡œ Docker Hubì— ì—…ë¡œë“œë§Œ í•˜ë©´ ë©ë‹ˆë‹¤! 1$ docker push petercha90/peter-tensorflow-pytorch:1.0 ë˜ ì‹œê°„ì´ ì¢€ ê±¸ë¦½ë‹ˆë‹¤.. â€¦â€¦ â³ 1234567891011121314151617181920The push refers to repository [docker.io/petercha90/peter-tensorflow-pytorch]fdd4a938bd06: Pushed be825b2f1c27: Pushed a3442dbff3f9: Mounted from civisanalytics/civis-jupyter-python3 734b701f4670: Mounted from civisanalytics/civis-jupyter-python3 5d22569a8a20: Mounted from civisanalytics/civis-jupyter-python3 99645d10b61c: Mounted from civisanalytics/civis-jupyter-python3 43c65e275431: Mounted from civisanalytics/civis-jupyter-python3 5efecd288488: Mounted from civisanalytics/civis-jupyter-python3 ef945229e9cd: Mounted from civisanalytics/civis-jupyter-python3 dc2c8974046d: Mounted from civisanalytics/civis-jupyter-python3 2a83ea7d2735: Mounted from civisanalytics/civis-jupyter-python3 70191a7dc716: Mounted from civisanalytics/civis-jupyter-python3 c3a15ba40d5e: Mounted from civisanalytics/civis-jupyter-python3 603a1f4a3e0c: Mounted from civisanalytics/civis-jupyter-python3 b57c79f4a9f3: Mounted from civisanalytics/civis-jupyter-python3 d60e01b37e74: Mounted from civisanalytics/civis-jupyter-python3 e45cfbc98a50: Mounted from civisanalytics/civis-jupyter-python3 762d8e1a6054: Mounted from civisanalytics/civis-jupyter-python3 1.0: digest: sha256:ffc16d44d34f063a0856999b0f04fc71f322e4d1d47e026ffed6ad2ab89f6a81 size: 4094 ğŸ‰Ta-da!!ğŸ‰ Uploadê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ì´ì „ í¬ìŠ¤íŠ¸ì—ì„œ ì´ë¯¸ì§€ë¥¼ Pullí•˜ë©´ì„œ ì‹œì‘í•œ ê²ƒ ê¸°ì–µë‚˜ì‹œë‚˜ìš”? ê·¸ ê²ƒì²˜ëŸ¼ ì´ì œ ì–´ë””ì„œë“  ì¸í„°ë„·ë§Œ ì˜ ëœë‹¤ë©´, Anaconda3-Tensorflow-Pytorchì´ ì„¤ì¹˜ë˜ì–´ ìˆê³  + Jupyter notebook ìë™ì‹¤í–‰ì´ ë˜ëŠ”! ë³´ì•ˆì€ì–´ì©” ì´ë¯¸ì§€ë¥¼ ë‹¤ìš´ë°›ì•„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤! :sunglasses: ì—¬ê¸°ê¹Œì§€ ì´ì „ í¬ìŠ¤íŒ…ê³¼ í•¨ê»˜ Dockerì— ëŒ€í•´ ì•„ì£¼ ëŸ¬í”„í•˜ê²Œ í•¨ê»˜ ì•Œì•„ ë³´ì•˜ìŠµë‹ˆë‹¤. ë” êµ¬ì²´ì ì´ê³  ì„¤ì • ë°©ë²•ë“¤ê³¼ Dockerë¥¼ ì´ìš©í•œ ë‹¤ì–‘í•œ ì„œë¹„ìŠ¤ ê°œë°œì— ëŒ€í•´ì„œëŠ” Referenceë¥¼ ì°¸ê³ í•˜ì‹œë©´ ë˜ê² ìŠµë‹ˆë‹¤! References ì´ˆë³´ë¥¼ ìœ„í•œ ë„ì»¤ ì•ˆë‚´ì„œ - ì„¤ì¹˜í•˜ê³  ì»¨í…Œì´ë„ˆ ì‹¤í–‰í•˜ê¸° ì´ˆë³´ë¥¼ ìœ„í•œ ë„ì»¤ ì•ˆë‚´ì„œ - ì´ë¯¸ì§€ ë§Œë“¤ê³  ë°°í¬í•˜ê¸° document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","link":"/2019/05/09/docker-102/"}],"tags":[{"name":"machine-learning","slug":"machine-learning","link":"/tags/machine-learning/"},{"name":"ml","slug":"ml","link":"/tags/ml/"},{"name":"logarithm","slug":"logarithm","link":"/tags/logarithm/"},{"name":"log","slug":"log","link":"/tags/log/"},{"name":"useful-info","slug":"useful-info","link":"/tags/useful-info/"},{"name":"tutorial","slug":"tutorial","link":"/tags/tutorial/"},{"name":"Colab","slug":"Colab","link":"/tags/Colab/"},{"name":"deep_learning","slug":"deep-learning","link":"/tags/deep-learning/"},{"name":"blog","slug":"blog","link":"/tags/blog/"},{"name":"hexo","slug":"hexo","link":"/tags/hexo/"},{"name":"tensorflow","slug":"tensorflow","link":"/tags/tensorflow/"},{"name":"machine_learning","slug":"machine-learning","link":"/tags/machine-learning/"},{"name":"pandas","slug":"pandas","link":"/tags/pandas/"},{"name":"dataframe","slug":"dataframe","link":"/tags/dataframe/"},{"name":"basic","slug":"basic","link":"/tags/basic/"},{"name":"CNN","slug":"CNN","link":"/tags/CNN/"},{"name":"Batch","slug":"Batch","link":"/tags/Batch/"},{"name":"Epoch","slug":"Epoch","link":"/tags/Epoch/"},{"name":"Filter","slug":"Filter","link":"/tags/Filter/"},{"name":"Kernel","slug":"Kernel","link":"/tags/Kernel/"},{"name":"Padding","slug":"Padding","link":"/tags/Padding/"},{"name":"Pooling","slug":"Pooling","link":"/tags/Pooling/"},{"name":"keras","slug":"keras","link":"/tags/keras/"},{"name":"Docker","slug":"Docker","link":"/tags/Docker/"},{"name":"docker","slug":"docker","link":"/tags/docker/"},{"name":"ssh","slug":"ssh","link":"/tags/ssh/"},{"name":"container ssh","slug":"container-ssh","link":"/tags/container-ssh/"},{"name":"regularization","slug":"regularization","link":"/tags/regularization/"},{"name":"loss","slug":"loss","link":"/tags/loss/"},{"name":"L1","slug":"L1","link":"/tags/L1/"},{"name":"L2","slug":"L2","link":"/tags/L2/"},{"name":"Lasso","slug":"Lasso","link":"/tags/Lasso/"},{"name":"Ridge","slug":"Ridge","link":"/tags/Ridge/"},{"name":"convex_optimisation","slug":"convex-optimisation","link":"/tags/convex-optimisation/"},{"name":"pseudo-label","slug":"pseudo-label","link":"/tags/pseudo-label/"},{"name":"tensorpack","slug":"tensorpack","link":"/tags/tensorpack/"},{"name":"Optimizer","slug":"Optimizer","link":"/tags/Optimizer/"},{"name":"Loss function","slug":"Loss-function","link":"/tags/Loss-function/"},{"name":"Back propagation","slug":"Back-propagation","link":"/tags/Back-propagation/"},{"name":"mobilenet","slug":"mobilenet","link":"/tags/mobilenet/"}],"categories":[{"name":"Machine Learning","slug":"Machine-Learning","link":"/categories/Machine-Learning/"},{"name":"Tutorial","slug":"Tutorial","link":"/categories/Tutorial/"},{"name":"Deep Learning paper","slug":"Deep-Learning-paper","link":"/categories/Deep-Learning-paper/"}]}