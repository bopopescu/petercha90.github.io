<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"
  xmlns:atom="http://www.w3.org/2005/Atom"
  xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Stand firm Peter</title>
    <link>https://www.stand-firm-peter.me/</link>
    <atom:link href="/rss2.xml" rel="self" type="application/rss+xml"/>
    
    <description>Peter&#39;s playground.</description>
    <pubDate>Tue, 30 Jul 2019 08:27:18 GMT</pubDate>
    <generator>http://hexo.io/</generator>
    
    <item>
      <title>Hi, Keras! :) (1)</title>
      <link>https://www.stand-firm-peter.me/2019/06/12/keras_101/</link>
      <guid>https://www.stand-firm-peter.me/2019/06/12/keras_101/</guid>
      <pubDate>Wed, 12 Jun 2019 14:03:01 GMT</pubDate>
      <description>
      
        &lt;ul&gt;
&lt;li&gt;A Keras Usage with fashion MNIST&lt;/li&gt;
&lt;li&gt;Keras example using Colab&lt;/li&gt;&lt;/ul&gt;
      
      </description>
      
      <content:encoded><![CDATA[<ul><li>A Keras Usage with fashion MNIST</li><li>Keras example using Colab<a id="more"></a></li></ul><br><center><img src="/gallery/keras4.png" width="400"></center><br><ul><li><p>Pytorch와 Tensorflow의 Wrapper인 Tensorpack만 써봤던 저는, 올해 처음으로 <code>Keras</code>를 사용해보게 되었습니다. </p></li><li><p><strong><a href="https://tykimos.github.io/lecture/" target="_blank" rel="noopener"><code>블록과 함께 하는 파이썬 딥러닝 케라스</code></a></strong> 라는 책으로 공부하면서 그 간결함에 놀랐고, 대충대충 이해하고 넘어갔던 개념들이 좋은 예시로 설명되어 있어, 그 내용들을 정리해보고자 포스팅을 하게 되었습니다. </p></li><li><p>이번 포스팅은 책의 <strong><code>Part 1, 케라스 시작하기</code>와 <code>Part 2. 딥러닝 개념잡기</code>에 나오는 Keras 예제들을 Fashion MNIST 데이터로 재구성</strong>해 본 것입니다. <span class="github-emoji" style="color: transparent;background:no-repeat url(https://assets-cdn.github.com/images/icons/emoji/unicode/1f62c.png?v8) center/contain" data-src="https://assets-cdn.github.com/images/icons/emoji/unicode/1f62c.png?v8">😬</span> </p></li><li><p>책 내용 이외에 추가된 부분은, Colab의 Notebook으로 이번 포스팅이 구성이 되었다는 것이고, <a href="https://colab.research.google.com/drive/1AM1C3EiiA8wXtRP7UGYdAY0BwInpQ9t_#scrollTo=c7PIC9x4Os_R" target="_blank" rel="noopener">여기</a>에서 Colab Notebook으도 동일한 내용 확인하실 수 있습니다.</p></li><li><p>또, <code>matplotlib</code>의 plot 대신에, <code>Tensorboardcolab</code>을 사용하여서 plot 시각화를 하도록 방식을 바꿔보았습니다. </p><blockquote><p>흔쾌히 블로그 포스팅을 허락해주신 저자 김태영님께 다시 한 번 감사를 표합니다. <span class="github-emoji" style="color: transparent;background:no-repeat url(https://assets-cdn.github.com/images/icons/emoji/unicode/263a.png?v8) center/contain" data-src="https://assets-cdn.github.com/images/icons/emoji/unicode/263a.png?v8">☺</span></p></blockquote></li></ul><br><hr><h2 id="Import-packages"><a href="#Import-packages" class="headerlink" title="Import packages"></a>Import packages</h2><ul><li>자, 시작해볼까요! <span class="github-emoji" style="color: transparent;background:no-repeat url(https://assets-cdn.github.com/images/icons/emoji/unicode/1f60e.png?v8) center/contain" data-src="https://assets-cdn.github.com/images/icons/emoji/unicode/1f60e.png?v8">😎</span><figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> os</span><br><span class="line"><span class="hljs-keyword">import</span> keras</span><br><span class="line"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf</span><br><span class="line"><span class="hljs-keyword">import</span> keras.utils <span class="hljs-keyword">as</span> utils </span><br><span class="line"><span class="hljs-keyword">import</span> matplotlib.pyplot  <span class="hljs-keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm_notebook</span><br><span class="line"><span class="hljs-keyword">from</span> keras.datasets <span class="hljs-keyword">import</span> fashion_mnist</span><br><span class="line"><span class="hljs-keyword">from</span> keras.layers <span class="hljs-keyword">import</span> Dense, Activation</span><br><span class="line"><span class="hljs-keyword">from</span> keras.models <span class="hljs-keyword">import</span> Sequential, load_model</span><br><span class="line"></span><br><span class="line"><span class="hljs-comment"># remove error message from tensorflow</span></span><br><span class="line">tf.logging.set_verbosity(tf.logging.ERROR)</span><br><span class="line">%matplotlib inline</span><br></pre></td></tr></tbody></table></figure></li></ul><ul><li><p><strong>Output:</strong></p><figure class="highlight shell hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Using TensorFlow backend.</span><br></pre></td></tr></tbody></table></figure></li><li><p><strong>keras.utils</strong>:</p><ul><li>자주 사용되는 유용한 기능들 모음. 대표적으로 One-hot encoding을 해주는 to_categorical(), l1-l2 normalize를 가능하게 해주는 normalize() 등이 있다. </li></ul></li><li><p><strong>keras.datasets</strong>:</p><ul><li>MNIST,  Fashion MNIST, CIFAR10, CIFAR100, IMDB Movie reviews 긍정-부정 판별셋,   Reuters 뉴스토픽 분류셋, Boston 부동산가격 dataset을 불러올 수 있다.  </li></ul></li><li><p><strong>keras.layers</strong>:</p><ul><li>Dense부터 CNN, Pooling, Padding, RNN 등등.. 익숙한 딥러닝 layer들의 집합소.</li></ul></li><li><p><strong>keras.models</strong>:</p><ul><li>keras 모델을 만드는 방법은 크게, Sequential과 Model - functional API를 사용하는 방법 2가지로 나뉜다. Pytorch랑 비슷하다. </li><li>Sequential은 사용할 모델의 부품을 다 설정한 뒤 Input을 넣으면 한번에 레이어와 레이어 사이 설정을 세팅한 output에 맞게 맞춰주고, functional API인 Model을 사용하면 한땀한땀(?) 그 흐름을 구체적으로 설정할 수 있는 자유도를 가진다. </li><li>본 포스팅에서는 Sequential을 사용할 것이니, Model을 사용하는 예시는 <a href="https://keras.io/getting-started/functional-api-guide/" target="_blank" rel="noopener">여기</a>에서 확인.</li></ul></li></ul><br><h2 id="Loading-Data"><a href="#Loading-Data" class="headerlink" title="Loading Data"></a>Loading Data</h2><ul><li><p>Fashion MNIST </p><figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(x_train, y_train),  (x_test, y_test) = fashion_mnist.load_data()</span><br></pre></td></tr></tbody></table></figure><p><strong>Output:</strong></p><figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Downloading data <span class="hljs-keyword">from</span> http://fashion-mnist.s3-website.eu-central<span class="hljs-number">-1.</span>amazonaws.com/train-labels-idx1-ubyte.gz</span><br><span class="line"><span class="hljs-number">32768</span>/<span class="hljs-number">29515</span> [=================================] - <span class="hljs-number">0</span>s <span class="hljs-number">9</span>us/step</span><br><span class="line">Downloading data <span class="hljs-keyword">from</span> http://fashion-mnist.s3-website.eu-central<span class="hljs-number">-1.</span>amazonaws.com/train-images-idx3-ubyte.gz</span><br><span class="line"><span class="hljs-number">26427392</span>/<span class="hljs-number">26421880</span> [==============================] - <span class="hljs-number">5</span>s <span class="hljs-number">0</span>us/step</span><br><span class="line">Downloading data <span class="hljs-keyword">from</span> http://fashion-mnist.s3-website.eu-central<span class="hljs-number">-1.</span>amazonaws.com/t10k-labels-idx1-ubyte.gz</span><br><span class="line"><span class="hljs-number">8192</span>/<span class="hljs-number">5148</span> [===============================================] - <span class="hljs-number">0</span>s <span class="hljs-number">0</span>us/step</span><br><span class="line">Downloading data <span class="hljs-keyword">from</span> http://fashion-mnist.s3-website.eu-central<span class="hljs-number">-1.</span>amazonaws.com/t10k-images-idx3-ubyte.gz</span><br><span class="line"><span class="hljs-number">4423680</span>/<span class="hljs-number">4422102</span> [==============================] - <span class="hljs-number">2</span>s <span class="hljs-number">1</span>us/step</span><br></pre></td></tr></tbody></table></figure></li></ul><br><h2 id="Peeking-the-data"><a href="#Peeking-the-data" class="headerlink" title="Peeking the data"></a>Peeking the data</h2><ul><li>10개의 Fashion MNIST 데이터들을 시각화! <span class="github-emoji" style="color: transparent;background:no-repeat url(https://assets-cdn.github.com/images/icons/emoji/unicode/1f60f.png?v8) center/contain" data-src="https://assets-cdn.github.com/images/icons/emoji/unicode/1f60f.png?v8">😏</span><figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">class_names = [<span class="hljs-string">'T-shirt/top'</span>, <span class="hljs-string">'Trouser'</span>, <span class="hljs-string">'Pullover'</span>, <span class="hljs-string">'Dress'</span>, <span class="hljs-string">'Coat'</span>,</span><br><span class="line">               <span class="hljs-string">'Sandal'</span>, <span class="hljs-string">'Shirt'</span>, <span class="hljs-string">'Sneaker'</span>, <span class="hljs-string">'Bag'</span>, <span class="hljs-string">'Ankle boot'</span>]</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="hljs-number">8</span>, <span class="hljs-number">4</span>))</span><br><span class="line"><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">10</span>):</span><br><span class="line">    plt.subplot(<span class="hljs-number">2</span>, <span class="hljs-number">5</span>, i+<span class="hljs-number">1</span>)</span><br><span class="line">    plt.xticks([])</span><br><span class="line">    plt.yticks([])</span><br><span class="line">    plt.imshow(x_train[i], cmap=plt.cm.binary)</span><br><span class="line">    plt.xlabel(class_names[y_train[i]])</span><br><span class="line">    plt.grid(<span class="hljs-literal">False</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure></li></ul><center><img src="/gallery/keras2.png"></center><br><h2 id="Preprocessing"><a href="#Preprocessing" class="headerlink" title="Preprocessing"></a>Preprocessing</h2><ul><li><p>50000 for Training, 10000 for Validation, 10000 for Test</p><figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">x_val = x_train[<span class="hljs-number">50000</span>:]</span><br><span class="line">y_val = y_train[<span class="hljs-number">50000</span>:]</span><br><span class="line">x_train = x_train[:<span class="hljs-number">50000</span>]</span><br><span class="line">y_train = y_train[:<span class="hljs-number">50000</span>]</span><br><span class="line"></span><br><span class="line"><span class="hljs-comment"># preprocessing </span></span><br><span class="line">x_train = x_train.reshape(<span class="hljs-number">50000</span>, <span class="hljs-number">784</span>).astype(<span class="hljs-string">'float32'</span>) / <span class="hljs-number">255.0</span></span><br><span class="line">x_val = x_val.reshape(<span class="hljs-number">10000</span>, <span class="hljs-number">784</span>).astype(<span class="hljs-string">'float32'</span>) / <span class="hljs-number">255.0</span></span><br><span class="line">x_test = x_test.reshape(<span class="hljs-number">10000</span>, <span class="hljs-number">784</span>).astype(<span class="hljs-string">'float32'</span>) / <span class="hljs-number">255.0</span></span><br></pre></td></tr></tbody></table></figure></li></ul><ul><li><p>Label one-hot encoding (<strong>utils.to_categorical</strong>):<br>keras.utils.to_categorical <a href="https://keras.io/utils/#to_categorical" target="_blank" rel="noopener">API</a></p><figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># label one-hot encoding.</span></span><br><span class="line">y_train = utils.to_categorical(y_train)</span><br><span class="line">y_val = utils.to_categorical(y_val)</span><br><span class="line">y_test = utils.to_categorical(y_test)</span><br></pre></td></tr></tbody></table></figure></li></ul><br><h2 id="Callbacks"><a href="#Callbacks" class="headerlink" title="Callbacks"></a>Callbacks</h2><ul><li><p>Tensorboard 띄우기</p></li><li><p>Early Stopping / 5번을 기다려도 성능이 나아지지 않을 경우 학습 중단</p></li><li><p>Model Checkpoint  / val_loss가 가장 낮을 때만 저장</p>  <figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> tensorboardcolab <span class="hljs-keyword">import</span> *</span><br><span class="line"><span class="hljs-keyword">from</span> keras.callbacks <span class="hljs-keyword">import</span> EarlyStopping, ModelCheckpoint</span><br><span class="line"></span><br><span class="line"><span class="hljs-comment"># 3. Tensorboard 세팅</span></span><br><span class="line">tbc=TensorBoardColab()</span><br><span class="line"></span><br><span class="line"><span class="hljs-comment"># 4. Early Stopping  </span></span><br><span class="line">early_stopping = EarlyStopping(patience=<span class="hljs-number">5</span>) </span><br><span class="line"></span><br><span class="line"><span class="hljs-comment"># 5. Model Checkpoint</span></span><br><span class="line">path = <span class="hljs-string">'./model/'</span></span><br><span class="line"><span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> os.path.exists(path):</span><br><span class="line">    os.mkdir(path)    </span><br><span class="line">model_path = path + <span class="hljs-string">'{epoch:02d}-{val_loss:.4f}.h5'</span></span><br><span class="line">checkpoint = ModelCheckpoint(filepath = model_path, </span><br><span class="line">                               monitor = <span class="hljs-string">'val_loss'</span>,</span><br><span class="line">                               verbose = <span class="hljs-number">0</span>,</span><br><span class="line">                               save_best_only = <span class="hljs-literal">True</span>)</span><br></pre></td></tr></tbody></table></figure></li></ul><ul><li><strong>Output:</strong><figure class="highlight shell hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Wait for 8 seconds...</span><br><span class="line">TensorBoard link:</span><br><span class="line">https://57207182.ngrok.io</span><br></pre></td></tr></tbody></table></figure></li></ul><br><h2 id="Create-a-model-Train-Test"><a href="#Create-a-model-Train-Test" class="headerlink" title="Create a model / Train / Test"></a>Create a model / Train / Test</h2><ul><li><p><strong>Sequential()</strong> - 모델 생성</p></li><li><p><strong>add()</strong> - 모델 블럭끼우기</p></li><li><p><strong>compile()</strong> - 모델 학습에 쓸 도구 세팅하기</p></li><li><p><strong>fit()</strong> - 학습시키기</p></li><li><p><strong>evaluate()</strong> - 평가하기 </p>  <figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># GPU 사용</span></span><br><span class="line"><span class="hljs-comment"># with tf.device('/device:GPU:0'):</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-comment"># 1. 모델 구성</span></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Dense(units=<span class="hljs-number">64</span>, input_dim=<span class="hljs-number">28</span>*<span class="hljs-number">28</span>, activation=<span class="hljs-string">'relu'</span>))</span><br><span class="line">model.add(Dense(units=<span class="hljs-number">10</span>, activation=<span class="hljs-string">'softmax'</span>))</span><br><span class="line"></span><br><span class="line"><span class="hljs-comment"># 2. 모델 학습과정 설정하기 </span></span><br><span class="line">model.compile(loss=<span class="hljs-string">'categorical_crossentropy'</span>, </span><br><span class="line">              optimizer=<span class="hljs-string">'sgd'</span>, </span><br><span class="line">              metrics=[<span class="hljs-string">'accuracy'</span>])</span><br><span class="line"><span class="hljs-comment"># 3. 모델 학습시키기</span></span><br><span class="line"><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> tqdm_notebook(range(<span class="hljs-number">50</span>)):</span><br><span class="line">    hist = model.fit(x_train, y_train, epochs=<span class="hljs-number">1</span>, batch_size=<span class="hljs-number">32</span>, </span><br><span class="line">                     verbose=<span class="hljs-number">0</span>, validation_data=(x_test, y_test),</span><br><span class="line">                     callbacks=[TensorBoardColabCallback(tbc), </span><br><span class="line">                                early_stopping, checkpoint])</span><br><span class="line">    <span class="hljs-comment"># tensorboard lines</span></span><br><span class="line">    tbc.save_value(<span class="hljs-string">"fasion mnist"</span>, <span class="hljs-string">"train_acc"</span>, epoch, hist.history[<span class="hljs-string">'acc'</span>][<span class="hljs-number">0</span>])</span><br><span class="line">    tbc.save_value(<span class="hljs-string">"fasion mnist"</span>, <span class="hljs-string">"val_acc"</span>, epoch, hist.history[<span class="hljs-string">'val_acc'</span>][<span class="hljs-number">0</span>])</span><br><span class="line">    tbc.save_value(<span class="hljs-string">"fasion mnist"</span>, <span class="hljs-string">"train_loss"</span>, epoch, hist.history[<span class="hljs-string">'loss'</span>][<span class="hljs-number">0</span>])</span><br><span class="line">    tbc.save_value(<span class="hljs-string">"fasion mnist"</span>, <span class="hljs-string">"val_loss"</span>, epoch, hist.history[<span class="hljs-string">'val_loss'</span>][<span class="hljs-number">0</span>])</span><br><span class="line"></span><br><span class="line">    tbc.flush_line(<span class="hljs-string">"train_acc"</span>)</span><br><span class="line">    tbc.flush_line(<span class="hljs-string">"val_acc"</span>)</span><br><span class="line">    tbc.flush_line(<span class="hljs-string">"train_loss"</span>)</span><br><span class="line">    tbc.flush_line(<span class="hljs-string">"val_loss"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="hljs-keyword">if</span> (epoch+<span class="hljs-number">1</span>)%<span class="hljs-number">10</span> == <span class="hljs-number">0</span>:</span><br><span class="line">        print(<span class="hljs-string">'-----'</span>*<span class="hljs-number">5</span>)</span><br><span class="line">        print(<span class="hljs-string">"Epoch: {} | Loss: {:0.3f} | Acc: {:0.3f}"</span>.format(</span><br><span class="line">              epoch+<span class="hljs-number">1</span>, hist.history[<span class="hljs-string">'loss'</span>][<span class="hljs-number">0</span>], hist.history[<span class="hljs-string">'acc'</span>][<span class="hljs-number">0</span>]))</span><br><span class="line"></span><br><span class="line">loss_and_metrics = model.evaluate(x_test, y_test, batch_size=<span class="hljs-number">32</span>)</span><br><span class="line">tbc.close()</span><br><span class="line"></span><br><span class="line">print(<span class="hljs-string">'-----'</span>*<span class="hljs-number">10</span>)</span><br><span class="line">print(<span class="hljs-string">'\nLoss and metrics: '</span> + str(loss_and_metrics))</span><br></pre></td></tr></tbody></table></figure></li></ul><ul><li><strong>Output:</strong><figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">HBox(children=(IntProgress(value=<span class="hljs-number">0</span>, max=<span class="hljs-number">50</span>), HTML(value=<span class="hljs-string">''</span>)))</span><br><span class="line">-------------------------</span><br><span class="line">Epoch: <span class="hljs-number">10</span> | Loss: <span class="hljs-number">0.393</span> | Acc: <span class="hljs-number">0.864</span></span><br><span class="line">-------------------------</span><br><span class="line">Epoch: <span class="hljs-number">20</span> | Loss: <span class="hljs-number">0.342</span> | Acc: <span class="hljs-number">0.879</span></span><br><span class="line">-------------------------</span><br><span class="line">Epoch: <span class="hljs-number">30</span> | Loss: <span class="hljs-number">0.312</span> | Acc: <span class="hljs-number">0.890</span></span><br><span class="line">-------------------------</span><br><span class="line">Epoch: <span class="hljs-number">40</span> | Loss: <span class="hljs-number">0.288</span> | Acc: <span class="hljs-number">0.898</span></span><br><span class="line">-------------------------</span><br><span class="line">Epoch: <span class="hljs-number">50</span> | Loss: <span class="hljs-number">0.270</span> | Acc: <span class="hljs-number">0.905</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-number">10000</span>/<span class="hljs-number">10000</span> [==============================] - <span class="hljs-number">1</span>s <span class="hljs-number">60</span>us/step</span><br><span class="line">--------------------------------------------------</span><br><span class="line"></span><br><span class="line">Loss <span class="hljs-keyword">and</span> metrics: [<span class="hljs-number">0.3537946595430374</span>, <span class="hljs-number">0.8761</span>]</span><br></pre></td></tr></tbody></table></figure></li></ul><ul><li><p><strong>Tensorboard Plot:</strong></p>  <center><img src="/gallery/keras5.png"></center></li></ul><br><h2 id="Model-Structure-Visualization"><a href="#Model-Structure-Visualization" class="headerlink" title="Model Structure Visualization"></a>Model Structure Visualization</h2><ul><li><p>Model 구조 시각화하기: <strong>model.summary() & SVG()</strong> <span class="github-emoji" style="color: transparent;background:no-repeat url(https://assets-cdn.github.com/images/icons/emoji/unicode/1f603.png?v8) center/contain" data-src="https://assets-cdn.github.com/images/icons/emoji/unicode/1f603.png?v8">😃</span></p>  <figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> IPython.display <span class="hljs-keyword">import</span> SVG</span><br><span class="line"><span class="hljs-keyword">from</span> keras.utils.vis_utils <span class="hljs-keyword">import</span> model_to_dot</span><br><span class="line"></span><br><span class="line">print(model.summary())</span><br><span class="line">SVG(model_to_dot(model, show_shapes=<span class="hljs-literal">True</span>).create(prog=<span class="hljs-string">'dot'</span>, format=<span class="hljs-string">'svg'</span>))</span><br></pre></td></tr></tbody></table></figure></li><li><p><strong>Output:</strong></p><figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">_________________________________________________________________</span><br><span class="line">Layer (type)                 Output Shape              Param <span class="hljs-comment">#   </span></span><br><span class="line">=================================================================</span><br><span class="line">dense_1 (Dense)              (<span class="hljs-literal">None</span>, <span class="hljs-number">64</span>)                <span class="hljs-number">50240</span>     </span><br><span class="line">_________________________________________________________________</span><br><span class="line">dense_2 (Dense)              (<span class="hljs-literal">None</span>, <span class="hljs-number">10</span>)                <span class="hljs-number">650</span>       </span><br><span class="line">=================================================================</span><br><span class="line">Total params: <span class="hljs-number">50</span>,<span class="hljs-number">890</span></span><br><span class="line">Trainable params: <span class="hljs-number">50</span>,<span class="hljs-number">890</span></span><br><span class="line">Non-trainable params: <span class="hljs-number">0</span></span><br><span class="line">_________________________________________________________________</span><br><span class="line"><span class="hljs-literal">None</span></span><br></pre></td></tr></tbody></table></figure></li></ul><center><img src="/gallery/keras3.png" width="300px"></center><br><h2 id="Save-amp-Load-Model"><a href="#Save-amp-Load-Model" class="headerlink" title="Save & Load Model"></a>Save & Load Model</h2><ul><li><p>Model 저장 & 불러오기</p>  <figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> model.save(<span class="hljs-string">'fashion_mnist_model.h5'</span>)</span><br><span class="line">model = load_model(<span class="hljs-string">'fashion_mnist_model.h5'</span>)</span><br></pre></td></tr></tbody></table></figure></li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content:encoded>
      
      <comments>https://www.stand-firm-peter.me/2019/06/12/keras_101/#disqus_thread</comments>
    </item>
    
    <item>
      <title>Hi, Colab! :)</title>
      <link>https://www.stand-firm-peter.me/2019/06/12/Colab_tutorial/</link>
      <guid>https://www.stand-firm-peter.me/2019/06/12/Colab_tutorial/</guid>
      <pubDate>Wed, 12 Jun 2019 12:31:02 GMT</pubDate>
      <description>
      
        &lt;ul&gt;
&lt;li&gt;Cloud Jupyter Notebook powered by Google&lt;/li&gt;
&lt;li&gt;Colab Introduction&lt;/li&gt;
&lt;/ul&gt;
      
      </description>
      
      <content:encoded><![CDATA[<ul><li>Cloud Jupyter Notebook powered by Google</li><li>Colab Introduction</li></ul><a id="more"></a><h2 id="Colab이란-no-mouth"><a href="#Colab이란-no-mouth" class="headerlink" title="Colab이란? :no_mouth:"></a><a href="https://colab.research.google.com" target="_blank" rel="noopener">Colab</a>이란? <span class="github-emoji" style="color: transparent;background:no-repeat url(https://assets-cdn.github.com/images/icons/emoji/unicode/1f636.png?v8) center/contain" data-src="https://assets-cdn.github.com/images/icons/emoji/unicode/1f636.png?v8">😶</span></h2><ul><li><code>Jupyter Notebook</code>를 구글 드라이브에서 사용할 수 있는 것인데, 여태 있었던 구글 문서나 구글 스프레드시트처럼, 실시간 협업이 가능한 버전이라고 생각하면 된다고 합니다. 원래 구글 내부에서 직원들이 사용하던 것이라고 하네요! 그래서 error가 생기면 STACK OVERFLOW 버튼이 ..:+1:</li><li>그렇기 때문에, Jupyter Notebook나 다른 IDE에서 흔히 제공하는 Variable다음 <code>.</code>을 찍고, Tab키를 치면 하위요소(함수 or 변수)의 일부만 쳐도 나타나게 하는 친숙한 기능들도, 조금 반응이 느리긴 하지만, 0.5초 정도 뒤에 나타납니다. :D </li><li><strong>GPU, TPU 사용 설정</strong>을 하시려거든, 맨처음 Notebook을 생성하실 때, 선택하실 수도 있고, <code>수정 -> 노트 설정</code>을 누르시면 GPU, TPU 사용 설정을 할 수 있습니다. <span class="github-emoji" style="color: transparent;background:no-repeat url(https://assets-cdn.github.com/images/icons/emoji/unicode/1f604.png?v8) center/contain" data-src="https://assets-cdn.github.com/images/icons/emoji/unicode/1f604.png?v8">😄</span></li></ul><h2 id="Linux-명령어-사용하기-astonished"><a href="#Linux-명령어-사용하기-astonished" class="headerlink" title="Linux 명령어 사용하기 :astonished:"></a>Linux 명령어 사용하기 <span class="github-emoji" style="color: transparent;background:no-repeat url(https://assets-cdn.github.com/images/icons/emoji/unicode/1f632.png?v8) center/contain" data-src="https://assets-cdn.github.com/images/icons/emoji/unicode/1f632.png?v8">😲</span></h2><ul><li><p>Colab에서는 느낌표로 쓴 뒤에 명령어를 치면 terminal에서 작동하는 것으로 처리해줍니다. 로컬에서 Bash창을 켜서 설치하고 다시 Jupyter로 돌아와야했던 귀찮은 과정이 매우 심플해졌습니다! 하지만,</p>  <figure class="highlight shell hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">$</span><span class="hljs-bash"> cat sample.txt</span></span><br></pre></td></tr></tbody></table></figure><p>  같은 native Linux에서나 가능한 몇몇 문법들은 작동하지 않습니다. </p></li><li><p>그래서, 100% Linux native 명령어를 쓸 수 있는 것은 아니며, 어디까지나 그때 그때, <strong>필요한 library, package 설치 편의를 위한 수준</strong>이라고 볼 수 있을 것 같습니다.</p></li><li><p>리눅스 명령어에서 익숙한 분들은 당연히 경로 이동을 할때 <code>cd</code>를 쓸 텐데, <code>!cd</code>는 먹히지 않고, <code>os</code>를 <code>import</code>하신 뒤에, <code>os.chdir()</code>로 이동해야 합니다. </p></li><li><p>빈 폴더를 하나 만들고 그 안에 짧은 txt파일을 만들어 확인해 봅시다.</p><h4 id="Cell-1"><a href="#Cell-1" class="headerlink" title="Cell. 1"></a>Cell. 1</h4>  <figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> os</span><br><span class="line">!mkdir test</span><br><span class="line">os.chdir(<span class="hljs-string">'test'</span>)</span><br><span class="line">!pwd</span><br><span class="line"><span class="hljs-comment"># 명령어는 못찾는다고 나오지만 생성은 합니다 :)</span></span><br><span class="line">!<span class="hljs-string">'Sample text!'</span> > sample.txt</span><br></pre></td></tr></tbody></table></figure><p>  <strong>Output</strong>:</p>  <figure class="highlight shell hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">/content/test</span><br><span class="line">   /bin/bash: Sample text!: command not found</span><br><span class="line">   sample.txt</span><br></pre></td></tr></tbody></table></figure></li></ul><pre><code>#### Cell. 2<figure class="highlight shell hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 목록에는 파일이 확인되지만, </span></span><br><span class="line">!ls</span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> cat은 작동하지 않습니다. </span></span><br><span class="line">!cat sample.txt</span><br></pre></td></tr></tbody></table></figure>**Output:**<figure class="highlight shell hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sample.txt</span><br></pre></td></tr></tbody></table></figure></code></pre><h2 id="Colab-에서-쓸-수-있는-GPU-wink"><a href="#Colab-에서-쓸-수-있는-GPU-wink" class="headerlink" title="Colab.에서 쓸 수 있는 GPU :wink:"></a>Colab.에서 쓸 수 있는 GPU <span class="github-emoji" style="color: transparent;background:no-repeat url(https://assets-cdn.github.com/images/icons/emoji/unicode/1f609.png?v8) center/contain" data-src="https://assets-cdn.github.com/images/icons/emoji/unicode/1f609.png?v8">😉</span></h2><ul><li><p>일단 필요한 Util을 다운을 받고,</p><figure class="highlight shell hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi</span><br><span class="line">!pip install gputil</span><br><span class="line">!pip install psutil</span><br><span class="line">!pip install humanize</span><br></pre></td></tr></tbody></table></figure></li><li><p>Import 해줍시다. </p><figure class="highlight shell hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import psutil</span><br><span class="line">import humanize</span><br><span class="line">import os</span><br><span class="line">import GPUtil as GPU</span><br></pre></td></tr></tbody></table></figure></li></ul><ul><li><p><strong>GPU는 하나</strong>만 허락해 줍니다만… 갓글님의 그 하나는 에이스입니다. 2019.06.12 현재. 무려 <strong>T4</strong>. <span class="github-emoji" style="color: transparent;background:no-repeat url(https://assets-cdn.github.com/images/icons/emoji/unicode/1f62d.png?v8) center/contain" data-src="https://assets-cdn.github.com/images/icons/emoji/unicode/1f62d.png?v8">😭</span> 개인 실험용으로는 충분한 것 같습니다. </p><figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">GPUs = GPU.getGPUs()</span><br><span class="line">gpu = GPUs[<span class="hljs-number">0</span>]</span><br><span class="line"></span><br><span class="line">print(gpu.__dict__[<span class="hljs-string">"name"</span>])</span><br><span class="line">print(<span class="hljs-string">"The number of GPUs: {}"</span>.format(len(GPUs)))</span><br><span class="line">print(<span class="hljs-string">"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB"</span>.format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil* <span class="hljs-number">100</span>, gpu.memoryTotal))</span><br></pre></td></tr></tbody></table></figure><p>  <strong>Output</strong>:</p><figure class="highlight shell hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Tesla T4</span><br><span class="line">The number of GPUs: 1</span><br><span class="line">GPU RAM Free: 15079MB | Used: 0MB | Util   0% | Total 15079MB</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="참고사항"><a href="#참고사항" class="headerlink" title="참고사항"></a>참고사항</h3><ul><li><p>안타깝지만, Colab은 <code>Docker기반의 Container</code>로 실행되기 때문에 <strong>한 번에 12시간까지만 사용</strong> 할 수 있습니다. 그래서, 작업 하시던 Colab을 껏다가 잠시 후 다시 시작하면 새로운 docker container를 받기 때문에 새로운 인스턴스 위에서 시작할 때마다 <strong>설치가 필요한 패키지들을 매번 다시 설치해야</strong> 합니다.</p></li><li><p>그 다음 부터는 Jupyter notebook을 사용하듯 사용하면 됩니다.</p></li></ul><h2 id="Local-file-Upload-grinning"><a href="#Local-file-Upload-grinning" class="headerlink" title="Local file Upload! :grinning:"></a>Local file Upload! <span class="github-emoji" style="color: transparent;background:no-repeat url(https://assets-cdn.github.com/images/icons/emoji/unicode/1f600.png?v8) center/contain" data-src="https://assets-cdn.github.com/images/icons/emoji/unicode/1f600.png?v8">😀</span></h2><ul><li><p>Local가지고 있는 CIFAR10 png data로 테스트 해봤습니다. </p>  <figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> google.colab <span class="hljs-keyword">import</span> files</span><br><span class="line">cifar10 = files.upload()</span><br></pre></td></tr></tbody></table></figure>  <img src="/gallery/colab6.png" width="800"></li></ul><br><ul><li><p>로컬에서 files를 통해서 가져오는 데이터들은 기본적으로 dictionary 형태로 받아서 변수에 저장합니다. 이 업로드한 데이터들도 instance가 바뀌면(= 새로 시작하면) 없어지니, 참고하세요.   </p></li><li><p>cifar10 이라는 변수에 들어온 local uploaded data를 아래와 같이 확인해보면 귀여운 개구리를 볼 수 있습니다. <span class="github-emoji" style="color: transparent;background:no-repeat url(https://assets-cdn.github.com/images/icons/emoji/unicode/1f636.png?v8) center/contain" data-src="https://assets-cdn.github.com/images/icons/emoji/unicode/1f636.png?v8">😶</span></p>  <figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> io</span><br><span class="line"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image</span><br><span class="line"></span><br><span class="line">item = cifar10.get(list(cifar10.keys())[<span class="hljs-number">0</span>])</span><br><span class="line">image = Image.open(io.BytesIO(item))</span><br><span class="line"></span><br><span class="line">plt.imshow(image)</span><br></pre></td></tr></tbody></table></figure>  <img src="/gallery/colab7.png" width="700"></li></ul><ul><li>사실 이렇게 이미지를 올리면, upload 하고자 하는 데이터가 많을 수록 속도도 느릴 뿐만 아니라 브라우저를 다시 시작할 때마다, 또 업로드를 해야합니다. </li><li>로컬에 데이터가 많을 경우는 개인 Google Drive에 업로드 한 다음, 그 directory 안에서 작업을 하면 되겠죠? </li><li>그렇다면 작업하는 코드가 있는 Google Drive 자체를 Mount 하는 방법을 알아보도록 하겠습니다. :) </li></ul><h2 id="Mount-your-Google-Drive"><a href="#Mount-your-Google-Drive" class="headerlink" title="Mount your Google Drive"></a>Mount your Google Drive</h2><ul><li><p><strong>Google Drive는 한 번만 Mount하면</strong> 됩니다. 아래 코드를 실행시키시면, 설치를 하다가 구글 계정 인증을 해달라는 링크가 나오는데, 거기서 verification code를 잘 복사하셔서 인증하시면 됩니다. </p><figure class="highlight shell hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">!apt-get install -y -qq software-properties-common python-software-properties module-init-tools</span><br><span class="line">!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null</span><br><span class="line">!apt-get update -qq 2>&1 > /dev/null</span><br><span class="line">!apt-get -y install -qq google-drive-ocamlfuse fuse</span><br><span class="line">from google.colab import auth</span><br><span class="line">auth.authenticate_user()</span><br><span class="line">from oauth2client.client import GoogleCredentials</span><br><span class="line">creds = GoogleCredentials.get_application_default()</span><br><span class="line">import getpass</span><br><span class="line">!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL</span><br><span class="line">vcode = getpass.getpass()</span><br><span class="line">!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}</span><br></pre></td></tr></tbody></table></figure></li><li><p><code>"/home"</code>으로 경로를 이동한 뒤에, drive라는 폴더를 만들어서 본인 계정의 구글 드라이브를 drive라는 폴더에 Mount합니다. </p></li><li><p>이 과정을 거치면 개인 Google Drive에 있는 파일들이 이 폴더 안에 들어가게 됩니다. </p></li><li><p>저의 경우, <code>Colab_Notebooks</code>라는 이름으로 폴더가 생성되어 있고, 그 폴더 안에 이 튜토리얼이 있습니다. </p>  <figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">os.chdir(<span class="hljs-string">"/home"</span>)</span><br><span class="line">!mkdir drive</span><br><span class="line">!google-drive-ocamlfuse drive</span><br><span class="line"></span><br><span class="line">os.chdir(<span class="hljs-string">"/home/drive/Colab_Notebooks"</span>)</span><br><span class="line">!ls</span><br></pre></td></tr></tbody></table></figure>  <img src="/gallery/colab9.png" width="750"><br></li><li><p>제가 옮겨놓은 train폴더 안에 이미지들을 확인해 봅니다. <span class="github-emoji" style="color: transparent;background:no-repeat url(https://assets-cdn.github.com/images/icons/emoji/unicode/1f636.png?v8) center/contain" data-src="https://assets-cdn.github.com/images/icons/emoji/unicode/1f636.png?v8">😶</span></p>  <br><img src="/gallery/colab10.png" width="750"><img src="/gallery/colab11.png" width="750"></li></ul><br><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li>Jaeyeon Baek님의 <a href="http://jybaek.tistory.com/686" target="_blank" rel="noopener">블로그</a>, </li><li><a href="https://github.com/GunhoChoi" target="_blank" rel="noopener">최건호</a>님의 <code>Google Colaboratory 사용법</code></li><li><a href="https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d" target="_blank" rel="noopener">DEEP LEARNING TURKEY</a></li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content:encoded>
      
      <comments>https://www.stand-firm-peter.me/2019/06/12/Colab_tutorial/#disqus_thread</comments>
    </item>
    
    <item>
      <title>Hi, Docker! :) (3)</title>
      <link>https://www.stand-firm-peter.me/2019/05/25/docker-103/</link>
      <guid>https://www.stand-firm-peter.me/2019/05/25/docker-103/</guid>
      <pubDate>Sat, 25 May 2019 06:26:56 GMT</pubDate>
      <description>
      
        &lt;ul&gt;
&lt;li&gt;Docker Container에 SSH 접속&lt;/li&gt;
&lt;li&gt;현재 내 컨테이너를 이미지로 저장하기&lt;/li&gt;&lt;/ul&gt;
      
      </description>
      
      <content:encoded><![CDATA[<ul><li>Docker Container에 SSH 접속</li><li>현재 내 컨테이너를 이미지로 저장하기<a id="more"></a></li></ul><br><ul><li>Docker Tutorial, 세 번째<span class="github-emoji" style="color: transparent;background:no-repeat url(https://assets-cdn.github.com/images/icons/emoji/unicode/2b50.png?v8) center/contain" data-src="https://assets-cdn.github.com/images/icons/emoji/unicode/2b50.png?v8">⭐</span>입니다! </li></ul><hr><ul><li><p>이번 포스팅에서는 <a href="https://www.stand-firm-peter.me/2019/05/09/docker-102/">이전 글</a>에서 노출시킨 <strong><code>22 port</code></strong> 를 사용, 컨테이너 환경으로 외부에서 <strong><code>SSH</code> 접속</strong>을 하는 방법에 대해 다루고, SSH Setting이 끝난 <strong>컨테이너 자체를 이미지로 만드는 방법</strong>을 알아보도록 하겠습니다. </p></li><li><p>최근들어 많은 회사나 단체, 개인들이 AWS나 Google Cloud Platform 등을 사용하면서 GPU 및 TPU Server를 사용하고 있죠. 그래서 당연히 <u>AWS나 Google Cloud에서도 Docker를 사용</u>할 수 있게 됐고, 자연스럽게 언제 어디서든 무거운 계산이나 학습은 Cloud나 원격 서버에서 처리하고 실제 사용자는 자유롭게 접속하고 해당 머신을 사용할 수 있게 되었습니다. Digital Nomad<span class="github-emoji" style="color: transparent;background:no-repeat url(https://assets-cdn.github.com/images/icons/emoji/unicode/1f411.png?v8) center/contain" data-src="https://assets-cdn.github.com/images/icons/emoji/unicode/1f411.png?v8">🐑</span>가 가까워지고 있습니다. <del>혹은 Digital Slave..</del></p></li><li><p>이런 현실에 맞춰, SSH로 내 Deocker Container에 접속하는 법 정도는 아는 것이 좋겠죠?  물론 키와 패스워드 관리 및 보안상의 이유로 <a href="http://jpetazzo.github.io/2014/06/23/docker-ssh-considered-evil/" target="_blank" rel="noopener">일각</a>에서는 SSH로 컨테이너에 접속할 수 있게 하는 것을 우려하지만, 개인적인 학습이나 가벼운 실험 용도로만 사용한다고 했을 때는 효율적이라고 생각해 포스팅을 하기로 했습니다. </p></li></ul><br><h2 id="SSH-Server-in-Container"><a href="#SSH-Server-in-Container" class="headerlink" title="SSH Server in Container"></a>SSH Server in Container</h2><h3 id="1-Container-생성-cap-add"><a href="#1-Container-생성-cap-add" class="headerlink" title="1. Container 생성 (--cap-add)"></a>1. Container 생성 (<code>--cap-add</code>)</h3><ul><li><p>먼저 SSH을 사용할 수 있게 이미지로 부터 컨테이너를 생성할 때, 아래와 같은 옵션을 함께 줍니다. 이미지는 <a href="https://www.stand-firm-peter.me/2019/05/09/docker-102/">Hi, Docker! :) (2)</a>에서 생성한 <code>docker101</code>이미지를 사용합니다. </p><figure class="highlight bash hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -d --name ssh_container --<span class="hljs-built_in">cap</span>-add=NET_ADMIN --<span class="hljs-built_in">cap</span>-add=NET_RAW -p 8888:8888 -p 22022:22 docker101</span><br></pre></td></tr></tbody></table></figure><p><code>--cap-add=NET_ADMIN</code>에서 <strong><code>--cap-add</code></strong> 옵션은, 컨테이너에게 특정한 <strong>cgroups</strong> 을 사용하게 해주는 것으로, 여기서는 <strong>admin의 network를 사용</strong>하겠다는 의미로 <strong><code>NET_ADMIN</code></strong> 을, <strong>admin의 iptables를 그대로 사용</strong>하겠다는 의미 <strong><code>NET_RAW</code></strong> 를 변수로 줍니다. </p><blockquote><p><strong>cgroups</strong>: control groups의 약자 - 프로세스들의 자원의 사용(CPU, 메모리, 디스크 입출력, 네트워크 등)을 제한하고 격리시키는 리눅스 커널 기능 (feat. wikipedia) </p></blockquote></li></ul><br><ul><li>저는 <strong><code>-p 22022:22</code></strong> 로, 컨테이너가 SSH 접속을 허용할 22번 포트를 Host의 22022와 연결시켜 주겠습니다. </li></ul><h3 id="2-SSH-ufw-설치"><a href="#2-SSH-ufw-설치" class="headerlink" title="2. SSH, ufw 설치"></a>2. SSH, ufw 설치</h3><ul><li><p>이렇게 생성한 컨테이너에 이제 SSH 접속을 할 수 있도록 하려면, 손봐줄 것이 많기때문에…<span class="github-emoji" style="color: transparent;background:no-repeat url(https://assets-cdn.github.com/images/icons/emoji/unicode/1f44a.png?v8) center/contain" data-src="https://assets-cdn.github.com/images/icons/emoji/unicode/1f44a.png?v8">👊</span> 백그라운드에서 돌아가고 있는 <code>ssh_container</code>에 <code>exec</code>로 접속합니다. </p>  <figure class="highlight shell hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">$</span><span class="hljs-bash"> docker <span class="hljs-built_in">exec</span> -it ssh_container /bin/bash</span></span><br></pre></td></tr></tbody></table></figure></li><li><p>그리고 SSH와, 리눅스에서 방화벽을 관리해주는 ufw를 설치합니다. </p>  <figure class="highlight shell hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">$</span><span class="hljs-bash"> apt-get install ssh ufw -y</span></span><br></pre></td></tr></tbody></table></figure><p>  아래와 같이 sshd의 위치가 잘 나온다면 설치가 잘 된 것입니다!</p>  <figure class="highlight shell hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[work] # which sshd</span><br><span class="line">/usr/sbin/sshd</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="3-비밀번호-설정-sshd-config-passwd-root"><a href="#3-비밀번호-설정-sshd-config-passwd-root" class="headerlink" title="3. 비밀번호 설정 (sshd_config, passwd root)"></a>3. 비밀번호 설정 (sshd_config, passwd root)</h3><ul><li><p>SSH 접속을 할 때 물어볼 비밀번호를 설정하려면, 먼저 <code>/etc/ssh/</code> 아래에 있는 <code>sshd_config</code>파일을 좀 수정해야합니다. </p>  <figure class="highlight bash hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ vim /etc/ssh/sshd_config</span><br></pre></td></tr></tbody></table></figure><p>  를 보시면, </p>  <figure class="highlight bash hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment">#       $OpenBSD: sshd_config,v 1.101 2017/03/14 07:19:07 djm Exp $</span></span><br><span class="line"><span class="hljs-comment"># This is the sshd server system-wide configuration file.  See</span></span><br><span class="line"><span class="hljs-comment"># sshd_config(5) for more information.</span></span><br><span class="line"><span class="hljs-comment"># 어쩌구저쩌구...</span></span><br><span class="line">...</span><br><span class="line"><span class="hljs-comment">#LoginGraceTime 2m</span></span><br><span class="line"><span class="hljs-comment">#PermitRootLogin prohibit-password</span></span><br><span class="line"><span class="hljs-comment">#StrictModes yes</span></span><br><span class="line">...</span><br></pre></td></tr></tbody></table></figure><p>  라고 뜰 텐데요, 여기서 아래와 같이 <strong><code>#PermitRootLogin prohibit-password</code></strong> 부분의 주석을 해제하고, <code>prohibit-password</code>를 <code>yes</code>로 바꿔줍니다. </p>  <figure class="highlight bash hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line"><span class="hljs-comment">#LoginGraceTime 2m</span></span><br><span class="line">PermitRootLogin yes</span><br><span class="line"><span class="hljs-comment">#StrictModes yes</span></span><br><span class="line">...</span><br></pre></td></tr></tbody></table></figure></li><li><p>그렇게 저장을 하신 뒤에, 다시 bash로 돌아와 <strong><code>passwd root</code></strong> 을 입력해서 비밀번호를 설정해주면 끝입니다!</p><figure class="highlight bash hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[work] <span class="hljs-comment"># passwd root</span></span><br><span class="line">Enter new UNIX password:</span><br><span class="line">Retype new UNIX password: </span><br><span class="line">passwd: password updated successfully</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="4-ufw-세팅"><a href="#4-ufw-세팅" class="headerlink" title="4. ufw 세팅"></a>4. ufw 세팅</h3><ul><li><p><code>etc/ufw/</code>아래에 있는 <code>ufw.conf</code>파일에서 <code>ENABLED=no</code>를,</p><figure class="highlight bash hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ vim /etc/ufw/ufw.conf</span><br></pre></td></tr></tbody></table></figure><figure class="highlight bash hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># /etc/ufw/ufw.conf</span></span><br><span class="line">...</span><br><span class="line">ENABLED=no</span><br><span class="line">...</span><br></pre></td></tr></tbody></table></figure><p><code>ENABLED=yes</code>로 <span class="github-emoji" style="color: transparent;background:no-repeat url(https://assets-cdn.github.com/images/icons/emoji/unicode/1f447.png?v8) center/contain" data-src="https://assets-cdn.github.com/images/icons/emoji/unicode/1f447.png?v8">👇</span> 바꿔줍니다.</p><figure class="highlight bash hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">ENABLED=yes</span><br><span class="line">...</span><br></pre></td></tr></tbody></table></figure></li><li><p>그 뒤에, bash로 돌아와서 <strong><code>ufw enable</code></strong> 로 활성화를 해주고,</p><figure class="highlight shell hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[work] # ufw enable</span><br><span class="line">Firewall is active and enabled on system startup</span><br></pre></td></tr></tbody></table></figure></li><li><p>이제 실제로 22번 port를 방화벽에서 허락할 수 있게 <strong><code>ufw allow</code></strong> 를 사용합니다. </p><figure class="highlight shell hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[work] # ufw allow 22/tcp</span><br><span class="line">Rule added</span><br><span class="line">Rule added (v6)</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="5-SSH-server-시작"><a href="#5-SSH-server-시작" class="headerlink" title="5. SSH server 시작"></a>5. SSH server 시작</h3><ul><li><p>수고하셨습니다. 이제 귀찮은 일은 다 끝났습니다.<br><code>service ssh start</code>로 ssh를 시작하고, </p><figure class="highlight shell hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[work] # service ssh start</span><br><span class="line"> * Starting OpenBSD Secure Shell server sshd              [ OK ]</span><br></pre></td></tr></tbody></table></figure><p><code>service ssh status</code>로 동작을 확인하면 끝!</p><figure class="highlight shell hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[work] # service ssh status</span><br><span class="line"> * sshd is running</span><br></pre></td></tr></tbody></table></figure></li></ul><br><h2 id="SSH-Client"><a href="#SSH-Client" class="headerlink" title="SSH Client"></a>SSH Client</h2><ul><li><p>자, 그럼 열심히 세팅한 컨테이너로 이제 접속을 해봐야겠죠?<span class="github-emoji" style="color: transparent;background:no-repeat url(https://assets-cdn.github.com/images/icons/emoji/unicode/1f60e.png?v8) center/contain" data-src="https://assets-cdn.github.com/images/icons/emoji/unicode/1f60e.png?v8">😎</span> 당연하지만 기본 개념은 <strong>Port forwarding</strong>입니다. Host의 22022번 port가 ssh_container의 22번 port와 연결되어있기 때문에, 기본적으로 외부에서 Docker 컨테이너로 접속을 하려면 Docker가 실행되고 있는 Host 머신을 통해서 연결을 해야합니다. </p></li><li><p>먼저 도커가 실행되고 있는 제 PC는 맥북인 관계로 <code>ifconfig</code>를 사용해서 제 컴퓨터의 IP가 <code>172.16.8.236</code>라는 것을 알아냈습니다. (linux: <code>ifconfig</code> - window: <code>ipconfig</code>) 따라서, ssh 명령어도 아래와 같습니다. </p>  <figure class="highlight shell hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">$</span><span class="hljs-bash"> ssh -p 22022 root@172.16.8.236</span></span><br></pre></td></tr></tbody></table></figure><p>  그렇다면 이 명령을 내리는 의미는 아래의 그림과 같습니다. </p>  <center><img src="/gallery/docker2.png"></center></li></ul><ul><li><p>아래와 같이 접속을 허용하겠냐는 물음에 답하면 비밀번호를 물어보고, </p>  <figure class="highlight shell hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">The authenticity of host '[172.16.8.236]:22022 ([172.16.8.236]:22022)' can't be established.</span><br><span class="line">ECDSA key fingerprint is SHA256:iMDl7X79mKNZEA5oadtMr2zQdJhJ4n2toAeJ58o9Tsg.</span><br><span class="line">Are you sure you want to continue connecting (yes/no)? yes</span><br><span class="line">Warning: Permanently added '[172.16.8.236]:22022' (ECDSA) to the list of known hosts.</span><br><span class="line">root@172.16.8.236's password:</span><br></pre></td></tr></tbody></table></figure><p> 비밀번호를 입력하면 드디어 ssh_container 안으로 입성(?)하게 됩니다!</p> <figure class="highlight shell hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">Welcome to Ubuntu 18.04.2 LTS (GNU/Linux 4.9.125-linuxkit x86_64)</span><br><span class="line"></span><br><span class="line"> * Documentation:  https://help.ubuntu.com</span><br><span class="line"> * Management:     https://landscape.canonical.com</span><br><span class="line"> * Support:        https://ubuntu.com/advantage</span><br><span class="line">This system has been minimized by removing packages and content that are</span><br><span class="line">not required on a system that users do not log into.</span><br><span class="line"></span><br><span class="line">To restore this content, you can run the 'unminimize' command.</span><br><span class="line"></span><br><span class="line">The programs included with the Ubuntu system are free software;</span><br><span class="line">the exact distribution terms for each program are described in the</span><br><span class="line">individual files in /usr/share/doc/*/copyright.</span><br><span class="line"></span><br><span class="line">Ubuntu comes with ABSOLUTELY NO WARRANTY, to the extent permitted by</span><br><span class="line">applicable law.</span><br><span class="line"></span><br><span class="line">[~] #</span><br></pre></td></tr></tbody></table></figure></li></ul><ul><li><p>ssh를 사용해서 컨테이너 안으로 들어왔습니다! <code>work</code> directory안에 반가운 <code>Data</code>폴더도 그대로 잘 있네요. 이제 곧 Digital Nomad<span class="github-emoji" style="color: transparent;background:no-repeat url(https://assets-cdn.github.com/images/icons/emoji/unicode/1f411.png?v8) center/contain" data-src="https://assets-cdn.github.com/images/icons/emoji/unicode/1f411.png?v8">🐑</span>가 될 것같은 기분 <del>은 희망사항</del> 입니다. </p>  <figure class="highlight shell hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[~] # cd work</span><br><span class="line">[work] # ls -a</span><br><span class="line">.  ..  .empty  Data</span><br><span class="line">[work] #</span><br></pre></td></tr></tbody></table></figure></li></ul><h4 id="이-예시는-내부망이라서-외부에서-원격접속은-못하잖아요"><a href="#이-예시는-내부망이라서-외부에서-원격접속은-못하잖아요" class="headerlink" title="이 예시는 내부망이라서, 외부에서 원격접속은 못하잖아요?"></a>이 예시는 내부망이라서, 외부에서 원격접속은 못하잖아요?</h4><ul><li>맞습니다. 잘 아시겠지만, 이번 포스팅에서 예시로 들었던 IP <code>172.16.8.236</code>은 내부망(같은 공유기를 쓰는, 혹은 같은 사내망)입니다. 따라서, 때로는 <code>192.xx.xxx.xx</code>가 될 수도 있죠. 같은 내부망뿐만 아니라, 진정으로 인터넷을 통해 어디서나 접근을 가능하게 하고 싶다면 저 IP는 Host가 부여받은 <strong>Public IP인 external IP</strong>이어야 합니다. </li><li>AWS나 GCP에서 Docker 컨테이너를 사용하고 계신다면, 사용하고 계신 Cloud Machine에 접근할 수 있는 IP를 알면 되는 것이고, 자체 사설 서버를 운영하신다고 해도 마찬가지 입니다. 해당 Host 머신이 가지고 있는 Static IP, 고정IP가 되겠죠.</li><li>다만 각각의 환경에 따라 ssh 접속을 허용하기 위한 SSH Server측의 방화벽 및 구체적인 세팅을 다 설명하기에는 이번 포스팅의 논지를 흐릴 것 같아 <del>사실 제가 힘들어서<span class="github-emoji" style="color: transparent;background:no-repeat url(https://assets-cdn.github.com/images/icons/emoji/unicode/1f61e.png?v8) center/contain" data-src="https://assets-cdn.github.com/images/icons/emoji/unicode/1f61e.png?v8">😞</span></del>, 내부망 접속이라는 예시를 통해 ssh container 접속의 개념만 살펴보았습니다. 외부망을 통해 Docker Container에 접속을 하시려면, 필요에 따라 가지고 계신 환경에 따른 더 많은 정보가 필요합니다.</li></ul><br><h2 id="Save-My-Container-as-an-Image-commit"><a href="#Save-My-Container-as-an-Image-commit" class="headerlink" title="Save My Container as an Image.(commit)"></a>Save My Container as an Image.(<code>commit</code>)</h2><ul><li><p><del>더 게으르고 싶은 개발자가 좋은 개발자기 때문에,</del> 우리는 이 귀찮은 작업들을, 매번 컨테이너를 생성할 때마다 해줄 수는 없습니다! 이렇게 힘들게(?) 세팅한, SSH 접속이 되는 <code>ssh_container</code>를 image로 만들어서 Docker Hub에도 올리고, 편하게 사용하고 싶습니다. </p></li><li><p>이것을 가능하게 해주는 명령어가 <strong><code>commit</code></strong> 입니다. 말이 나온 김에 지금 당장 사용하도록 하겠습니다. <code>ssh_container</code>로 <code>ssh_machine_learning</code>이라는 이름으로 Image를 만듭니다. </p>  <figure class="highlight shell hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">$</span><span class="hljs-bash"> docker commit ssh_container ssh_machine_learning</span></span><br><span class="line">sha256:2e134384b1c846ee76a069db2aad0b2664610c195b9d8c1b03d79b9e3de74a0e</span><br></pre></td></tr></tbody></table></figure><p>  이미지가 잘 생성이 됐는지 확인을 해보니, 잘 생성이 되었네요! 참 쉽죠?<span class="github-emoji" style="color: transparent;background:no-repeat url(https://assets-cdn.github.com/images/icons/emoji/unicode/1f607.png?v8) center/contain" data-src="https://assets-cdn.github.com/images/icons/emoji/unicode/1f607.png?v8">😇</span><span class="github-emoji" style="color: transparent;background:no-repeat url(https://assets-cdn.github.com/images/icons/emoji/unicode/1f918.png?v8) center/contain" data-src="https://assets-cdn.github.com/images/icons/emoji/unicode/1f918.png?v8">🤘</span></p>  <figure class="highlight shell hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">$</span><span class="hljs-bash"> docker images</span></span><br><span class="line">REPOSITORY                                    TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">ssh_machine_learning                          latest              4d9c11b16e4c        4 seconds ago       4.75GB</span><br><span class="line">docker101                                     latest              71522855bd07        4 days ago          4.72GB</span><br></pre></td></tr></tbody></table></figure></li></ul><br><h3 id="Test"><a href="#Test" class="headerlink" title="Test"></a>Test</h3><ul><li><p>그럼 정말로 의도대로 잘 생성된 이미지인지 확인하기 위해, 기존의 ssh_container와, docker101 이미지를 삭제합니다. </p>  <figure class="highlight shell hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">$</span><span class="hljs-bash"> docker stop ssh_container</span></span><br><span class="line">ssh_container</span><br><span class="line"><span class="hljs-meta">$</span><span class="hljs-bash"> docker rm ssh_container</span></span><br><span class="line">ssh_container</span><br><span class="line"><span class="hljs-meta">$</span><span class="hljs-bash"> docker rmi docker101</span></span><br><span class="line">Untagged: docker101:latest</span><br></pre></td></tr></tbody></table></figure><p>  그리고 생성한 <code>ssh_machine_learning</code> 이미지로 컨테이너를 생성하고 확인합니다. <code>happy_cori</code>라는 이름의 컨테이너로 생성이 되어있습니다. </p>  <figure class="highlight shell hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">$</span><span class="hljs-bash"> docker run -d --<span class="hljs-built_in">cap</span>-add=NET_ADMIN --<span class="hljs-built_in">cap</span>-add=NET_RAW -p 8888:8888 -p 22022:22 ssh_machine_learning</span></span><br><span class="line">e3f1a95dc804632ed1802c17c90b44046f13301a261d06ebd48dcd7cb8f57447</span><br><span class="line"><span class="hljs-meta">$</span><span class="hljs-bash"> docker ps </span></span><br><span class="line">CONTAINER ID        IMAGE                  COMMAND                  CREATED             STATUS              PORTS                                           NAMES</span><br><span class="line">292970ce1cff        ssh_machine_learning   "/tini -- /bin/sh -c…"   3 seconds ago       Up 2 seconds        0.0.0.0:8888->8888/tcp, 0.0.0.0:22022->22/tcp   happy_cori</span><br></pre></td></tr></tbody></table></figure><p>  <code>happy_cori</code>로 exec 접속을 해서 SSH Server를 시작시킵니다.</p>  <figure class="highlight shell hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">$</span><span class="hljs-bash"> docker <span class="hljs-built_in">exec</span> -it happy_cori /bin/bash</span></span><br><span class="line">[work] # service ssh start</span><br><span class="line"> * Starting OpenBSD Secure Shell server sshd                  [ OK ]</span><br></pre></td></tr></tbody></table></figure></li><li><p>위에 나왔던 같은 방식으로, SSH 접속을 해봅니다.<del>팝콘준비<span class="github-emoji" style="color: transparent;background:no-repeat url(https://assets-cdn.github.com/images/icons/emoji/unicode/1f35f.png?v8) center/contain" data-src="https://assets-cdn.github.com/images/icons/emoji/unicode/1f35f.png?v8">🍟</span></del></p></li></ul><h4 id="Dealing-with-an-Error"><a href="#Dealing-with-an-Error" class="headerlink" title="Dealing with an Error"></a>Dealing with an Error</h4><ul><li><p>아, 지금 저처럼 같은 PC로 접속을 하신다면 아마도..</p>  <figure class="highlight shell hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"> @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@</span><br><span class="line"> @    WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED!   @</span><br><span class="line"> @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@</span><br><span class="line"> IT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY!</span><br><span class="line"></span><br><span class="line">어쩌구저쵸구..</span><br><span class="line">...</span><br><span class="line">Add correct host key in /Users/chayesol/.ssh/known_hosts to get rid of this message.</span><br><span class="line">...</span><br></pre></td></tr></tbody></table></figure><p>  이런 멋진 친구를 먼저 만나게 될 것입니다. 그도 그럴만한 것이, 접속을 하려는 PC 입장에서는 <code>똑같은 IP로 접속을 하려고 하는데, 전혀 다른 Server인데??</code>라고 하면서 <code>'뭐냐이거'</code>라고 정색을 하는 것이죠.  이럴 경우, PC가 가지고 있떤 ssh-key를 아예 초기화시켜주는, </p>  <figure class="highlight plain hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ssh-keygen -R YOUR.IP.ADDR.ESS</span><br></pre></td></tr></tbody></table></figure><p>  를 실행한 뒤에 다시 하면 된다는 분들이 계시고, 저같은 경우 이 방법이 안먹혀서 에러 메세지 하단쯤에 친절히 적혀 있는 <code>/Users/chayesol/.ssh/known_hosts</code>을 파일을 열고 해당 IP를 지워버렸습니다. </p>  <center><img src="/gallery/docker3.png"></center>  <br><p>  그리고나서 다시, 도즈언<span class="github-emoji" style="color: transparent;background:no-repeat url(https://assets-cdn.github.com/images/icons/emoji/unicode/1f3ca.png?v8) center/contain" data-src="https://assets-cdn.github.com/images/icons/emoji/unicode/1f3ca.png?v8">🏊</span> 하니 잘 되네요!</p>  <figure class="highlight shell hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">$</span><span class="hljs-bash"> ssh -p 22022 root@172.16.8.236</span></span><br><span class="line">The authenticity of host '[172.16.8.236]:22022 ([172.16.8.236]:22022)' can't be established.</span><br><span class="line">ECDSA key fingerprint is SHA256:XFFyjB4g0y4cJzd08AV2nDfxGxzcm8qBoS5n7VRc9fo.</span><br><span class="line">Are you sure you want to continue connecting (yes/no)? yes</span><br><span class="line">Warning: Permanently added '[172.16.8.236]:22022' (ECDSA) to the list of known hosts.</span><br><span class="line">root@172.16.8.236's password: </span><br><span class="line">Welcome to Ubuntu 18.04.2 LTS (GNU/Linux 4.9.125-linuxkit x86_64)</span><br><span class="line"></span><br><span class="line"> * Documentation:  https://help.ubuntu.com</span><br><span class="line"> * Management:     https://landscape.canonical.com</span><br><span class="line"> * Support:        https://ubuntu.com/advantage</span><br><span class="line">This system has been minimized by removing packages and content that are</span><br><span class="line">not required on a system that users do not log into.</span><br><span class="line"></span><br><span class="line">To restore this content, you can run the 'unminimize' command.</span><br><span class="line"></span><br><span class="line">The programs included with the Ubuntu system are free software;</span><br><span class="line">the exact distribution terms for each program are described in the</span><br><span class="line">individual files in /usr/share/doc/*/copyright.</span><br><span class="line"></span><br><span class="line">Ubuntu comes with ABSOLUTELY NO WARRANTY, to the extent permitted by</span><br><span class="line">applicable law.</span><br><span class="line"></span><br><span class="line">[~] #</span><br></pre></td></tr></tbody></table></figure></li></ul><br><ul><li>이상으로 3번에 걸친 Docker Tutorial을 모두 마치도록 하겠습니다.<br>읽어주셔서 감사합니다. <span class="github-emoji" style="color: transparent;background:no-repeat url(https://assets-cdn.github.com/images/icons/emoji/unicode/1f647.png?v8) center/contain" data-src="https://assets-cdn.github.com/images/icons/emoji/unicode/1f647.png?v8">🙇</span></li></ul><hr><h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3><ul><li><strong><a href="https://gist.github.com/ruo91/11394722" target="_blank" rel="noopener">ruo91 - GitHub Gist</a></strong></li><li><strong>docker의 ubuntu <a href="https://chanhy63.tistory.com/11" target="_blank" rel="noopener">container에 ssh로 접속하기</a></strong></li><li><strong>HOW TO CREATE A <a href="https://www.scalyr.com/blog/create-docker-image/" target="_blank" rel="noopener">DOCKER IMAGE FROM A CONTAINER</a></strong></li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content:encoded>
      
      <comments>https://www.stand-firm-peter.me/2019/05/25/docker-103/#disqus_thread</comments>
    </item>
    
    <item>
      <title>Hi, Docker! :) (2)</title>
      <link>https://www.stand-firm-peter.me/2019/05/09/docker-102/</link>
      <guid>https://www.stand-firm-peter.me/2019/05/09/docker-102/</guid>
      <pubDate>Thu, 09 May 2019 06:26:56 GMT</pubDate>
      <description>
      
        &lt;ul&gt;
&lt;li&gt;로컬 저장소 컨테이너로 마운트하기&lt;/li&gt;
&lt;li&gt;내 컨테이너 환경 이미지로 Upload하기&lt;/li&gt;&lt;/ul&gt;
      
      </description>
      
      <content:encoded><![CDATA[<ul><li>로컬 저장소 컨테이너로 마운트하기</li><li>내 컨테이너 환경 이미지로 Upload하기<a id="more"></a></li></ul><br><ul><li>안녕하세요 :) Docker Tutorial, 두 번째<span class="github-emoji" style="color: transparent;background:no-repeat url(https://assets-cdn.github.com/images/icons/emoji/unicode/270c.png?v8) center/contain" data-src="https://assets-cdn.github.com/images/icons/emoji/unicode/270c.png?v8">✌</span>입니다! </li></ul><hr><ul><li>컨테이너를 만들고 작업을 열심히 했는데, 그 컨테이너가 실수로 지워진다면, 그 컨테이너 안에 있던 모든 자료들이 삭제되었다는 것을 의미합니다 <del>동공지진<span class="github-emoji" style="color: transparent;background:no-repeat url(https://assets-cdn.github.com/images/icons/emoji/unicode/1f440.png?v8) center/contain" data-src="https://assets-cdn.github.com/images/icons/emoji/unicode/1f440.png?v8">👀</span></del> 그런 일을 미연에 방지하기 위해서, 저장소를 컨테이너 외부에 두는 것이 안전하죠! 그래서, <strong>첫 번째</strong>로 생성한 Docker 컨테이너에 <code>내 로컬 폴더 연동하기</code>를 함께 알아보겠습니다.</li><li>또 내가 쓰던 개발환경을 떠나, 새로운 곳으로 갔을때<del>이직</del> 일일히 환경설정을 그 때 환경으로 다 할 필요 없이 우리는 도커를 쓸 수 있습니다. <strong>두 번째</strong>로 내가 작업하고 있는 컨테이너의 설정을 Image로 <code>Docker Hub</code> or <code>Registry</code>에 업로드해서 다른 곳에서도 쓸 수 있도록 하는 방법을 알아보겠습니다!</li></ul><h2 id="Local-Directory-Mount-run-v"><a href="#Local-Directory-Mount-run-v" class="headerlink" title="Local Directory Mount (run -v)"></a>Local Directory Mount (run -v)</h2><ul><li>내가 가지고 있는 Host OS있는 폴더를 생성한 컨테이너와 공유하려면 run 명령어를 실행할 때 <code>-v</code> 옵션을 사용하면 됩니다! 포트 설정을 할 때와 같이 <u><code>:</code>을 기준으로 좌측에는 마운트하고자 하는 폴더경로</u>를, <u>우측에는 마운트시킬 컨테이너 경로</u>를 적어주면 됩니다.<figure class="highlight shell hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">$</span><span class="hljs-bash"> docker run -it \</span></span><br><span class="line">  -v /path/to/folder:/root/work \</span><br><span class="line">  image_ID_or_name /bin/bash</span><br></pre></td></tr></tbody></table></figure></li></ul><h4 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h4><ul><li>제 컴퓨터 바탕화면에 <code>Data</code>라는 폴더에는 CNN 학습을 위한 이미지들이 담겨있는 <code>train</code>이라는 폴더가 있습니다. 이 폴더를 <a href="https://www.stand-firm-peter.me/2019/04/24/docker-intro/">이전 포스팅</a>에서 다운 받았던 이미지를 사용한 컨테이너와 연동시켜보도록 하겠습니다. 먼저 가지고 있는 images의 ID를 확인해보니, <code>a8928a6d6eaa</code>이네요.  <figure class="highlight console hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">REPOSITORY                                    TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">civisanalytics/civis-jupyter-python3          latest              a8928a6d6eaa        8 days ago          3.37GB</span><br></pre></td></tr></tbody></table></figure></li></ul><ul><li><p>해당 이미지로 컨테이너를 생성하면서 마운트를 해보면, </p>  <figure class="highlight bash hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -it -p 8888:8888 \</span><br><span class="line">    -v /Users/chayesol/Desktop/Data:/root/work \</span><br><span class="line">    a8928a6d6eaa /bin/bash</span><br></pre></td></tr></tbody></table></figure><p>실제로 <code>1.jpg</code>, <code>2.jpg</code>가 들어있는 <code>train</code> 폴더가 <code>/root/work/train</code>로 잘 마운트 된 것을 확인할 수 있었습니다.</p><figure class="highlight shell hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[work] # ls -a</span><br><span class="line">.  ..  train</span><br><span class="line">[work] # cd train </span><br><span class="line">[train] # ls -a</span><br><span class="line">.  ..  1.jpg  2.jpg</span><br><span class="line">[train] # pwd</span><br><span class="line">/root/work/train</span><br></pre></td></tr></tbody></table></figure></li><li><p>이 폴더는 실제로 공유되고 있는 폴더이기 때문에, 이 폴더 안에 파일을 지우면 당연히 컨테이너 상에서도 지워집니다. (Vise Versa)</p></li><li><p>Docker는 로컬 뿐만아니라 <strong><code>AWS S3 Bucket</code>과 연동</strong>시킬 수도 있습니다. <del>시간나면..쿨럭..<span class="github-emoji" style="color: transparent;background:no-repeat url(https://assets-cdn.github.com/images/icons/emoji/unicode/1f637.png?v8) center/contain" data-src="https://assets-cdn.github.com/images/icons/emoji/unicode/1f637.png?v8">😷</span>다시 포스팅하겠습니다..</del></p></li></ul><hr><h2 id="내-컨테이너-환경-Upload하기"><a href="#내-컨테이너-환경-Upload하기" class="headerlink" title="내 컨테이너 환경 Upload하기!"></a>내 컨테이너 환경 Upload하기!</h2><h3 id="Layer"><a href="#Layer" class="headerlink" title="Layer?"></a>Layer?</h3><ul><li><p>컨테이너는 이미지 기반으로 생성되기 때문에, 내 컨테이너 환경을 업로드한다는 것은, 내 컨테이너 환경의 이미지를 만든다고 생각할 수 있습니다. Docker는 이미지를 만들 때, <strong>최종 이미지를 만들기 위한 명령어들을 한땀한땀 실행</strong>합니다. <del>이태리장인<span class="github-emoji" style="color: transparent;background:no-repeat url(https://assets-cdn.github.com/images/icons/emoji/shipit.png?v8) center/contain" data-src="https://assets-cdn.github.com/images/icons/emoji/shipit.png?v8"> </span></del> </p></li><li><p>즉, 최종 이미지를 만들기 시작한 맨처음 기반이 되어주는 이미지로 컨테이너를 만든 다음, 그 컨테이너에서 그 다음 부품(명령어)을 가져다가 설치해서 다시 이미지를 만들고, 또 그 다음 부품, 그 다음, 그 다음.. 식이라는 거죠. </p></li><li><p>이렇게 한 겹, 한 겹 싸이는 구조 때문에, 그 부품이 되는 명령어 하나하나를 <code>layer</code>라고 부릅니다. </p><center>    <img src="/gallery/dk2.png" width="80%"></center></li></ul><br><h3 id="업로드-할-이미지-만들기-Dockerfile"><a href="#업로드-할-이미지-만들기-Dockerfile" class="headerlink" title="업로드 할 이미지 만들기(Dockerfile)"></a>업로드 할 이미지 만들기(Dockerfile)</h3><ul><li><p>Docker는 이미지 파일을 <strong><code>Dockerfile</code></strong> 이라는 파일을 보고 생성합니다. Dockerfile을 작성하기 위해서는 <strong>Dockerfile 명령어</strong>들을 사용해서 내 환경에 맞게 잘 적어줘야합니다. </p></li><li><p>실습을 위해, 여태까지는 Tensorflow만 사용했지만, Pytorch도 사용하고 싶은 사용자가 있다고 가정합시다. 그렇다면 다음과 같은 시나리오로 이미지를 만들 수 있습니다. </p>  <figure class="highlight plain hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1. Jupyter notebook과 Tensorflow가 설치되어 있는 이미지를 Base Image로 사용</span><br><span class="line">2. Pytorch를 추가로 설치 (layer 추가)</span><br><span class="line">3. 컨테이너 생성시, Jupyter notebook 자동 실행하도록 세팅.</span><br></pre></td></tr></tbody></table></figure><p>  이 시나리오에 해당하는 Dockerfile을 먼저 보고, 하나씩 설명해보도록 하겠습니다. </p></li></ul><h3 id="Dockerfile"><a href="#Dockerfile" class="headerlink" title="Dockerfile"></a><strong>Dockerfile</strong></h3><ul><li>우리가 만들 Image의 Dockerfile은 다음과 같습니다. 원하시는 경로에서 다음과 같은 Dockerfile을 만들어 주세요. (파일 이름을 “Dockerfile”로) <figure class="highlight docker hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># Base Image</span></span><br><span class="line"><span class="hljs-keyword">FROM</span> civisanalytics/civis-jupyter-python3</span><br><span class="line"><span class="hljs-keyword">LABEL</span><span class="hljs-bash"> maintainer=<span class="hljs-string">"petercha90@gmail.com"</span></span></span><br><span class="line"></span><br><span class="line"><span class="hljs-comment"># Pytorch 설치</span></span><br><span class="line"><span class="hljs-keyword">RUN</span><span class="hljs-bash"> apt-get -y -qq update && \</span></span><br><span class="line"><span class="hljs-bash"> conda install -y pytorch-cpu torchvision-cpu -c pytorch</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-comment"># Data 폴더 복사</span></span><br><span class="line"><span class="hljs-keyword">COPY</span><span class="hljs-bash"> ./Data /root/work/Data/</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-comment"># 명령어를 실행할 디렉토리 설정</span></span><br><span class="line"><span class="hljs-keyword">WORKDIR</span><span class="hljs-bash"> /root/work</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-comment"># Jupyter notebook 가동</span></span><br><span class="line"><span class="hljs-keyword">EXPOSE</span> <span class="hljs-number">8888</span> <span class="hljs-number">22</span></span><br><span class="line"><span class="hljs-keyword">CMD</span><span class="hljs-bash"> jupyter notebook --NotebookApp.token=<span class="hljs-string">''</span> \</span></span><br><span class="line"><span class="hljs-bash"> --ip=0.0.0.0 --port=8888 --allow-root</span></span><br></pre></td></tr></tbody></table></figure></li></ul><ul><li><p><strong><code>FROM</code></strong>: </p><figure class="highlight docker hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">FROM</span> civisanalytics/civis-jupyter-python3:<span class="hljs-number">1.11</span>.<span class="hljs-number">0</span></span><br></pre></td></tr></tbody></table></figure><p>  ‘이미지의 Base를 어디로부터 가져오겠느냐’는 말입니다. 저는 Jupyter notebook과 Tensorflow가 설치되어 있는 이미지를 Base Image로 사용하려 <a href="https://www.stand-firm-peter.me/2019/04/24/docker-intro/">이전 포스팅</a>에서 사용한 이미지를 Base로 삼고 있습니다.<br>  <strong><code>:</code>앞에는 이미지 이름</strong>이, <strong>뒤에는 버전정보라고 볼 수 있는 <code>Tag</code></strong> 를 적어줍니다. </p><br> </li><li><p><strong><code>LABEL</code></strong>:</p>  <figure class="highlight docker hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">LABEL</span><span class="hljs-bash"> maintainer=<span class="hljs-string">"petercha90@gmail.com"</span></span></span><br></pre></td></tr></tbody></table></figure><p>  보통 <code>MAINTANER</code>라는 명령어를 쓰지만, 곧 ‘will be deprecated’라고 하여, 자체적으로 추천하는 LABEL을 사용해 봤습니다. LABEL의 key값으로 maintainer를 주고, value로 제 e-mail을 써서, 이 이미지의 관리자가 누구인지 밝히고 있습니다. - 추가 정보기 때문에 Build하는데 영향을 주지는 않습니다. </p><br> </li><li><p><strong><code>RUN</code></strong>:</p>  <figure class="highlight docker hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">RUN</span><span class="hljs-bash"> apt-get -y -qq update && \</span></span><br><span class="line"><span class="hljs-bash"> conda install -y pytorch-cpu torchvision-cpu -c pytorch</span></span><br></pre></td></tr></tbody></table></figure><p>  가장 많이, 자주 쓰는 명령어입니다. RUN 다음 적히는 명령어를 그대로 실행하게 해줍니다.<br>   먼저 ubuntu 다운을 위해 apt-get update를 해줍니다. <code>-y</code>는 update 도중 생기는 yes/no를 묻는 질문에 막혀서 멈추지 않도록 미리 모두 yes를 주기 위함이고, <code>-qq</code>는 설치 내역 등의 log 출력하지 않도록하는 quiet 옵션입니다.<br>   그 다음, Pytorch를 설치하는 명령어를 실행하도록 하고 있습니다. </p><br>    </li><li><p><strong><code>COPY</code></strong>:</p>  <figure class="highlight docker hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">COPY</span><span class="hljs-bash"> ./Data /root/work/Data/</span></span><br></pre></td></tr></tbody></table></figure><p>  COPY 다음에 나오는 첫번째 경로에 있는 파일을 두번째로 적힌 컨테이너 상의 경로로 복사합니다. 저는 바탕화면에 있는 Data 폴더(현재 Dockerfile이 있는 경로가 바탕화면이라서 ./Data)를 <code>/root/work/Data/</code>로 복사하게 했습니다.<br>  두 번째 경로에 해당하는 디렉토리가 없다면 자동 생성합니다. 실제로 /root/work/에는 Data라는 이름의 폴더가 없지만 이번 이미지 Build과정을 통해 생성하게 됩니다. </p><br> </li><li><p><strong><code>WORKDIR</code></strong>:</p><figure class="highlight docker hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">WORKDIR</span><span class="hljs-bash"> /root/work</span></span><br></pre></td></tr></tbody></table></figure><p>  RUN, COPY, CMD 등의 명령어들을 실행할 경로를 지정해줍니다. 접속했을 때, 맨 처음 위치하게 되는 경로이기도 합니다. 그 다음 명령어 상에서 경로 이동이 생기더라도, 그 다음 명령어에서 자동으로 여기 적은 경로로 위치가 초기화됩니다.</p><br> </li><li><p><strong><code>EXPOSE</code></strong>:</p>  <figure class="highlight docker hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">EXPOSE</span> <span class="hljs-number">8888</span> <span class="hljs-number">22</span></span><br></pre></td></tr></tbody></table></figure><p>  컨테이너 실행시, 요청을 기다리는 port를 미리 열어줍니다. 여러개를 설정 할 수도 있습니다. 저는 그 <a href="https://www.stand-firm-peter.me/2019/05/25/docker-103/">다음 포스팅</a>에서 나올 개념인 ssh접속을 위해서 22번 port도 열어주기로 했습니다. </p><br> </li><li><p><strong><code>CMD</code></strong>:</p>  <figure class="highlight docker hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">CMD</span><span class="hljs-bash"> jupyter notebook --NotebookApp.token=<span class="hljs-string">''</span> \</span></span><br><span class="line"><span class="hljs-bash"> --ip=0.0.0.0 --port=8888 --allow-root</span></span><br></pre></td></tr></tbody></table></figure><p>컨테이너가 실제로 실행되었을 때, CMD에 적힌 명령어들을 실행합니다. 위에서 말했듯이, 컨테이너 생성시 Jupyter notebook을 자동 실행하도록 세팅하기 위해 미리 CMD로 해당 명령어를 적어놓았습니다. </p></li><li><p>그 외에도 자주 쓰는 명령어로 <code>ADD</code>, <code>VOLUME</code>, <code>ENV</code> 등이 있습니다. 더 많은 정보는 <a href="https://docs.docker.com/engine/reference/builder/" target="_blank" rel="noopener">공식문서</a>를 참고해주세요.</p><br>### Build!</li><li><p>이미지를 생성하는 명령어 <code>build</code>와 이름을 설정해주는 <code>-t</code>(tag)옵션을 사용한 아래 명령어로 Dockerfile을 실행 시키면, </p>  <figure class="highlight shell hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">$</span><span class="hljs-bash"> docker build -t docker101 .</span></span><br></pre></td></tr></tbody></table></figure><p>  시간이 꽤 걸립니다..<span class="github-emoji" style="color: transparent;background:no-repeat url(https://assets-cdn.github.com/images/icons/emoji/unicode/23f3.png?v8) center/contain" data-src="https://assets-cdn.github.com/images/icons/emoji/unicode/23f3.png?v8">⏳</span></p>  <figure class="highlight shell hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">Removing intermediate container a39920cdab45</span><br><span class="line"><span class="hljs-meta"> ---></span><span class="hljs-bash"> 547c429ef2ee</span></span><br><span class="line">Successfully built 547c429ef2ee</span><br><span class="line">Successfully tagged docker101:latest</span><br><span class="line"><span class="hljs-meta">$</span><span class="hljs-bash"></span></span><br></pre></td></tr></tbody></table></figure><p>  라는 메세지가 나오면 성공적으로 Image를 생성한 것입니다!</p></li><li><p><code>docker images</code>로 생성한 이미지를 확인해봅니다. 와우… 3.37GB Base-image에 Pytorch를 설치해서 4.71GB SIZE가 돼버린 <del>뚠뚠이<span class="github-emoji" style="color: transparent;background:no-repeat url(https://assets-cdn.github.com/images/icons/emoji/unicode/1f437.png?v8) center/contain" data-src="https://assets-cdn.github.com/images/icons/emoji/unicode/1f437.png?v8">🐷</span></del> docker101 Image가 보이네요!</p>  <figure class="highlight console hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">$</span><span class="hljs-bash"> docker images</span></span><br><span class="line">REPOSITORY                                    TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">docker101                                     latest              547c429ef2ee        13 minutes ago      4.71GB</span><br><span class="line">civisanalytics/civis-jupyter-python3          latest              a8928a6d6eaa        10 days ago         3.37GB</span><br></pre></td></tr></tbody></table></figure></li></ul><ul><li><p>그렇다면…! 떨리는 맘으로 Jupyter notebook을 자동 실행되도록 설정한 것까지 잘 되는지 확인해보겠습니다! <del>팝콘각<span class="github-emoji" style="color: transparent;background:no-repeat url(https://assets-cdn.github.com/images/icons/emoji/unicode/1f35f.png?v8) center/contain" data-src="https://assets-cdn.github.com/images/icons/emoji/unicode/1f35f.png?v8">🍟</span></del></p>  <figure class="highlight shell hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">$</span><span class="hljs-bash"> docker run --name first_one -d -p 8888:8888 docker101</span></span><br></pre></td></tr></tbody></table></figure><p>  역시 localhost:8888로 접속을하니 바로 Jupyter notebook으로 접속이 되네요! 의도한 <code>CMD</code> 세팅이 잘 되어 있다는 것을 확인할 수 있습니다. <span class="github-emoji" style="color: transparent;background:no-repeat url(https://assets-cdn.github.com/images/icons/emoji/unicode/1f60e.png?v8) center/contain" data-src="https://assets-cdn.github.com/images/icons/emoji/unicode/1f60e.png?v8">😎</span><br>  맨처음 <code>COPY</code>로 복사했던 Data 폴더가 먼저 환영해 주네요 :) 그 안에 학습용 데이터들도 잘 복사가 되어있는 것을 확인할 수 있습니다. </p>  <center>    <img src="/gallery/dk6.png" width="100%"></center>  <center>    <img src="/gallery/dk7.png" width="100%"></center><p>  새 Python notebook을 만들어 Pytorch까지 잘 설치되어있는지 확인해 보면..맙소사… Pytorch와 Tensorflow, 둘 다 잘 작동하는군요! 성공적입니다!<span class="github-emoji" style="color: transparent;background:no-repeat url(https://assets-cdn.github.com/images/icons/emoji/unicode/1f382.png?v8) center/contain" data-src="https://assets-cdn.github.com/images/icons/emoji/unicode/1f382.png?v8">🎂</span><span class="github-emoji" style="color: transparent;background:no-repeat url(https://assets-cdn.github.com/images/icons/emoji/unicode/1f389.png?v8) center/contain" data-src="https://assets-cdn.github.com/images/icons/emoji/unicode/1f389.png?v8">🎉</span><span class="github-emoji" style="color: transparent;background:no-repeat url(https://assets-cdn.github.com/images/icons/emoji/unicode/1f38a.png?v8) center/contain" data-src="https://assets-cdn.github.com/images/icons/emoji/unicode/1f38a.png?v8">🎊</span><span class="github-emoji" style="color: transparent;background:no-repeat url(https://assets-cdn.github.com/images/icons/emoji/unicode/1f385.png?v8) center/contain" data-src="https://assets-cdn.github.com/images/icons/emoji/unicode/1f385.png?v8">🎅</span><span class="github-emoji" style="color: transparent;background:no-repeat url(https://assets-cdn.github.com/images/icons/emoji/unicode/1f381.png?v8) center/contain" data-src="https://assets-cdn.github.com/images/icons/emoji/unicode/1f381.png?v8">🎁</span> </p><pre><code><center>   <img src="/gallery/dk4.png" width="100%"></center></code></pre></li></ul><h2 id="Upload"><a href="#Upload" class="headerlink" title="Upload"></a>Upload</h2><ul><li>잘만든 이미지를 공유하는 방법으로 아래와 같은 두 가지 방법이 있습니다.<ol><li><strong><code>Docker Registry</code></strong> 를 설치하여 업로드한다. (like Git)</li><li><strong><code>Docker Hub</code></strong> 에 업로드 한다. (like Github)</li></ol></li></ul><h3 id="Docker-Registry"><a href="#Docker-Registry" class="headerlink" title="Docker Registry"></a>Docker Registry</h3><ul><li><a href="https://docs.docker.com/registry/" target="_blank" rel="noopener">Docker Registry</a>는 git처럼 설치형으로, 만든 이미지를 Registry 서버로 <code>push</code>하고, 다른 서버에서 <code>pull</code>을 받아서 사용합니다.  <center>    <img src="/gallery/dk3.png" width="80%">    </center></li></ul><h3 id="Docker-Hub"><a href="#Docker-Hub" class="headerlink" title="Docker Hub"></a>Docker Hub</h3><ul><li><a href="https://hub.docker.com/" target="_blank" rel="noopener">Docker Hub</a>는 도커에서 제공하는 기본 이미지 저장소로, 회원가입만하면, 대용량의 이미지도 무료로 업로드하고 다운로드 받을 수 있습니다. 마치 Github처럼 웹상에서 다운받을 수도 있고, docker 명령어로 이미지를 업로드 하고, 다운 받을 수 있는 공간입니다.</li></ul><br>    <center>      <img src="/gallery/dk5.png" width="100%">      </center><br><ul><li>이번 포스팅에서는 Docker Hub를 사용하여 업로는 하는 방법만 다뤄보도록 하겠습니다! </li></ul><h3 id="Docker-Hub-Uploading"><a href="#Docker-Hub-Uploading" class="headerlink" title="Docker Hub Uploading"></a>Docker Hub Uploading</h3><ul><li>Docker Hub에 만든 이미지를 올리는 것은 3가지 단계만 거치면 끝입니다.<br> 1. <code>Login</code>  2. <code>Renaming</code>   3 <code>Push</code>. </li></ul><h4 id="Login-login"><a href="#Login-login" class="headerlink" title="Login (login)"></a>Login (login)</h4><ul><li>먼저 Docker Hub 홈페이지에서 회원가입을 하시고 아래 명령어를 입력하면  Docker Hub 계정에 로그인 할 수 있습니다. <figure class="highlight shell hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">$</span><span class="hljs-bash"> docker login</span></span><br><span class="line">Login with your Docker ID to push and pull images from Docker Hub. If you don't have a Docker ID, head over to https://hub.docker.com to create one.</span><br><span class="line">Username: petercha90</span><br><span class="line">Password:</span><br><span class="line">Login Succeeded</span><br></pre></td></tr></tbody></table></figure></li></ul><h4 id="Renaming-tag"><a href="#Renaming-tag" class="headerlink" title="Renaming (tag)"></a>Renaming (tag)</h4><ul><li><p>Docker Hub에 올릴 이미지는, </p></li><li><p><em><code>[User_ID]/[Image_name]:[tag]</code>*</em> 라는 규칙으로 이름을 구성합니다. </p></li><li><p><strong><code>tag</code></strong> 명령어를 사용하여 금방 만들었던 docker101 이미지의 이름을 규칙에 맞게 바꿔주면서, 버전 정보(1.0)도 입력해보겠습니다. </p>  <figure class="highlight docker hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker tag docker101 petercha90/peter-tensorflow-pytorch:<span class="hljs-number">1.0</span></span><br></pre></td></tr></tbody></table></figure></li><li><p>docker images로 확인해보니, docker101과 용량도 같은데 이름이 petercha90/peter-tensorflow-pytorch이고, TAG가 1.0인 이미지를 확인할 수 있었습니다. </p> <figure class="highlight console hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta"> $</span><span class="hljs-bash"> docker images</span></span><br><span class="line">REPOSITORY                                    TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">docker101                                     latest              34bbb1c093da        20 minutes ago      4.71GB</span><br><span class="line">petercha90/peter-tensorflow-pytorch           1.0                 34bbb1c093da        20 minutes ago      4.71GB</span><br></pre></td></tr></tbody></table></figure></li></ul><h4 id="Push-push"><a href="#Push-push" class="headerlink" title="Push (push)"></a>Push (push)</h4><ul><li><p>이제 <code>push</code>명령어로 Docker Hub에 업로드만 하면 됩니다!</p>  <figure class="highlight shell hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">$</span><span class="hljs-bash"> docker push petercha90/peter-tensorflow-pytorch:1.0</span></span><br></pre></td></tr></tbody></table></figure><p>  또 시간이 좀 걸립니다..<br>  ……<br>  <span class="github-emoji" style="color: transparent;background:no-repeat url(https://assets-cdn.github.com/images/icons/emoji/unicode/23f3.png?v8) center/contain" data-src="https://assets-cdn.github.com/images/icons/emoji/unicode/23f3.png?v8">⏳</span></p> <figure class="highlight shell hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">The push refers to repository [docker.io/petercha90/peter-tensorflow-pytorch]</span><br><span class="line">fdd4a938bd06: Pushed </span><br><span class="line">be825b2f1c27: Pushed </span><br><span class="line">a3442dbff3f9: Mounted from civisanalytics/civis-jupyter-python3 </span><br><span class="line">734b701f4670: Mounted from civisanalytics/civis-jupyter-python3 </span><br><span class="line">5d22569a8a20: Mounted from civisanalytics/civis-jupyter-python3 </span><br><span class="line">99645d10b61c: Mounted from civisanalytics/civis-jupyter-python3 </span><br><span class="line">43c65e275431: Mounted from civisanalytics/civis-jupyter-python3 </span><br><span class="line">5efecd288488: Mounted from civisanalytics/civis-jupyter-python3 </span><br><span class="line">ef945229e9cd: Mounted from civisanalytics/civis-jupyter-python3 </span><br><span class="line">dc2c8974046d: Mounted from civisanalytics/civis-jupyter-python3 </span><br><span class="line">2a83ea7d2735: Mounted from civisanalytics/civis-jupyter-python3 </span><br><span class="line">70191a7dc716: Mounted from civisanalytics/civis-jupyter-python3 </span><br><span class="line">c3a15ba40d5e: Mounted from civisanalytics/civis-jupyter-python3 </span><br><span class="line">603a1f4a3e0c: Mounted from civisanalytics/civis-jupyter-python3 </span><br><span class="line">b57c79f4a9f3: Mounted from civisanalytics/civis-jupyter-python3 </span><br><span class="line">d60e01b37e74: Mounted from civisanalytics/civis-jupyter-python3 </span><br><span class="line">e45cfbc98a50: Mounted from civisanalytics/civis-jupyter-python3 </span><br><span class="line">762d8e1a6054: Mounted from civisanalytics/civis-jupyter-python3 </span><br><span class="line">1.0: digest: sha256:ffc16d44d34f063a0856999b0f04fc71f322e4d1d47e026ffed6ad2ab89f6a81 size: 4094</span><br></pre></td></tr></tbody></table></figure></li></ul><ul><li><span class="github-emoji" style="color: transparent;background:no-repeat url(https://assets-cdn.github.com/images/icons/emoji/unicode/1f389.png?v8) center/contain" data-src="https://assets-cdn.github.com/images/icons/emoji/unicode/1f389.png?v8">🎉</span><strong>Ta-da!!</strong><span class="github-emoji" style="color: transparent;background:no-repeat url(https://assets-cdn.github.com/images/icons/emoji/unicode/1f389.png?v8) center/contain" data-src="https://assets-cdn.github.com/images/icons/emoji/unicode/1f389.png?v8">🎉</span> Upload가 완료되었습니다! 이전 포스트에서 이미지를 Pull하면서 시작한 것 기억나시나요? 그 것처럼 이제 어디서든 인터넷만 잘 된다면, Anaconda3-Tensorflow-Pytorch이 설치되어 있고 + Jupyter notebook 자동실행이 되는! <del>보안은어쩔</del> 이미지를 다운받아 사용할 수 있습니다! :sunglasses:  </li></ul><br><center><img src="/gallery/dk8.png" width="80%"></center><br>    <hr><ul><li>여기까지 이전 포스팅과 함께 Docker에 대해 아주 러프하게 함께 알아 보았습니다. 더 구체적이고 설정 방법들과 Docker를 이용한 다양한 서비스 개발에 대해서는 Reference를 참고하시면 되겠습니다!</li></ul><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><strong>초보를 위한 도커 안내서 - <a href="https://subicura.com/2017/01/19/docker-guide-for-beginners-2.html" target="_blank" rel="noopener">설치하고 컨테이너 실행하기</a></strong></li><li><strong>초보를 위한 도커 안내서 - <a href="https://subicura.com/2017/02/10/docker-guide-for-beginners-create-image-and-deploy.html" target="_blank" rel="noopener">이미지 만들고 배포하기</a></strong></li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content:encoded>
      
      <comments>https://www.stand-firm-peter.me/2019/05/09/docker-102/#disqus_thread</comments>
    </item>
    
    <item>
      <title>Hi, Docker! :) (1)</title>
      <link>https://www.stand-firm-peter.me/2019/04/24/docker-intro/</link>
      <guid>https://www.stand-firm-peter.me/2019/04/24/docker-intro/</guid>
      <pubDate>Wed, 24 Apr 2019 06:26:56 GMT</pubDate>
      <description>
      
        &lt;ul&gt;
&lt;li&gt;Introduction to Docker. &lt;/li&gt;
&lt;li&gt;Docker 개념, 설치, 유용한 명령어 사용해보기.&lt;/li&gt;
&lt;/ul&gt;
      
      </description>
      
      <content:encoded><![CDATA[<ul><li>Introduction to Docker. </li><li>Docker 개념, 설치, 유용한 명령어 사용해보기.</li></ul><a id="more"></a><h2 id="Docker-no-mouth"><a href="#Docker-no-mouth" class="headerlink" title="Docker? :no_mouth:"></a>Docker? <span class="github-emoji" style="color: transparent;background:no-repeat url(https://assets-cdn.github.com/images/icons/emoji/unicode/1f636.png?v8) center/contain" data-src="https://assets-cdn.github.com/images/icons/emoji/unicode/1f636.png?v8">😶</span></h2><ul><li><p>귀여운 고래 아이콘<span class="github-emoji" style="color: transparent;background:no-repeat url(https://assets-cdn.github.com/images/icons/emoji/unicode/1f433.png?v8) center/contain" data-src="https://assets-cdn.github.com/images/icons/emoji/unicode/1f433.png?v8">🐳</span>으로 많은 사랑을 받고 있는 <code>Docker</code>에 대해 간단히 알아보도록 하겠습니다. </p><center>  <img src="/gallery/docker2.png" height="300px" width="300px"></center></li><li><p>Docker는 기존의 Virtual Machine들과 같이 Host OS 위에 Guest OS를 올리는 것이 아니라, 별도의 OS를 만들지 않고 단순히 <strong>프로세스만 격리</strong>시켜서 동작하는 방식입니다. 그래서 훨씬 더 빠르게 가상환경을 즐길 수 있게 해줍니다!</p></li><li><p>그래서 CPU나 메모리는 프로세스가 필요한 만큼만 사용하기 때문에 성능도 실제 Host에서 돌아가는 다른 Process들과 비교해서 큰 차이가 없답니다. <span class="github-emoji" style="color: transparent;background:no-repeat url(https://assets-cdn.github.com/images/icons/emoji/unicode/1f609.png?v8) center/contain" data-src="https://assets-cdn.github.com/images/icons/emoji/unicode/1f609.png?v8">😉</span></p></li></ul><center>    <img src="/gallery/docker3.png" width="80%"></center><h3 id="Container-안에-다-있어요"><a href="#Container-안에-다-있어요" class="headerlink" title="Container 안에 다 있어요!"></a>Container 안에 다 있어요!</h3><ul><li>Docker가 핫한 이유는 이게 다가 아니겠죠. 머신러닝을 위한 환경구축을 해보신 분들은 다들 공감하실 수 <strike> 빡쳐 보신 적<span class="github-emoji" style="color: transparent;background:no-repeat url(https://assets-cdn.github.com/images/icons/emoji/unicode/1f47f.png?v8) center/contain" data-src="https://assets-cdn.github.com/images/icons/emoji/unicode/1f47f.png?v8">👿</span></strike>있으실 겁니다. 내가 그렇게 수많은 에러들과 StackOverflow를 헤매가며 설정한 그 환경 말이죠. (Anarconda + Tensorflow + Pytorch + R + R Studio + cuDNN + 온갖 Python Packages + 등등..)</li><li>이제 Docker를 쓰면, 그렇게 만든 환경을 Docker계의 Github인 <a href="https://hub.docker.com/" target="_blank" rel="noopener">Docker Hub</a>에 Image화 한 뒤 올리면, 어디서나 받아서 쓸 수 있습니다. 또한 남들이 열심히 만들어서 공유해 준, <strike> 인성 거의 산타<span class="github-emoji" style="color: transparent;background:no-repeat url(https://assets-cdn.github.com/images/icons/emoji/unicode/1f385.png?v8) center/contain" data-src="https://assets-cdn.github.com/images/icons/emoji/unicode/1f385.png?v8">🎅</span></strike> 환경을 받아 편하게 쓸 수도 있습니다. 너무 좋죠?</li></ul><br><center>    <img src="/gallery/docker4.png" width="60%"></center><br><ul><li>그렇게 공유하는 (Github의 Private Repository처럼 Docker Hub에도 Private계정을 제공합니다.) 파일을 <code>Image</code>라고 하고, 그 Image를 받아서 생성하게 되는 하나하나의 Process 가상환경을 우리는 <code>Container</code>라고 부릅니다. <code>Docker</code>라는 이름에 걸맞게 항만에서 수많은 컨테이너들이 공유되는 환경이 Docker Hub이라고 생각하시면 되겠네요. </li><li>그럼 이제 Docker를 설치해 보실까요! </li></ul><br><h2 id="Installation"><a href="#Installation" class="headerlink" title="Installation"></a>Installation</h2><h4 id="Linux"><a href="#Linux" class="headerlink" title="Linux"></a>Linux</h4><ul><li><p>Ubuntu 환경만 설명하자면, 아래와 같은 명령어로 간편하게 설치 하실 수 있습니다. 명령어 위에 주석처리된 부분은 2019년 5월 현재 Ubuntu 환경의 Prerequisites이니 참고하세요 :) </p><figure class="highlight shell hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> OS requirements</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> To install Docker CE, you need the 64-bit version of one of these Ubuntu versions:</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> Cosmic 18.10</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> Bionic 18.04 (LTS)</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> Xenial 16.04 (LTS)</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">$</span><span class="hljs-bash"> sudo apt-get update</span></span><br><span class="line"><span class="hljs-meta">$</span><span class="hljs-bash"> sudo apt-get install docker-ce docker-ce-cli containerd.io</span></span><br></pre></td></tr></tbody></table></figure></li><li><p>다른 Linux 환경은 <a href="https://docs.docker.com/install/linux/docker-ce/centos/" target="_blank" rel="noopener">여기</a>를 참조하세요.</p></li></ul><h4 id="Mac-amp-Windows"><a href="#Mac-amp-Windows" class="headerlink" title="Mac & Windows"></a>Mac & Windows</h4><ul><li>Mac과 Windows 환경은 다음과 같은 기준에 따라 설치 방법이 두 가지로 나누어 집니다.<blockquote><ol><li><p><strong>Windows</strong>: <code>Windows 10 Pro 이상</code> 모델 (10 Home 안됨)<br>                  <strong>→</strong> <strong><a href="https://hub.docker.com/editions/community/docker-ce-desktop-windows" target="_blank" rel="noopener">Docker for Windows</a></strong><br><strong>Mac</strong>:  OS가 <code>Sierra 10.12 혹은 그 이상</code><br>         <strong>→</strong> <strong><a href="https://hub.docker.com/editions/community/docker-ce-desktop-mac" target="_blank" rel="noopener">Docker for Mac</a></strong></p></li><li><p><strong>Windows & Mac</strong>: 1번 조건을 만족하지 못하는 경우 <strong>→</strong> <strong><a href="https://docs.docker.com/toolbox/overview/" target="_blank" rel="noopener">Docker ToolBox</a></strong></p></li></ol></blockquote></li></ul><h5 id="참고-사항"><a href="#참고-사항" class="headerlink" title="참고 사항"></a>참고 사항</h5><ul><li>기본적으로 <strong>Docker에 회원가입</strong>을 하시고 ID를 생성하셔야 설치 파일을 다운을 받을 수 있습니다.</li><li>Windows에서는 <strong><code>[작업 관리자 > 성능]</code></strong> 에 들어가 <strong><code>"가상화 : 사용"</code></strong> 을 확인을 하시고 안되어있다면, <a href="https://docs.microsoft.com/ko-kr/virtualization/hyper-v-on-windows/quick-start/enable-hyper-v" target="_blank" rel="noopener">활성화</a>를 해줘야 합니다.</li><li>개인적인 경험상, Windows 환경에서 1번의 환경이 충족되어 Docker for Windows를 설치하였는데도, <u><strong>Linux Container로 Switch를 못한다</strong> 던가 하는 에러</u>가 발생되어 사용이 힘들 때<br>$\to$ 그냥 2번으로 Docker ToolBox를 설치하고, <code>Docker Quickstart Terminal</code>을 사용, Docker를 실행하기도 했습니다. <strike>되기만하면 장땡이니까요 </strike></li></ul><h4 id="설치-확인"><a href="#설치-확인" class="headerlink" title="설치 확인"></a>설치 확인</h4><ul><li><p><strong><code>docker version</code></strong> 이라고 Terminal에 쳤을 때, 아래와 같이 version 정보가 잘 나온다면 설치가 잘 된 것입니다. :)</p><figure class="highlight shell hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">Client: Docker Engine - Community</span><br><span class="line"> Version:           18.09.2</span><br><span class="line"> API version:       1.39</span><br><span class="line"> Go version:        go1.10.8</span><br><span class="line"> Git commit:        6247962</span><br><span class="line"> Built:             Sun Feb 10 04:12:39 2019</span><br><span class="line"> OS/Arch:           darwin/amd64</span><br><span class="line"> Experimental:      false</span><br><span class="line"></span><br><span class="line">Server: Docker Engine - Community</span><br><span class="line"> Engine:</span><br><span class="line">  Version:          18.09.2</span><br><span class="line">  API version:      1.39 (minimum version 1.12)</span><br><span class="line">  Go version:       go1.10.6</span><br><span class="line">  Git commit:       6247962</span><br><span class="line">  Built:            Sun Feb 10 04:13:06 2019</span><br><span class="line">  OS/Arch:          linux/amd64</span><br><span class="line">  Experimental:     true</span><br></pre></td></tr></tbody></table></figure></li><li><p>Docker version을 확인해보니, <code>Client-Server</code>로 나뉘어져 있는 것을 확인할 수 있습니다. Docker가 실제로 어떻게 동작하는지 볼 수 있는 부분입니다. <span class="github-emoji" style="color: transparent;background:no-repeat url(https://assets-cdn.github.com/images/icons/emoji/unicode/1f609.png?v8) center/contain" data-src="https://assets-cdn.github.com/images/icons/emoji/unicode/1f609.png?v8">😉</span> </p></li><li><p>사용자가 Docker 명령을 내리면 Client에서 기본적으로 Docker Server를 바라보고 있기 때문에, 사용자는 바로 명령만 내린 것 같지만, 실제로는 Server가 Client로 부터 전송을 받아, 처리한 결과를 다시 Client에게 돌려주고 있는 것이죠.</p></li></ul><center>    <img src="/gallery/docker7.png"></center><br><ul><li>자, 이제 설치를 잘 마쳤으면 본격적으로 Docker를 사용해 볼까요?</li></ul><br><h2 id="Practice"><a href="#Practice" class="headerlink" title="Practice"></a>Practice</h2><ul><li>아래와 같은 순서로 실습을 하면서 필요한 명령어들을 정리해 보겠습니다 <span class="github-emoji" style="color: transparent;background:no-repeat url(https://assets-cdn.github.com/images/icons/emoji/unicode/1f609.png?v8) center/contain" data-src="https://assets-cdn.github.com/images/icons/emoji/unicode/1f609.png?v8">😉</span>  <figure class="highlight plain hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1. Anaconda가 설치되어 있는 Ubuntu Image를 다운받기. </span><br><span class="line">2. 그 이미지로 생성한 컨테이너에서 Jupyter notebook을 띄워놓기.</span><br><span class="line">3. Host Browser로 접근해서 사용.</span><br></pre></td></tr></tbody></table></figure></li></ul><br><h4 id="1-이미지-다운로드-하기-pull-images"><a href="#1-이미지-다운로드-하기-pull-images" class="headerlink" title="1. 이미지 다운로드 하기 (pull, images)"></a>1. 이미지 다운로드 하기 (pull, images)</h4><ul><li><a href="https://hub.docker.com" target="_blank" rel="noopener">Docker Hub</a>에 접속해서 <code>jupyter-python3</code>로 검색을 하니, 천만 다운로드에 빛나는 이미지가 나오네요. </li></ul><center>    <img src="/gallery/docker6.png" width="93%"></center><br><ul><li>아래의 명령어를 입력하면, <code>Anaconda3</code>를 품은 <code>Ubuntu 18.04</code> Image를 다운로드 받게 됩니다. 다운로드에 약간의 시간이 소요됩니다.   <figure class="highlight shell hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">$</span><span class="hljs-bash"> docker pull civisanalytics/civis-jupyter-python3</span></span><br></pre></td></tr></tbody></table></figure></li></ul><br><ul><li><p>보시다시피, 기본적으로 Docker 명령어는 <code>docker</code>로 시작하고, Git을 쓰신 분들은 익숙한 단어이실 <code>pull</code>이라는 명령어로 원하는 이미지를 가져 올 수 있습니다. 가져온 이미지는 명령어 </p>  <figure class="highlight shell hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">$</span><span class="hljs-bash"> docker images</span></span><br></pre></td></tr></tbody></table></figure><p>  를 통해 확인할 수 있습니다. </p></li></ul><br><h4 id="2-컨테이너-목록-조회-amp-삭제-ps-rm-stop"><a href="#2-컨테이너-목록-조회-amp-삭제-ps-rm-stop" class="headerlink" title="2. 컨테이너 목록 조회 & 삭제 (ps, rm, stop)"></a>2. 컨테이너 목록 조회 & 삭제 (ps, rm, stop)</h4><ul><li><p>컨테이너 실습에 앞서서, 깔끔한 진행을 위해 현재 Docker 설치시에 Default로 가지고 있는 컨테이너들을 한 번 싹 비우고 시작하도록 하겠습니다<span class="github-emoji" style="color: transparent;background:no-repeat url(https://assets-cdn.github.com/images/icons/emoji/unicode/1f60f.png?v8) center/contain" data-src="https://assets-cdn.github.com/images/icons/emoji/unicode/1f60f.png?v8">😏</span>. 아래 명령어를 입력하시면 현재 멈춰있는 컨테이너까지 포함한 목록들을 확인할 수 있습니다. </p>  <figure class="highlight shell hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">$</span><span class="hljs-bash"> docker ps -a</span></span><br></pre></td></tr></tbody></table></figure></li></ul><br><ul><li><strong><code>docker ps</code>는 현재 동작하고 있는 컨테이너를 모든 컨테이너들을 조회</strong>하는 명령어 입니다. <strong><code>-a</code> 옵션은 멈춘 컨테이너까지 모두 조회</strong>합니다. 아직 컨테이너 생성은 하지도 않는데 목록에 멈춰있는 다른 컨테이너들이 보이실 것입니다. 다 지워보도록 하겠습니다.<span class="github-emoji" style="color: transparent;background:no-repeat url(https://assets-cdn.github.com/images/icons/emoji/unicode/1f608.png?v8) center/contain" data-src="https://assets-cdn.github.com/images/icons/emoji/unicode/1f608.png?v8">😈</span>  <figure class="highlight shell hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">$</span><span class="hljs-bash"> docker rm $(docker ps -a -q)</span></span><br></pre></td></tr></tbody></table></figure></li></ul><br><ul><li><strong><code>docker rm</code>는 멈춰있는 컨테이너를 삭제</strong>하는 명령이고, <strong><code>-q</code> 옵션</strong>은, PORT, STATUS, NAME등의 정보는 제외하고 <strong>컨테이너 ID만 확인</strong>하게 해주는 옵션입니다. 따라서 바로 위에서 배웠던 <code>docker ps -a -q</code>의 결과로 나오는 ID에 해당하는 모든 컨테이너들을 삭제해라는 명령이 됩니다. </li><li>컨테이너가 아니라 이미지를 삭제하고 싶으면 <code>docker rmi</code>로 i만 추가해주세요!</li></ul><br><ul><li>혹시 컨테이너가 정지 상태가 아닌데 <code>docker rm container_ID</code>를 실행하시면 해당 컨테이너는 삭제되지 않습니다. 먼저 <code>docker stop container_ID</code>로 삭제하고자 하는 컨테이너의 동작을 멈춘 뒤에 실행해야합니다. </li></ul><br><h4 id="3-컨테이너-생성-amp-포트-설정-amp-이름지어주기-run-p-–name"><a href="#3-컨테이너-생성-amp-포트-설정-amp-이름지어주기-run-p-–name" class="headerlink" title="3. 컨테이너 생성 & 포트 설정 & 이름지어주기 (run -p, –name)"></a>3. 컨테이너 생성 & 포트 설정 & 이름지어주기 (run -p, –name)</h4><ul><li>이제 우리가 사용할 우분투 컨테이너를 생성하고 접속해보도록 하겠습니다.  <figure class="highlight shell hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">$</span><span class="hljs-bash"> docker run -it --name docker101 \</span></span><br><span class="line">  -p 8888:8888 civisanalytics/civis-jupyter-python3 \</span><br><span class="line">  /bin/bash</span><br></pre></td></tr></tbody></table></figure></li></ul><br><ul><li><strong><code>run</code>명령어로, 가지고 이미지를 실행</strong>하라고 하면서 <strong><code>-it</code> 옵션을 주어서(<code>-ti</code>도 같습니다) 터미널(t)에 입력(i)</strong> 을 받을 수 있게 해줍니다. <code>-i</code>와 <code>-t</code>옵션을 함께 쓴 거죠. 제일 마지막에 <strong>터미널의 경로를 <code>/bin/bash</code></strong> 로 전달해줍니다.</li><li><strong><code>--name</code></strong> 옵션을 줘서 원하는 이름을 부여할 수도 있습니다. 이름을 따로 주지 않으면 유명한 과학자의 이름에 수식어를 붙여서 랜덤생성합니다.(장영실도 포함되어있다고 하네요!) </li><li><strong><code>-p</code> 옵션</strong>은 포워딩 해줄 <code>port</code>번호를 의미하는데요, <strong>앞</strong>에 8888은 <strong>호스트 port</strong>, <strong>뒤</strong>의 8888은  <strong>컨테이너 port</strong>를 의미합니다.    </li></ul><br><ul><li><p>접속이 잘 되었다면 아래와 같이 sudo mode로 root권한을 가진 상태의 bash를 쓸 수 있게 됐습니다! 간단한 <code>ls -a</code>이나 <code>pwd</code>같은 명령어들로 가상환경 Ubuntu를 느껴보세요.<span class="github-emoji" style="color: transparent;background:no-repeat url(https://assets-cdn.github.com/images/icons/emoji/unicode/1f60e.png?v8) center/contain" data-src="https://assets-cdn.github.com/images/icons/emoji/unicode/1f60e.png?v8">😎</span>. <code>apt update</code>로 우분투를 업데이트 해줍니다.</p><figure class="highlight shell hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">$</span><span class="hljs-bash"> [work] <span class="hljs-comment"># apt update</span></span></span><br></pre></td></tr></tbody></table></figure></li></ul><br><ul><li>사실 <strong><code>run</code>명령어</strong>는 실행하라고 한 이미지가 로컬에 없을 경우, 가장 최신 버전으로 다운을 받기 때문에, <strong>이미지를 다운받으면서 동시에 컨테이너를 만드는 명령어</strong>이기도 합니다. 하지만, 한 번 다운 받고 난 뒤에는 해당 이미지가 업데이트가 되어도 가지고 있는 이미지만 사용하기 때문에, 가장 최신 버전을 다운 받게 해주는 <code>pull</code>도 메리트가 있는 것이죠.</li></ul><br><ul><li><p>다시 본론으로 돌아와, 접속한 컨테이너 우분투 환경에서 <code>python</code>을 입력해보면, Acaconda3-python 3.7이 설치 되어있음을 확인할 수 있습니다. 이로써 Anaconda를 설치한 적도 없지만, 사용할 수 있는 환경을 Get하게 됐습니다.<span class="github-emoji" style="color: transparent;background:no-repeat url(https://assets-cdn.github.com/images/icons/emoji/unicode/1f60a.png?v8) center/contain" data-src="https://assets-cdn.github.com/images/icons/emoji/unicode/1f60a.png?v8">😊</span></p><figure class="highlight shell hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[work] # python</span><br><span class="line">Python 3.7.1 | packaged by conda-forge | (default, Feb 18 2019, 01:42:00) </span><br><span class="line">[GCC 7.3.0] :: Anaconda, Inc. on linux</span><br><span class="line">Type "help", "copyright", "credits" or "license" for more information.</span><br><span class="line"><span class="hljs-meta">></span><span class="hljs-bash">>></span></span><br></pre></td></tr></tbody></table></figure></li></ul><br><ul><li>이 상태에서 <code>jupyter notebook</code>을 바로 실행을 시킬 수도 있습니다. 하지만 다른 명령어들을 더 익히기 위해 <code>exit</code>로 일단 나오도록 합니다.</li></ul><br><h4 id="4-컨테이너-시작-명령어-실행시키기-start-exec-d"><a href="#4-컨테이너-시작-명령어-실행시키기-start-exec-d" class="headerlink" title="4. 컨테이너 시작, 명령어 실행시키기 (start, exec -d)"></a>4. 컨테이너 시작, 명령어 실행시키기 (start, exec -d)</h4><ul><li><p>Jupyter notebook을 실행시키도록 해보겠습니다! 먼저 <code>docker ps -a</code>을 입력해서, 방금 나왔던 컨테이너의 이름을 확인해봅니다. <code>exit</code>명령어로 환경을 나오면, 기본적으로 컨테이너는 <code>Stopped(Exited)</code>인 상태입니다.</p>  <figure class="highlight shell hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">chayesol-ui-MacBook-Pro:Blog chayesol$ docker ps -a</span><br><span class="line">CONTAINER ID        IMAGE                                  COMMAND                CREATED             STATUS                     PORTS               NAMES</span><br><span class="line">57ca32782e7e        civisanalytics/civis-jupyter-python3   "/tini -- /bin/bash"   9 minutes ago       Exited (0) 6 minutes ago                       docker101</span><br></pre></td></tr></tbody></table></figure><p>  제가 생성할 때 이름으로 주었던 <code>docker101</code>이 이름으로 잘 보이네요! </p><br></li><li><p>이 컨테이너는 지금 Stopped 상태(Exited)이기 때문에 새로 동작을 시켜 줘야합니다. <strong><code>docker start</code>명령어</strong>로 다시 작동시킨 뒤, Jupyter notebook을 실행합니다.  </p>  <figure class="highlight shell hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">$</span><span class="hljs-bash"> docker start docker101</span></span><br><span class="line"><span class="hljs-meta">$</span><span class="hljs-bash"> docker <span class="hljs-built_in">exec</span> docker101 jupyter notebook \</span></span><br><span class="line">  --ip=0.0.0.0 --port=8888 --allow-root</span><br></pre></td></tr></tbody></table></figure></li></ul><br><ul><li><strong><code>exec</code> 명령어</strong>는 <u>해당 컨테이너 이름(or ID) 뒤에 나열된 명령어들을 실행하게 해줍니다</u>. ip는 0.0.0.0으로 로컬호스트를 지칭하고, 포트는 우리가 컨테이너 생성할 때 작성한 8888로 주었습니다.</li></ul><br><ul><li>실행 후, 나오는 <code>token값</code>을 복사한 뒤, 호스트의 브라우저 창에 <code>localhost:8888</code>을 입력하시면 <code>token</code>을 적게 되어 있습니다. 그 결과, 아래와 같이 우리는 컨테이너에 있는 Jupyter notebook을 도커를 통해 로컬호스트에서 사용할 수 있게 되었습니다!<span class="github-emoji" style="color: transparent;background:no-repeat url(https://assets-cdn.github.com/images/icons/emoji/unicode/1f606.png?v8) center/contain" data-src="https://assets-cdn.github.com/images/icons/emoji/unicode/1f606.png?v8">😆</span></li></ul><center>    <img src="/gallery/docker10.png" width="90%"></center><br><h4 id="exec-d"><a href="#exec-d" class="headerlink" title="exec -d?"></a><code>exec -d</code>?</h4><ul><li><p><code>exec</code>명령을 줄 때, <code>-d</code>옵션을 추가하면, <strong>detached mode, 즉 백그라운드에서 컨테이너가 실행</strong>되도록 할 수 있습니다. (<code>-d</code>옵션은 <code>run</code>에도 쓸 수 있습니다.) 우리 예시에서는 보안상 Jupyter notebook의 token을 출력받고 사용해야하기 때문에 <code>-d</code>옵션을 사용하지 않았습니다.</p></li><li><p>보안상 권장사항은 아니지만, <code>exec -d</code> 옵션을 사용해서 편하고 빠르게, ‘귀찮은 token입력 없이 jupyter notebook만 내가 띄우고 싶다!’ 하시면 아래와 같은 명령어를 사용하실 수 있습니다. </p> <figure class="highlight shell hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">$</span><span class="hljs-bash"> docker <span class="hljs-built_in">exec</span> -d docker101 \</span></span><br><span class="line">  jupyter notebook --NotebookApp.token='' \</span><br><span class="line">  --ip=0.0.0.0 --port=8888 --allow-root</span><br><span class="line"><span class="hljs-meta">$</span><span class="hljs-bash"></span></span><br></pre></td></tr></tbody></table></figure></li><li><p>실행 후에는 아무 일도 없다는 듯이 그 다음 line을 출력하지만, <code>localhost:8888</code>로 접속하시면 똑같이 Jupyter notebook을 사용하실 수 있습니다. </p></li></ul><br><h4 id="5-컨테이너-재접속-amp-재시작-attach-restart"><a href="#5-컨테이너-재접속-amp-재시작-attach-restart" class="headerlink" title="5. 컨테이너 재접속 & 재시작 (attach, restart)"></a>5. 컨테이너 재접속 & 재시작 (attach, restart)</h4><ul><li><p>Jupyter notebook은 성공적으로 띄웠으나, 컨테이너에 다시 접속해서 패키지를 더 설치하거나 환경을 세팅해줘야 할 경우, 재접속 하는 방법은 <strong><code>exec</code></strong> 를 사용하는 방법과 <strong><code>attach</code></strong> 를 사용하는 방법, 두 가지가 있습니다. 또 다른 Terminal을 띄우신 뒤에, </p><figure class="highlight shell hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">$</span><span class="hljs-bash"> docker <span class="hljs-built_in">exec</span> -it container_name /bin/bash</span></span><br><span class="line">or</span><br><span class="line"><span class="hljs-meta">$</span><span class="hljs-bash"> docker attach container_name</span></span><br></pre></td></tr></tbody></table></figure><p>  둘 중 하나를 입력하시면 됩니다!</p></li></ul><br><ul><li>컨테이너를 재시작 해주고 싶은 경우는 <strong><code>docker restart</code></strong> 를 사용합니다.   <figure class="highlight shell hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">$</span><span class="hljs-bash"> docker restart contatiner_name</span></span><br></pre></td></tr></tbody></table></figure></li></ul><br><hr><ul><li>이상, Docker의 개념과 설치, 그리고 간단한 기본 명령어들에 대해 알아보았습니다. 다음 <a href="https://www.stand-firm-peter.me/2019/05/09/docker-102/"><code>Hi, Docker!:) (2)</code></a>에서는 <strong><code>컨테이너와 로컬저장소 연결하기</code></strong> 와 <strong><code>내 컨테이너 이미지로 업로드하기</code></strong> 라는 두가지 주제를 다뤄보도록 하겠습니다. </li><li>감사합니다 <span class="github-emoji" style="color: transparent;background:no-repeat url(https://assets-cdn.github.com/images/icons/emoji/unicode/1f60c.png?v8) center/contain" data-src="https://assets-cdn.github.com/images/icons/emoji/unicode/1f60c.png?v8">😌</span></li></ul><h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3><ul><li>이 글은 아래 두 글을 기반으로 작성되었습니다<span class="github-emoji" style="color: transparent;background:no-repeat url(https://assets-cdn.github.com/images/icons/emoji/unicode/1f604.png?v8) center/contain" data-src="https://assets-cdn.github.com/images/icons/emoji/unicode/1f604.png?v8">😄</span>. 더 자세한 정보는 ↓ <ul><li><strong>초보를 위한 도커 안내서 - <a href="https://subicura.com/2017/01/19/docker-guide-for-beginners-1.html" target="_blank" rel="noopener">도커란 무엇인가?</a></strong></li><li><strong>초보를 위한 도커 안내서 - <a href="https://subicura.com/2017/01/19/docker-guide-for-beginners-2.html" target="_blank" rel="noopener">설치하고 컨테이너 실행하기</a></strong></li></ul></li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content:encoded>
      
      <comments>https://www.stand-firm-peter.me/2019/04/24/docker-intro/#disqus_thread</comments>
    </item>
    
    <item>
      <title>Pandas Cheat Sheet</title>
      <link>https://www.stand-firm-peter.me/2019/02/16/pandas-101/</link>
      <guid>https://www.stand-firm-peter.me/2019/02/16/pandas-101/</guid>
      <pubDate>Sat, 16 Feb 2019 08:33:39 GMT</pubDate>
      <description>
      
        &lt;ul&gt;
&lt;li&gt;Pandas의 Dataframe 관련 기능정리.&lt;/li&gt;
&lt;li&gt;Cheat Sheet for Pandas Dataframe.&lt;/li&gt;
&lt;/ul&gt;
      
      </description>
      
      <content:encoded><![CDATA[<ul><li>Pandas의 Dataframe 관련 기능정리.</li><li>Cheat Sheet for Pandas Dataframe.</li></ul><a id="more"></a><h2 id="0-Start"><a href="#0-Start" class="headerlink" title="0. Start"></a>0. Start</h2><ul><li>Import pandas<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd</span><br></pre></td></tr></tbody></table></figure></li></ul><h2 id="1-Creating-a-dataframe"><a href="#1-Creating-a-dataframe" class="headerlink" title="1. Creating a dataframe"></a>1. Creating a dataframe</h2><ul><li><h5 id="Dictionary-Style"><a href="#Dictionary-Style" class="headerlink" title="Dictionary Style:"></a>Dictionary Style:</h5><figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">df = pd.DataFrame(</span><br><span class="line">    {<span class="hljs-string">"a"</span> : [<span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>],</span><br><span class="line">     <span class="hljs-string">"b"</span> : [<span class="hljs-number">7</span>, <span class="hljs-number">8</span>, <span class="hljs-number">9</span>],</span><br><span class="line">     <span class="hljs-string">"c"</span> : [<span class="hljs-number">10</span>, <span class="hljs-number">11</span>, <span class="hljs-number">12</span>]},</span><br><span class="line">     index = [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>])</span><br></pre></td></tr></tbody></table></figure></li><li><h5 id="Array-Style"><a href="#Array-Style" class="headerlink" title="Array Style:"></a>Array Style:</h5><figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">df = pd.DataFrame(</span><br><span class="line">          [[<span class="hljs-number">4</span>, <span class="hljs-number">7</span>, <span class="hljs-number">10</span>],</span><br><span class="line">          [<span class="hljs-number">5</span>, <span class="hljs-number">8</span>, <span class="hljs-number">11</span>],</span><br><span class="line">          [<span class="hljs-number">6</span>, <span class="hljs-number">9</span>, <span class="hljs-number">12</span>]],</span><br><span class="line">          index=[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>],</span><br><span class="line">          columns=[<span class="hljs-string">'a'</span>, <span class="hljs-string">'b'</span>, <span class="hljs-string">'c'</span>])</span><br></pre></td></tr></tbody></table></figure></li></ul><h2 id="2-Select-an-row-or-column"><a href="#2-Select-an-row-or-column" class="headerlink" title="2. Select an row or column"></a>2. Select an row or column</h2><ul><li><h5 id="There-are-5-ways-to-access-the-value-that-is-at-index-0-in-column-‘a’"><a href="#There-are-5-ways-to-access-the-value-that-is-at-index-0-in-column-‘a’" class="headerlink" title="There are 5 ways to access the value that is at index 0, in column ‘a’."></a>There are 5 ways to access the value that is at <code>index 0</code>, in <code>column ‘a’</code>.</h5><p><code>loc</code> selects the value by label, not index.<br><code>iloc</code> accesses to the value using row and column index.</p><figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df.loc[<span class="hljs-number">0</span>][<span class="hljs-string">'a'</span>]</span><br><span class="line">df.iloc[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>]</span><br></pre></td></tr></tbody></table></figure><p><code>at</code> selects the value by label, not index.<br><code>iat</code> accesses to the value using row and column index.</p><figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df.at[<span class="hljs-number">0</span>, <span class="hljs-string">'a'</span>]</span><br><span class="line">df.iat[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>]</span><br></pre></td></tr></tbody></table></figure><p><code>ix</code> can use both label and index.</p><figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.ix[<span class="hljs-number">0</span>, <span class="hljs-string">'a'</span>]</span><br></pre></td></tr></tbody></table></figure></li><li><p><strong>The difference between <code>loc</code> and <code>at</code> is the return type</strong>.<br> <code>loc</code> can return more than one row, it means <code>loc</code> can return a scalar, a Serise or a Dataframe. On the other hand, <code>at</code> <strong>only can access to a cell of certain position</strong>, it means it <strong>returns a scalar only</strong>. Actually it returns a scalar faster than <code>loc</code>, so if you have to deal with great amount of data, it would be more suitable.</p>  <figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">df.at[<span class="hljs-number">2</span>, <span class="hljs-string">'b'</span>]<span class="hljs-comment">#  A scalar.</span></span><br><span class="line">df.iat[<span class="hljs-number">2</span>, <span class="hljs-number">2</span>]</span><br><span class="line">df.loc[<span class="hljs-number">2</span>][<span class="hljs-string">'b'</span>]</span><br><span class="line">df.iloc[<span class="hljs-number">2</span>][<span class="hljs-number">2</span>]</span><br><span class="line">df.ix[<span class="hljs-number">2</span>, <span class="hljs-string">'b'</span>]  </span><br><span class="line"></span><br><span class="line">df.loc[<span class="hljs-number">2</span>][:<span class="hljs-string">'b'</span>]<span class="hljs-comment">#  A Series.</span></span><br><span class="line">df.iloc[<span class="hljs-number">2</span>][:<span class="hljs-number">2</span>]</span><br><span class="line">df.ix[<span class="hljs-number">2</span>, :<span class="hljs-string">'b'</span>]</span><br><span class="line"></span><br><span class="line">df.iloc[:<span class="hljs-number">2</span>][:<span class="hljs-number">2</span>] <span class="hljs-comment">#  A dataframe.</span></span><br><span class="line">df.ix[:<span class="hljs-number">2</span>, :<span class="hljs-string">'b'</span>]</span><br></pre></td></tr></tbody></table></figure></li><li><p>If you want to retrieve the value(s) from a series,</p>  <figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sr = df.b</span><br><span class="line">sr.values()</span><br></pre></td></tr></tbody></table></figure></li></ul><ul><li><h5 id="Select-multiple-rows-or-columns"><a href="#Select-multiple-rows-or-columns" class="headerlink" title="Select multiple rows or columns"></a>Select multiple rows or columns</h5>  <figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># rows</span></span><br><span class="line">df.iloc[[<span class="hljs-number">0</span>, <span class="hljs-number">2</span>]]</span><br><span class="line">df.loc[[<span class="hljs-number">1</span>, <span class="hljs-number">3</span>]]<span class="hljs-comment"># row names</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-comment"># columns</span></span><br><span class="line">df.iloc[:, [<span class="hljs-number">0</span>, <span class="hljs-number">2</span>]]</span><br><span class="line">df[[<span class="hljs-string">"a"</span>, <span class="hljs-string">"c"</span>]]<span class="hljs-comment"># column names</span></span><br></pre></td></tr></tbody></table></figure></li></ul><h2 id="3-Selecting-rows-with-conditions"><a href="#3-Selecting-rows-with-conditions" class="headerlink" title="3. Selecting rows with conditions"></a>3. Selecting rows with conditions</h2><ul><li><h5 id="Condition-in-the-brackets"><a href="#Condition-in-the-brackets" class="headerlink" title="Condition in the brackets."></a>Condition in the brackets.</h5><figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">df[df.a > <span class="hljs-number">4</span>]</span><br><span class="line">df[(df.a > <span class="hljs-number">4</span>) & (df.b < <span class="hljs-number">9</span>)]</span><br><span class="line"><span class="hljs-comment"># You have to wrap all conditions with parentheses.</span></span><br><span class="line">df[((df.a > <span class="hljs-number">4</span>) | (df.b < <span class="hljs-number">9</span>)) & (df.c > <span class="hljs-number">10</span>)]</span><br></pre></td></tr></tbody></table></figure></li><li><h5 id="Condition-using-query"><a href="#Condition-using-query" class="headerlink" title="Condition using query."></a>Condition using query.</h5><figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df.query(<span class="hljs-string">'a > 4'</span>)</span><br><span class="line">df.query(<span class="hljs-string">'a > 4 and b < 9'</span>)</span><br><span class="line">df.query(<span class="hljs-string">'(a > 4 or b < 9) and c > 10'</span>)</span><br></pre></td></tr></tbody></table></figure></li></ul><h2 id="4-Adding-rows-or-columns"><a href="#4-Adding-rows-or-columns" class="headerlink" title="4. Adding rows or columns"></a>4. Adding rows or columns</h2><ul><li><h5 id="Adding-new-rows"><a href="#Adding-new-rows" class="headerlink" title="Adding new rows"></a>Adding new rows</h5><figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df.loc[<span class="hljs-number">3</span>] = <span class="hljs-number">0</span><span class="hljs-comment"># fill with 0</span></span><br><span class="line">df.loc[<span class="hljs-number">3</span>] = [<span class="hljs-number">5</span>, <span class="hljs-number">7</span>, <span class="hljs-number">1</span>]<span class="hljs-comment"># Add a row</span></span><br></pre></td></tr></tbody></table></figure></li><li><h5 id="Creating-a-new-column"><a href="#Creating-a-new-column" class="headerlink" title="Creating a new column"></a>Creating a new column</h5><figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="hljs-string">"d"</span>] = <span class="hljs-number">0</span> <span class="hljs-comment"># fill with 0</span></span><br><span class="line">df[<span class="hljs-string">"d"</span>] = df.a <span class="hljs-comment"># copy column 'a'</span></span><br><span class="line"></span><br><span class="line">df[<span class="hljs-string">"d"</span>] = pd.Series([<span class="hljs-number">13</span>, <span class="hljs-number">14</span>, <span class="hljs-number">15</span>], index = df.index)<span class="hljs-comment"># fill with new values</span></span><br><span class="line">df.loc[ : , <span class="hljs-string">"d"</span>] = pd.Series([<span class="hljs-number">13</span>, <span class="hljs-number">14</span>, <span class="hljs-number">15</span>], index = df.index)</span><br></pre></td></tr></tbody></table></figure></li></ul><h2 id="5-Delete-Indices-Rows-or-Columns"><a href="#5-Delete-Indices-Rows-or-Columns" class="headerlink" title="5. Delete Indices, Rows or Columns"></a>5. Delete Indices, Rows or Columns</h2><ul><li><h5 id="Delete-rows"><a href="#Delete-rows" class="headerlink" title="Delete rows"></a>Delete rows</h5><figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">df.drop([<span class="hljs-number">0</span>, <span class="hljs-number">2</span>], axis=<span class="hljs-number">0</span>)<span class="hljs-comment"># Delete the rows with labels 0, 2</span></span><br><span class="line"></span><br><span class="line">df.set_index(<span class="hljs-string">"a"</span>, inplace=<span class="hljs-literal">True</span>)<span class="hljs-comment"># Delete all rows with label 4</span></span><br><span class="line">df.drop(<span class="hljs-number">4</span>, axis=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">True</span>)</span><br><span class="line">df.reset_index(inplace=<span class="hljs-literal">True</span>)</span><br><span class="line"></span><br><span class="line">df = df.iloc[<span class="hljs-number">2</span>:, ]<span class="hljs-comment"># Delete the first two rows using iloc selector</span></span><br></pre></td></tr></tbody></table></figure></li><li><h5 id="Delete-columns"><a href="#Delete-columns" class="headerlink" title="Delete columns."></a>Delete columns.</h5><figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df.drop(<span class="hljs-string">"a"</span>, axis=<span class="hljs-number">1</span>, inplace=<span class="hljs-literal">True</span>)<span class="hljs-comment"># Delete a column</span></span><br><span class="line">df.drop([<span class="hljs-string">"a"</span>, <span class="hljs-string">"c"</span>], axis=<span class="hljs-number">1</span>, inplace=<span class="hljs-literal">True</span>)<span class="hljs-comment"># Delete multiple columns</span></span><br></pre></td></tr></tbody></table></figure></li></ul><h2 id="6-Combine-Dataframes"><a href="#6-Combine-Dataframes" class="headerlink" title="6. Combine Dataframes"></a>6. Combine Dataframes</h2><ul><li><h5 id="pd-concat"><a href="#pd-concat" class="headerlink" title="pd.concat()"></a>pd.concat()</h5><figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">df2 = pd.DataFrame(<span class="hljs-comment"># Make two more dataframes</span></span><br><span class="line">          {<span class="hljs-string">"a"</span> : [<span class="hljs-number">1</span>, <span class="hljs-number">4</span>, <span class="hljs-number">7</span>],</span><br><span class="line">           <span class="hljs-string">"b"</span> : [<span class="hljs-number">2</span>, <span class="hljs-number">5</span>, <span class="hljs-number">8</span>],</span><br><span class="line">           <span class="hljs-string">"c"</span> : [<span class="hljs-number">3</span>, <span class="hljs-number">6</span>, <span class="hljs-number">9</span>]}, </span><br><span class="line">            index = [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>])</span><br><span class="line"></span><br><span class="line">df3 = pd.DataFrame(</span><br><span class="line">          {<span class="hljs-string">"d"</span> : [<span class="hljs-number">1</span>, <span class="hljs-number">7</span>],</span><br><span class="line">           <span class="hljs-string">"e"</span> : [<span class="hljs-number">2</span>, <span class="hljs-number">8</span>]},</span><br><span class="line">           index = [<span class="hljs-number">1</span>, <span class="hljs-number">3</span>])</span><br><span class="line"></span><br><span class="line"><span class="hljs-comment"># concat rows </span></span><br><span class="line">df4 = pd.concat([df, df2])<span class="hljs-comment"># indices can be duplicated</span></span><br><span class="line">df4.reset_index(drop=<span class="hljs-literal">True</span>, inplace=<span class="hljs-literal">True</span>)<span class="hljs-comment"># Reset index</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-comment"># concat columns</span></span><br><span class="line">df5 = pd.concat([df, df3], axis=<span class="hljs-number">1</span>)</span><br></pre></td></tr></tbody></table></figure></li></ul><ul><li><h5 id="pd-merge"><a href="#pd-merge" class="headerlink" title="pd.merge()"></a>pd.merge()</h5><figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">df6 = pd.DataFrame(<span class="hljs-comment"># Make another dataframes</span></span><br><span class="line">          {<span class="hljs-string">"a"</span> : [<span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">7</span>],</span><br><span class="line">           <span class="hljs-string">"f"</span> : [<span class="hljs-number">20</span>, <span class="hljs-number">50</span>, <span class="hljs-number">80</span>],</span><br><span class="line">           <span class="hljs-string">"g"</span> : [<span class="hljs-number">30</span>, <span class="hljs-number">60</span>, <span class="hljs-number">90</span>]}, </span><br><span class="line">            index = [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>])</span><br><span class="line"></span><br><span class="line">df7 = pd.merge(df, df6)       <span class="hljs-comment"># Inner join </span></span><br><span class="line">df8 = pd.merge(df, df6, how=<span class="hljs-string">'outer'</span>)       <span class="hljs-comment"># Outer join</span></span><br><span class="line">df9 = pd.merge(df, df6, how=<span class="hljs-string">'left'</span>)        <span class="hljs-comment"># left join</span></span><br><span class="line">df10 = pd.merge(df, df6, how=<span class="hljs-string">'right'</span>)      <span class="hljs-comment"># right join</span></span><br></pre></td></tr></tbody></table></figure></li></ul><h2 id="7-Iterate-over-a-dataframe"><a href="#7-Iterate-over-a-dataframe" class="headerlink" title="7. Iterate over a dataframe"></a>7. Iterate over a dataframe</h2><ul><li><h5 id="iterrows"><a href="#iterrows" class="headerlink" title="iterrows()"></a>iterrows()</h5><figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">for</span> index, row <span class="hljs-keyword">in</span> df.iterrows() :</span><br><span class="line">    print(row[<span class="hljs-string">'a'</span>], row[<span class="hljs-string">'b'</span>], row[<span class="hljs-string">'c'</span>])</span><br></pre></td></tr></tbody></table></figure></li></ul><h2 id="8-Reading-and-Writing-a-dataframe"><a href="#8-Reading-and-Writing-a-dataframe" class="headerlink" title="8. Reading and Writing a dataframe"></a>8. Reading and Writing a dataframe</h2><ul><li><h5 id="Reading-a-csv-file"><a href="#Reading-a-csv-file" class="headerlink" title="Reading a csv file:"></a>Reading a csv file:</h5><figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pd.read_csv(<span class="hljs-string">'name.csv'</span>)</span><br><span class="line"><span class="hljs-comment"># if the file has a date column,</span></span><br><span class="line">pd.read_csv(<span class="hljs-string">"name.csv"</span>, parse_dates=[<span class="hljs-string">"column_name"</span>])</span><br><span class="line"><span class="hljs-comment"># Then, pandas transform it as a numpy.datetime64 column.</span></span><br></pre></td></tr></tbody></table></figure></li><li><h5 id="Writing-as-a-csv-file"><a href="#Writing-as-a-csv-file" class="headerlink" title="Writing as a csv file:"></a>Writing as a csv file:</h5><figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df.to_csv(<span class="hljs-string">"name.csv"</span>, index=<span class="hljs-literal">False</span>)</span><br><span class="line"><span class="hljs-comment"># options</span></span><br><span class="line">df.to_csv(<span class="hljs-string">"name.csv"</span>, sep=<span class="hljs-string">'\t'</span>, encoding=<span class="hljs-string">'utf-8'</span>)</span><br></pre></td></tr></tbody></table></figure></li><li><h5 id="Writing-as-an-Excel-file"><a href="#Writing-as-an-Excel-file" class="headerlink" title="Writing as an Excel file:"></a>Writing as an Excel file:</h5><figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">writer = pd.ExcelWriter(<span class="hljs-string">'name.xlsx'</span>)</span><br><span class="line">df.to_excel(writer, <span class="hljs-string">'DataFrame'</span>)</span><br><span class="line">writer.save()</span><br></pre></td></tr></tbody></table></figure></li></ul><h2 id="9-Other-Useful-functions"><a href="#9-Other-Useful-functions" class="headerlink" title="9. Other Useful functions"></a>9. Other Useful functions</h2><ul><li><h5 id="Following-commands-are-used-often"><a href="#Following-commands-are-used-often" class="headerlink" title="Following commands are used often."></a>Following commands are used often.</h5> <figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">df.head(n) <span class="hljs-comment"># Select first n rows </span></span><br><span class="line">df.tail(n) <span class="hljs-comment"># Select last n rows</span></span><br><span class="line">df.nlargest(n, <span class="hljs-string">'a'</span>) <span class="hljs-comment"># Select and order top n entries.</span></span><br><span class="line">df.nsmallest(n, <span class="hljs-string">'c'</span>) <span class="hljs-comment"># Select and order bottom n entries</span></span><br><span class="line">df.sample(frac=<span class="hljs-number">0.5</span>)<span class="hljs-comment"># Randomly select fraction of rows.</span></span><br><span class="line">df.sample(n=<span class="hljs-number">2</span>)<span class="hljs-comment"># Randomly select n rows</span></span><br><span class="line">df.isna()<span class="hljs-comment"># Check whether each element has NA or not </span></span><br><span class="line">df.dropna()<span class="hljs-comment"># Drop rows with any column having NA/null data</span></span><br><span class="line">df.fillna(value)<span class="hljs-comment"># Replace all NA/null data with value</span></span><br><span class="line">df.rename(columns={<span class="hljs-string">"a"</span>: <span class="hljs-string">"k"</span>}, inplace=<span class="hljs-literal">True</span>) <span class="hljs-comment"># Renaming "a" column as "k"</span></span><br><span class="line">df.describe()<span class="hljs-comment"># To see basic statistics</span></span><br><span class="line">df.reset_index(drop=<span class="hljs-literal">True</span>, inplace=<span class="hljs-literal">True</span>)<span class="hljs-comment"># Reset index</span></span><br></pre></td></tr></tbody></table></figure></li></ul><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://www.datacamp.com/community/tutorials/pandas-tutorial-dataframe-python" target="_blank" rel="noopener">DataCamp</a></li><li><a href="https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf" target="_blank" rel="noopener">pandas.pydata.org</a></li><li><a href="https://www.shanelynn.ie/using-pandas-dataframe-creating-editing-viewing-data-in-python/" target="_blank" rel="noopener">Shane Lynn</a></li><li><a href="https://datascienceschool.net/view-notebook/7002e92653434bc88c8c026c3449d27b/" target="_blank" rel="noopener">Data Science School</a></li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content:encoded>
      
      <comments>https://www.stand-firm-peter.me/2019/02/16/pandas-101/#disqus_thread</comments>
    </item>
    
    <item>
      <title>L1 &amp; L2</title>
      <link>https://www.stand-firm-peter.me/2018/09/24/l1l2/</link>
      <guid>https://www.stand-firm-peter.me/2018/09/24/l1l2/</guid>
      <pubDate>Sun, 23 Sep 2018 15:00:00 GMT</pubDate>
      <description>
      
        &lt;ul&gt;
&lt;li&gt;&lt;code&gt;L1&lt;/code&gt;, &lt;code&gt;L2&lt;/code&gt; loss, regularization, and norm.&lt;/li&gt;&lt;/ul&gt;
      
      </description>
      
      <content:encoded><![CDATA[<ul><li><code>L1</code>, <code>L2</code> loss, regularization, and norm.<a id="more"></a></li><li>Machine Learning을 공부하기 시작하면, 꼭 마주치는 <code>L1, L2</code>. </li><li><code>L1, L2 loss</code>라고도 하고 <code>L1, L2 Regularization</code>이라고도 하는데, 명확히 그 각각의 개념과 그 차이를 짚고 넘어가려, Loss로써 쓰일 때와 Regularization으로써 쓰일 때를 정리해 보았다. </li></ul><h2 id="As-an-Error-Function"><a href="#As-an-Error-Function" class="headerlink" title="As an Error Function"></a>As an Error Function</h2><ul><li><p>모델의 Loss, 즉 Cost를 구하는 방법으로 사용하겠다 하면 L1, L2 loss function은 아래와 같은 식을 사용한다. </p></li><li><h3 id="L1-loss"><a href="#L1-loss" class="headerlink" title="L1 loss"></a>L1 loss</h3><p><code>L1 loss</code>부터 살펴보면, 식에서 보는 것과 같이 실제 값($y_i$)과, 예측값($f(x_i)$)의 그 차이값에 절대값을 취해, 그 오차 합을 최소화하는 방향으로 loss를 구한다.<br><code>Least Absolute Deviations</code>라고 하고 줄여서, <code>LAD</code>라고 한다.</p></li></ul><p>$$L = \sum\limits_{i=1}^{n}|y_i - f(x_i)|$$</p><ul><li><h3 id="L2-loss"><a href="#L2-loss" class="headerlink" title="L2 loss"></a>L2 loss</h3><code>L2 loss</code>는 <code>MSE (Mean Sqaured Error)</code>를 안다면 아주 익숙한 개념으로, target value인 실제값($y_i$)과 예측값($f(x_i)$) 사이의 오차를 제곱한 값들을 다 합해서 Loss로 산정한다.<br><code>Least squares error</code>라고 하고, 줄여서 <code>LSE</code>라고 한다. </li></ul><p>$$L = \sum\limits_{i=1}^n(y_i - f(x_i))^2$$</p><br><h3 id="L1-loss와-L2-loss-비교"><a href="#L1-loss와-L2-loss-비교" class="headerlink" title="L1 loss와 L2 loss 비교"></a>L1 loss와 L2 loss 비교</h3><ul><li>L1 loss와 L2 loss는 아래와 같은 차이점을 가지고 있다. </li></ul><h4 id="1-Robustness"><a href="#1-Robustness" class="headerlink" title="1. Robustness:"></a>1. <strong>Robustness</strong>:</h4><blockquote><p>$$L1 > L2$$</p></blockquote><ul><li>여기서 말하는 <code>Robustness</code>는 outlier, 즉 <code>이상치가 등장했을 때, loss function 얼마나 영향을 받는지</code>를 뜻하는 용어다. </li><li>L2 loss는 outlier의 정도가 심하면 심할 수록, 직관적으로 제곱을 하기 때문에 그 계산 값이 L1보다는 더 큰 수치로 작용을 할 수 밖에 없기 때문에 Roubustness에서 L1보다 더 그 성질이 작다고 말할 수 있다. </li><li>그렇기 때문에, <u>outliers가 효과적으로 적당히 무시되길 원한다면</u>, 비교적 이상치의 영향력을 작게 받는 <strong>L1 loss</strong>를, 반대로, <u>이상치의 등장에 주의 깊게 주목을 해야할 필요가 있는 경우</u>라면 <strong>L2 loss</strong>를 취하는 선택을 할 수 있겠다. </li></ul><h4 id="2-Stability"><a href="#2-Stability" class="headerlink" title="2. Stability:"></a>2. <strong>Stability</strong>:</h4><blockquote><p>$$L1 < L2$$</p></blockquote><ul><li><code>Stability</code>는 모델이 <code>비슷한 데이터에 대해서 얼마나 일관적인 예측을 할 수 있는가</code> 정도라고 생각하면 된다. 이해를 돕기 위해, 아래 animation을 참고하자.<br></li></ul><center><img src="/gallery/l2l1.png" width="150" height="80"><img src="/gallery/loss_l1l2.gif" height="250" width="300"> </center><ul><li><p>위 애니메이션 그래프는 실제 데이터(검은 점)와, Outlier point인 주황색 점이 움직임에 따라서 어떻게 그 예측 모델이 달라지는지 실제로 실험을 해 본 결과다. </p></li><li><p>Outlier point가 검은 점들과 비교적 비슷한 위치에 위치해서 덜(?) 이상치 일때, L1 loss 그래프는 변화가 있고 움직이지만, L2 loss 그래프에는 없다는 것을 관찰 할 수 있다. 이런 성질을 보고 <code>L1이 L2보다는 Unstable</code>하다고 표현한다.</p></li><li><p>이 애니메이션에서 위에서 살펴본 Robustness도 살짝 관찰할 수 있는데, Outlier point가 검은 점들이 구성하는 보이지 않는 선을 기준으로 밖에서 안으로 들어올 때,  확실히 L2 error line이 먼저 반응하는 것도 관찰할 수 있다. </p></li></ul><br><h2 id="As-Regularization"><a href="#As-Regularization" class="headerlink" title="As Regularization"></a>As Regularization</h2><ul><li>Machine learning에서 Regularization은 Overfitting을 방지하는 중요한 기법이다. 그래서 수식적으로 L1, L2 Regularization을 말하자면, 모델을 구성하는 계수(coefficients)들이 학습 데이터에 너무 완벽하게 Overfit되지 않도록, 그저 <strong><code>정규화 요소</code></strong>(regularization term)를 <strong>더해주는 것</strong>이다. </li></ul><h4 id="L1-regularization"><a href="#L1-regularization" class="headerlink" title="L1 regularization"></a>L1 regularization</h4><p>$$cost(W, b) = \frac{1}{m}\sum\limits_{i}^mL(\hat y_i, y_i) + \lambda\frac{1}{2}|w|$$</p><h4 id="L2-regularization"><a href="#L2-regularization" class="headerlink" title="L2 regularization"></a>L2 regularization</h4><p>$$cost(W, b) =  \frac{1}{m}\sum\limits_{i}^mL(\hat y_i, y_i) + \lambda\frac{1}{2}|w|^2$$</p><ul><li><p>위와 같이, 더해주는 정규화 요소로 L1 error때 봤던 절대값을 취하는 기법을 쓰냐, L2 error에서처럼 제곱을 취하는 값을 주냐에 따라 L1 정규화이냐 L2 정규화로 나뉜다. 아래는 딥러닝에서 쓰는 Loss function에 각각의 정규화를 취한 식이다. </p></li><li><p>$\lambda$는 얼마나 비중을 줄 것인지 정하는 상수다. 0에 가까울 수록 정규화의 효과는 없어진다. 우리는 적절한 $\lambda$값을 k-fold cross validation과 같은 방법으로 찾을 수 있다.</p></li></ul><h3 id="L1-L2-Regularization-차이-비교"><a href="#L1-L2-Regularization-차이-비교" class="headerlink" title="L1, L2 Regularization 차이 비교"></a>L1, L2 Regularization 차이 비교</h3><ul><li>두 정규화 방식에는 어떤 차이점이 있을까? 우선 그 차이를 확실히 알기 위해 이제 언급될 <code>Norm</code>이라는 개념에 대해 잠깐 언급하고 넘어가도록 하겠다. </li></ul><h4 id="Norm"><a href="#Norm" class="headerlink" title="Norm"></a>Norm</h4><ul><li>Norm은 <strong>벡터의 길이 혹은 크기를 측정하는 방법</strong>(함수)이다. </li></ul><p>$$L_p = \big(\sum\limits_i^n|x_i|^p\big)^{\frac{1}{p}}$$</p><ul><li><p>$p$는 Norm의 차수를 의미한다. 따라서, $p$가 1이면 L1 norm이고, $p$가 2이면 L2 norm이다.  $n$은 대상 벡터의 요소의 수다. </p></li><li><p>보통 Norm은 $||x||_1$ 혹은 $||x||_2$와 같이 L1 Norm이냐, L2 Norm이냐를 구별하는데, 아무런 표시가 없는 <strong>$||x||$와 같이 차수가 생략이 되었다면, L2 Norm을 의미</strong>한다. </p></li><li><p>Norm 계산의 결과로 나오는 수치는 <strong>원점에서 벡터 좌표까지의 거리</strong>고, <strong>Magnitude</strong>라고 부른다. </p><blockquote><p> <strong>L1, L2 정규화</strong>는 이같은 <strong>L1, L2 Norm을 사용한 값을 더해주는 것</strong>이다. 그래서 실제로 너무 Overfitting이 발생할 수 있는 가능을 가진 수치에 <strong>Penalty</strong>를 부여한다고 생각하면 된다. </p></blockquote></li></ul><br><h4 id="1-Solution-uniqueness-amp-Computational-efficiency"><a href="#1-Solution-uniqueness-amp-Computational-efficiency" class="headerlink" title="1. Solution uniqueness & Computational efficiency."></a>1. Solution uniqueness & Computational efficiency.</h4><blockquote><p>$$L2$$</p></blockquote><ul><li>다시 본론으로 돌아와서 L1, L2 정규화의 차이점을 알아보자면, L1, L2 정규화는 L1, L2 Norm을 계산함에 있어서 아래와 같은 특징을 지니게 된다. </li></ul><center><img src="/gallery/distance_l1l2norm.png" height="300"></center><ul><li>초록색이 L2 Norm인데, Square연산에 의해 유일한 Shortest path를 가지는 반면, L1 Norm을 의미하는 빨강, 파랑, 노랑색 path들은 다 같은 길이를 가지지만 제각각 다른 모양을 하고 있다. </li><li>이런 특징 때문에 <strong>Computational efficiency</strong>에서는 L2 Norm이 효율적인 계산량을 제공한다고 볼 수 있다. </li></ul><h4 id="2-Sparsity-amp-Feature-Selection"><a href="#2-Sparsity-amp-Feature-Selection" class="headerlink" title="2. Sparsity & Feature Selection"></a>2. Sparsity & Feature Selection</h4><blockquote><p>$$L1$$</p></blockquote><ul><li><p>$L1$ 정규화의 Sparsity를 설명하기 위해, 다음과 같은 두 Vector가 있다고 생각해보자.</p><blockquote><p>a = (0.25, 0.25, 0.25, 0.25)<br>b = (-0.5, 0.5, 0.0, 0.0)</p></blockquote><p>  이 두 벡터의 $L1 \text{ norm}$을 구하면,<br>   $||a||_1 = |0.25| + |0.25| + |0.25| + |0.25|  = 1$<br>   $||b||_1 = |-0.5| + |0.5| + |0.0| + |0.0| = 1$<br>  과 같이 같은 1이라는 숫자가 나오지만, </p><p>  $L2 \text{ norm}$을 구하면,<br>   $||a||_2 = \sqrt{0.25^2 + 0.25^2 + 0.25^2 + 0.25^2} = 0.5$<br>   $||b||_2 = \sqrt{(-0.5)^2 + (0.5)^2 + 0^2 + 0^2} = 0.707$<br>  과 같이 다른 수가 나온다. </p></li><li><p>이런 L1과 L2의 차이점은 위에서 살펴본 L2의 Solution uniqueness의 성질과 맞물려 생각할 수 있는데, L2는 이처럼 각각의 Vector에 대해 유니크한 값을 추출하는 반면, L1은 경우에 따라 특정 Feature(Vector의 요소)없이도 같은 값을 낼 수 있다는 말이 된다. </p></li><li><p>이런 특징으로 L1 norm은 <strong>Feature Selection</strong>을 하는 데 사용할 수 있고, 특정 Feature들을 0으로 처리해버리는 것이 가능하기 때문에 결과적으로 그 Coefficient들이 <strong>Sparse</strong>한 형태를 가질 수 있다. 만약 $\beta = [\beta_0, \beta_1]$이라는 벡터가 있을 때, 그 L1, L2 Norm의 값이 똑같이 1이라고 했을 때, L1과 L2에서 가능한 영역을 표시를 하자면 아래 그림과 같다. </p></li></ul><br><center><img src="/gallery/l1.png" height="293"></center><p>$$\text{L1: }||\beta||_1 = |\beta_0| + |\beta_1| = 1$$ </p><center><img src="/gallery/l2.png" height="300"></center><p>$$\text{L2: }||\beta||_2 = \sqrt{(\beta_0)^2 + (\beta_1)^2} = 1$$</p><ul><li>위의 그림- L2의 이런 원을 <strong>Unit Circle</strong>이라고 한다 - 위의 예시에서 본 것과 같이 ‘특정 요소가 0일 수 있는 경우의 수 / 전체 경우의 수’ 로 L1 Norm과 L2 Norm을 비교한다고 생각하면 ‘L1 norm의 경우 좀더 β의 요소 중 0이 들어갈 수 있는 가능성이 더 높다’고 말할 수 있다. </li><li>이해를 돕기위해 본 포스팅의 댓글로 <code>C B</code>님이 알려주신 것처럼, 마름모의 둘레는 한 변의 길이가 $\sqrt{2}$ 이니 대략 5.6568… 이 되고, 반지름이 1이니 원의 둘레는 6.28…정도 된다는 점을 생각해보면 된다.</li><li>이런 특징이 L1의 <strong>Sparsity</strong>, 혹은 <strong>Feature Selection</strong>이라는 개념을 가질 수 있게 해준다고 생각할 수 있다. Feature가 너무 많은 데이터셋을 다룰 때 유용하게 쓸 수 있다. 이러한 <strong>Feature Selection</strong>의 특징 때문에 L1 norm은 <strong>convex optimisation</strong>을 할 때 유용하게 쓰인다고 한다.</li></ul><h4 id="참고"><a href="#참고" class="headerlink" title="참고"></a>참고</h4><ul><li>L1 regularization을 쓰는 Regression model을 <strong>Lasso(Least Absolute Shrinkage and Selection Operator) Regression</strong>.</li><li>L2 regularization을 쓰는 Regression model을 <strong>Ridge Regression</strong><br>  이라고 부른다. </li></ul><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><ul><li><a href="https://www.quora.com/What-is-the-difference-between-L1-and-L2-regularization-How-does-it-solve-the-problem-of-overfitting-Which-regularizer-to-use-and-when" target="_blank" rel="noopener">Quora</a></li><li><a href="http://www.chioka.in/differences-between-l1-and-l2-as-loss-function-and-regularization/" target="_blank" rel="noopener">Garbled Notes</a></li><li><a href="https://towardsdatascience.com/l1-and-l2-regularization-methods-ce25e7fc831c" target="_blank" rel="noopener">Anuja Nagpal</a></li><li><a href="http://taewan.kim/post/norm/" target="_blank" rel="noopener">TAEWAN.KIM 블로그</a></li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content:encoded>
      
      <comments>https://www.stand-firm-peter.me/2018/09/24/l1l2/#disqus_thread</comments>
    </item>
    
    <item>
      <title>Logarithms</title>
      <link>https://www.stand-firm-peter.me/2018/09/12/Logarithms/</link>
      <guid>https://www.stand-firm-peter.me/2018/09/12/Logarithms/</guid>
      <pubDate>Wed, 12 Sep 2018 07:38:26 GMT</pubDate>
      <description>
      
        &lt;ul&gt;
&lt;li&gt;Deep Learning 논문에서 자주 등장하는 Log.&lt;/li&gt;
&lt;li&gt;Machine learning 및 통계에서 자주 쓰는 이유!&lt;/li&gt;
&lt;/ul&gt;
      
      </description>
      
      <content:encoded><![CDATA[<ul><li>Deep Learning 논문에서 자주 등장하는 Log.</li><li>Machine learning 및 통계에서 자주 쓰는 이유!</li></ul><a id="more"></a><h3 id="Log를-왜-쓰는-걸까"><a href="#Log를-왜-쓰는-걸까" class="headerlink" title="Log를 왜 쓰는 걸까"></a>Log를 왜 쓰는 걸까</h3><ul><li><p>많은 딥러닝 논문들을 읽다보면, 하나같이 수식으로 설명하기 시작하는데, 그 때 꼭 나오는 친구가 이 <code>Log</code>다. 이미 아시는 분들에겐 시시한 이야기였겠지만, 대충 어렴풋이 필자와 같이 ‘숫자 크기 작게 해주려고 하는 거겠지..’정도로만 생각하고 있었다면(맞긴 맞다만…), 정확한 의미를 알아보자. </p></li><li><p>아래는 상용로그인 $\text{log}x$와, $\text{ln}x$로 많이 쓰는 자연상수 $e$를 밑으로 하는 $\text{log}_ex$의 그래프다. </p>  <img src="/gallery/log.png" width="600"></li><li><p>이 그래프를 보면서 할 수 있는 생각은,</p><blockquote><p>‘$x$값이 엄청나게 커진다고 해도, $y$ 증가율은 격하게 변하지 않구나.’</p></blockquote><blockquote><p>$\to$ ‘$x$수치가 낮을 때는 민감하게 반응하고, 높을 때는 둔감하구나.’</p></blockquote><blockquote><p>$\to$ ‘그럼 수치가 대부분 낮을 때는 비교하기 좋을 거 같고, 이상치와 같은 비정상적인 예외 케이스들도 같이 고려할 수 있겠다.’</p></blockquote><p>  정도가 될 것이다. 그럼 이걸 활용하면 아래와 같은 상황에 유용하게 쓸 수 있다.</p></li></ul><br><h3 id="log-는-어디에-사용되나요"><a href="#log-는-어디에-사용되나요" class="headerlink" title="$log$는 어디에 사용되나요"></a>$log$는 어디에 사용되나요</h3><ul><li>대표적으로 두 가지의 경우에 많이 사용되는 것 같다. <blockquote><ol><li>데이터들 간의 수치적인 간극이 너무 커, 주어진 수치를 그대로 사용하면 회기분석시에 결과가 왜곡될 수도 있어서.</li><li>비선형적인 데이터의 분포를 선형적으로 쉽게 보기 위해서</li></ol></blockquote></li></ul><h4 id="1"><a href="#1" class="headerlink" title="1."></a>1.</h4><ul><li><p>아래의 <a href="http://datum.io/tag/log/" target="_blank" rel="noopener">사진</a>은 동물들의 체중별 뇌의 크기를 나타낸 scatter plot이다. </p>  <img src="/gallery/log3.png" width="600"></li><li><p>파충류같은 작은 동물들 부터, 코끼리, 고래, 공룡까지 다 들어 있다고 생각해보면 그 비교대상들이 서로 가지는 수치적인 차이는 실제로 왼쪽 그림과 같다.</p></li><li><p>오른쪽은 같은 데이터에 상용로그를 취한 것이고 실제로 그 경향성을 더 파악하기 쉬운 형태가 되었다. </p></li><li><p>아래 <a href="https://www.cfa.harvard.edu/~ejchaisson/cosmic_evolution/docs/text/text_cult_3.html" target="_blank" rel="noopener">사진</a>도 그런 방식으로 $\text{log}$를 취해서 파충류부터 고래와 코끼리, 공룡까지 비교한 plot인데, x축과 y축의 수치를 자세히 보면 $\text{log}$를 취한 그래프임을 알 수 있다.</p>  <img src="/gallery/brain.png" width="600"></li></ul><h4 id="2"><a href="#2" class="headerlink" title="2."></a>2.</h4><ul><li><p>아래는 $y=2^x$ 그래프와, 이 그래프에 자연로그를 취한 $\text{ln}2^x$의 그래프다. 비선형 그래프인 $y=2^x$를 선형으로 만들어 주고 있다. </p><img src="/gallery/log2.png" width="600"></li><li><p>이처럼, 로그는 복잡한 비선형인 수식들을 간소화 시켜주는 역할을 한다. 곱셈과 나눗셈이 log연산이 되면서 +, -로 바뀌기 때문에 아무래도, Model에서 computation을 많이 해야하는 부담도 좀더 줄어 들지 않을까?! 이런 이점 때문에도 많이 쓰는 것 같다.</p></li></ul><hr><ul><li>이상, $\text{log}$를 왜 쓰는지 한 번 알아 보았다.</li></ul><h5 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h5><ul><li><a href="http://igija.tistory.com/172" target="_blank" rel="noopener">blog1</a>, <a href="http://datum.io/tag/log/" target="_blank" rel="noopener">blog2</a></li><li><a href="https://www.desmos.com/calculator" target="_blank" rel="noopener">Desmos</a>(그래프 그려주는 사이트) </li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content:encoded>
      
      <comments>https://www.stand-firm-peter.me/2018/09/12/Logarithms/#disqus_thread</comments>
    </item>
    
    <item>
      <title>tf.identity()</title>
      <link>https://www.stand-firm-peter.me/2018/09/07/tf-identity/</link>
      <guid>https://www.stand-firm-peter.me/2018/09/07/tf-identity/</guid>
      <pubDate>Fri, 07 Sep 2018 06:00:30 GMT</pubDate>
      <description>
      
        &lt;ul&gt;
&lt;li&gt;Tensorflow에서 자주 등장하는 &lt;/li&gt;
&lt;li&gt;&lt;code&gt;tf.identity()&lt;/code&gt;에 대해 알아봅니다.&lt;/li&gt;
&lt;/ul&gt;
      
      </description>
      
      <content:encoded><![CDATA[<ul><li>Tensorflow에서 자주 등장하는 </li><li><code>tf.identity()</code>에 대해 알아봅니다.</li></ul><a id="more"></a><h4 id="tf-control-dependencies-와-함께"><a href="#tf-control-dependencies-와-함께" class="headerlink" title="tf.control_dependencies()와 함께"></a>tf.control_dependencies()와 함께</h4><ul><li>모델을 구현하다보면 거의 제일 마지막인 fully connected인 Linear에 이르러 맨 마지막 logits을 뽑아내기 전에 꼭 한 번쯤은 보게 되는 친구가 이 <code>tf.identity()</code>. 습관적으로 그냥 쓰는건가보다 하다가 문득 더 깊이 이해하고 넘어가야하겠다 싶어서 이렇게 포스팅으로 남긴다. </li><li><code>tf.identity()</code>를 이해하기 위해서는 <code>tf.control_dependencies()</code>를 먼저 이해해야 한다. Tensorflow의 공식문서에 따르면 그 설명이 아래와 같다.</li></ul><h3 id="tf-control-dependencies"><a href="#tf-control-dependencies" class="headerlink" title="tf.control_dependencies()"></a>tf.control_dependencies()</h3><blockquote><p>tf.control_dependencies(control_inputs)</p></blockquote><ul><li><p><code>control_inputs</code>: </p></li><li><p>A list of Operation or Tensor objects which <strong>must be executed or computed before running the operations defined in the context.</strong> Can also be None to clear the control dependencies. If eager execution is enabled, any callable object in the control_inputs list will be called.</p></li><li><p>Context 안에서 정의된 <u>Operation이</u> Running되기 “<strong>전</strong>“에 “<strong>먼저</strong>“ 실행시켜줄 친구들을 control inputs으로 넣어주면 먼저 실행해준다는 의미다. </p></li><li><p>그럼 이제 <code>tf.identity()</code>를 살펴보자.</p></li></ul><h3 id="tf-identity"><a href="#tf-identity" class="headerlink" title="tf.identity()"></a>tf.identity()</h3><blockquote><p>tf.identity(input, name=None)</p><ul><li>Return a tensor with the same shape and contents as input.</li></ul></blockquote><ul><li><p><code>input</code>: A Tensor.</p></li><li><p><code>name</code>: A name for the operation (optional).</p></li><li><p>그냥 입력된 Tensor랑 똑같은 Shape, 똑같은 contents를 돌려준다. <strike>그럼 왜 쓰는 거지??</strike></p></li></ul>  <figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">x = tf.Variable(<span class="hljs-number">0.0</span>)</span><br><span class="line">x_plus_1 = tf.assign_add(x, <span class="hljs-number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="hljs-keyword">with</span> tf.control_dependencies([x_plus_1]):</span><br><span class="line">    y = tf.identity(x)</span><br><span class="line">init = tf.initialize_all_variables()</span><br><span class="line"></span><br><span class="line"><span class="hljs-keyword">with</span> tf.Session() <span class="hljs-keyword">as</span> session:</span><br><span class="line">    init.run()</span><br><span class="line">    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">5</span>):</span><br><span class="line">        print(y.eval())</span><br></pre></td></tr></tbody></table></figure><ul><li><p><a href="https://stackoverflow.com/questions/34877523/in-tensorflow-what-is-tf-identity-used-for" target="_blank" rel="noopener">여기</a>에서 가져온 예시를 보면, 이유를 좀 알 수 있는데, 만약에 <code>y = tf.identity(x)</code> 부분이 그냥 <code>y = x</code>라면 아무 일도 일어나지 않음을 알 수 있다. print의 결과가 죄다. 0 0 0 0 0 이다. </p></li><li><p>왜냐하면, <code>tf.control_dependencies()</code>는 <strong>“Operation”이 실행되기 전</strong>에 inputs으로 들어온 부분을 처리해준다고 했는데, <u><code>y = x</code>는 아무런 operation이 없기 때문에</u> <code>x_plus_1</code>를 실행하지 않는다.</p></li></ul><h3 id="결론"><a href="#결론" class="headerlink" title="결론"></a>결론</h3><ul><li>Tensorflow로 모델을 만들 때, 주로 맨 마지막에 Fully connected Layer에서 Output에 해당하는 Logits을 뽑을 때 이 <code>tf.identity()</code>를 많이 쓰는 이유는 <code>tf.control_dependencies()</code>를 실행시켜주기 위한 건덕지(?)를 만들기 위해서다. </li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content:encoded>
      
      <comments>https://www.stand-firm-peter.me/2018/09/07/tf-identity/#disqus_thread</comments>
    </item>
    
    <item>
      <title>Pseudo Labelling</title>
      <link>https://www.stand-firm-peter.me/2018/08/22/pseudo-label/</link>
      <guid>https://www.stand-firm-peter.me/2018/08/22/pseudo-label/</guid>
      <pubDate>Wed, 22 Aug 2018 08:52:56 GMT</pubDate>
      <description>
      
        &lt;ul&gt;
&lt;li&gt;준지도학습인 Pseudo Labeling에 대해 알아봅니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Semi-Supervised Learning&lt;/code&gt;, &lt;code&gt;Pseudo Labeling&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
      
      </description>
      
      <content:encoded><![CDATA[<ul><li>준지도학습인 Pseudo Labeling에 대해 알아봅니다.</li><li><code>Semi-Supervised Learning</code>, <code>Pseudo Labeling</code></li></ul><a id="more"></a><h5 id="Pseudo-Label-The-Simple-and-Efficient-Semi-Supervised-Learning-Method-for-Deep-Neural-Networks"><a href="#Pseudo-Label-The-Simple-and-Efficient-Semi-Supervised-Learning-Method-for-Deep-Neural-Networks" class="headerlink" title="Pseudo-Label: The Simple and Efficient Semi-Supervised Learning Method for Deep Neural Networks"></a><a href="http://deeplearning.net/wp-content/uploads/2013/03/pseudo_label_final.pdf" target="_blank" rel="noopener">Pseudo-Label</a>: The Simple and Efficient Semi-Supervised Learning Method for Deep Neural Networks</h5><h4 id="Peter-Cha"><a href="#Peter-Cha" class="headerlink" title="Peter Cha"></a>Peter Cha</h4><h6 id="이-포스팅은-SHUBHAM-JAIN의-글을-레퍼런스로-사용하였습니다"><a href="#이-포스팅은-SHUBHAM-JAIN의-글을-레퍼런스로-사용하였습니다" class="headerlink" title="이 포스팅은 SHUBHAM JAIN의 글을 레퍼런스로 사용하였습니다."></a>이 포스팅은 <a href="https://www.analyticsvidhya.com/blog/2017/09/pseudo-labelling-semi-supervised-learning-technique/" target="_blank" rel="noopener">SHUBHAM JAIN</a>의 글을 레퍼런스로 사용하였습니다.</h6><hr><ul><li>이번 포스팅에서 살펴 볼, <strong>Pseudo Label</strong>은 <strong>Semi-supervised Learning</strong>의 여러 방법 중 한 가지 입니다. </li><li>먼저, Semi Supervised Learning이 무엇인지 살펴보기로 하겠습니다.</li></ul><br><hr><h2 id="1-Semi-Supervised-Learning란"><a href="#1-Semi-Supervised-Learning란" class="headerlink" title="1. Semi-Supervised Learning란?"></a>1. Semi-Supervised Learning란?</h2><ul><li><p>우리는 보통 <strong>labelled data (supervised learning)와 unlabelled data(unsupervised learning) 양쪽 모두를 사용하는</strong> 방식의 학습을 Semi-Supervised Learning(이하 SSL)라고 정의합니다.</p></li><li><p>그러면, 어떠한 상황에 SSL이 필요할까요? 보통 다음과 같은 두 가지 상황이 있습니다.  </p><blockquote><ol><li>만들고자 하는 Model에 쓸, Training data가 절대적으로 부족할 때.</li><li>Large dataset이 될 수록 새로 생성되는 data들에 대한 Human annotation이 힘들고, 비쌀 때.</li></ol></blockquote></li><li><p>그래서, 보통은 ‘<strong>데이터가 부족할 때 쓰는 방법</strong>‘으로만 알고 있지만, SSL을 아래와 같은 이유로 사용할 수도 있습니다. </p><blockquote><ol start="3"><li>Labeled data만으로는 도달 할 수 있는 성능에 한계가 있을 때, Unlabelled data를 사용하여 전반적인 성능을 더 높이기 위해. </li></ol></blockquote></li><li><p>논문에서 말하고 있는 Semi Supervised Learning의 목적과, 이 글 후반부에 나올 필자의 <code>Pseudo Label</code>실험도 이 세 번째 이유에 대한 것입니다.</p></li></ul><center><img src="/gallery/semi.jpg"></center><h6 id="Image-from-Dataiku-hadoop-summit"><a href="#Image-from-Dataiku-hadoop-summit" class="headerlink" title="Image from Dataiku hadoop summit."></a>Image from <a href="https://www.slideshare.net/Dataiku/dataiku-hadoop-summit-semisupervised-learning-with-hadoop-for-understanding-user-web-behaviours" target="_blank" rel="noopener">Dataiku hadoop summit</a>.</h6><br><hr><h2 id="2-Unlabeled-data는-어떻게-도움이-될까"><a href="#2-Unlabeled-data는-어떻게-도움이-될까" class="headerlink" title="2. Unlabeled data는 어떻게 도움이 될까?"></a>2. Unlabeled data는 어떻게 도움이 될까?</h2><ul><li>그렇다면 Unlabeled data를 쓴다는 것은 어떤 이점이 있을까요? </li></ul><blockquote><ol><li>Labelled data 는 비싸고 얻기 힘들지만 unlabelled는 그 양이 풍부하고 값이 싸기 때문에 <strong>데이터 획득이 용이하다</strong>.</li><li>Unlabeled data는 Model의 <u>Decision boundary를 더 정확하게 잡아주는 역할을</u> 해줌으로써, <strong>모델의 Robustness를 향상</strong>시킨다. </li></ol></blockquote><ul><li><p>두 번째 장점을 처음 읽으면 조금 추상적으로 다가올 수 있습니다. 그림으로 조금 더 설명하자면 아래와 같습니다. </p></li><li><p>단순히 2가지의 Class를 구별해야하는 모델의 경우, Labeled data만 가지고 그 Decision Boundary를 결정하게 되면 선형으로 그 Decision Boundary가 그어진다고 생각해 봅시다. 가지고 있는 Labeled Data에서 경계라고 판단할 만한 정보가 저것밖에 없기 때문에 가지고 있는 Data로 학습시킬 수 있는 모델의 한계라고도 생각할 수 있습니다. </p></li><li><p>다른 Unlabeled Data를 사용하면서 학습을 하면, 경계를 그을 때, 더 많은 Case들을 고려하면서 정교하게 경계를 긋기 시작합니다. </p></li><li><p>이는 자연스럽게, 나중에 모델이 Test set을 만났을 때, 혹은 처음보는 다른 Data를 만났을 때도, ‘당황하지 않고 대응할 수 있는’ 힘을 가지게 해준다고 이해할 수도 있습니다. 그래서 두 번째 장점에서 말하고 있는 모델의 <strong><code>Robustness</code></strong>(견고함)는 이를 뜻합니다. 우리가 잘 알고 있는 Overfitting도 이 Robustness의 정도가 낮아서 발생하는 것이라고 볼 수 있습니다.  </p></li></ul><center><img src="/gallery/a.png" height="350"><img src="/gallery/b.png" height="350"></center><h6 id="Images-from-A-Tutorial-on-Graph-based-Semi-Supervised-Learning-Algorithms-for-NLP"><a href="#Images-from-A-Tutorial-on-Graph-based-Semi-Supervised-Learning-Algorithms-for-NLP" class="headerlink" title="Images from A Tutorial on Graph based Semi-Supervised Learning Algorithms for NLP."></a>Images from <a href="http://graph-ssl.wdfiles.com/local--files/blog%3A_start/graph_ssl_acl12_tutorial_slides_final.pdf" target="_blank" rel="noopener">A Tutorial on Graph based Semi-Supervised Learning Algorithms for NLP</a>.</h6><br><hr><h2 id="3-Pseudo-Labeling을-소개합니다"><a href="#3-Pseudo-Labeling을-소개합니다" class="headerlink" title="3. Pseudo Labeling을 소개합니다 :)"></a>3. Pseudo Labeling을 소개합니다 :)</h2><ul><li><p>Pseudo Labelling의 개념은 아주 간단합니다. Labeled Data처럼 일일히 label을 하기보다, 이미 가지고 있는 <u>Labeled data에 기반하여</u> <strong>대략적인 Label을 주는 것</strong>을 <code>Pseudo Labelling</code>이라고 합니다. </p></li><li><p>그래서 Pseudo Labeling의 순서는 다음과 같습니다.</p><blockquote><ol><li>Labeled Data로 Model을 먼저 학습시킨다. </li><li>그렇게 학습된 모델을 사용하여, Unlabeled Data를 예측하고 그 결과를 Label로 사용하는 Pseudo-labeled data를 만든다.</li><li>Pseudo-labeled data와 Labeled data를 모두 사용하여 다시 그 모델을 학습시킨다.</li></ol></blockquote></li></ul><center><img src="/gallery/pseudo.png" height="350"><img src="/gallery/pseudo2.png" height="350"></center><h6 id="Images-from-Data-what-now"><a href="#Images-from-Data-what-now" class="headerlink" title="Images from Data, what now?"></a>Images from <a href="https://datawhatnow.com/pseudo-labeling-semi-supervised-learning/" target="_blank" rel="noopener">Data, what now?</a></h6><h3 id="3-1-Pseudo-Labeled-data"><a href="#3-1-Pseudo-Labeled-data" class="headerlink" title="3.1. Pseudo Labeled data"></a>3.1. Pseudo Labeled data</h3><ul><li>Pseudo Label은 아래와 같은 식으로, <strong>각각의 sample에 대해, 예측된 확률이 가장 높은 것</strong>으로 정합니다.</li></ul><center><img src="/gallery/formula1.png" height="80"></center><ul><li>예측된 확률이 가장 높은 것을 Label로 선정한다고 했을 때, 제대로 학습을 마치지 못한 모델로 이 작업을 하였을 경우에는 상식적으로 더 학습을 저해하는 데이터를 만들 뿐입니다. </li><li>그래서 Pseudo Label은 학습을 Labeled data로 일정 수준까지 마친 뒤의, <strong><em>fine-tuning</em> phase</strong>에 시행합니다. </li></ul><h3 id="3-2-Loss-Function-for-Pseudo-Labelling"><a href="#3-2-Loss-Function-for-Pseudo-Labelling" class="headerlink" title="3.2. Loss Function for Pseudo Labelling"></a>3.2. Loss Function for Pseudo Labelling</h3><ul><li>논문에서 Pseudo Label로 학습을 할 때는, 다음과 같은 Loss function을 사용합니다. </li></ul><center><img src="/gallery/formula2.png" height="300"></center><br><ul><li>적절한 수치의 $\alpha(t)$가 네트워크 성능에 있어서 매우 중요한 요소입니다. $\alpha(t)$가 너무 높으면 labeled data의 training을 방해할 것이고, 반대로 너무 그 수치가 작으면 unlabeled data의 유익을 취할 수 없게 되겠죠. </li><li>그래서 아래와 같이 점진적으로 그 비율을 늘려주는 식으로 $\alpha(t)$를 조절하여서 local minima에 빠지는 문제를 점차 피할 수 있도록하여, Process를 최적화시킵니다. </li></ul><center><img src="/gallery/formula3.png" height="225"></center><br><hr><h2 id="4-Pseudo-Label로-성능향상이-왜-가능한거죠"><a href="#4-Pseudo-Label로-성능향상이-왜-가능한거죠" class="headerlink" title="4. Pseudo-Label로 성능향상이 왜 가능한거죠?"></a>4. Pseudo-Label로 성능향상이 왜 가능한거죠?</h2><ul><li>논문에서는 이 <strong>Pseudo Label이 왜 잘 동작하는지</strong>에 대해 아래와 같이 설명합니다.</li></ul><h4 id="4-1-Low-Density-Separation-between-Classes"><a href="#4-1-Low-Density-Separation-between-Classes" class="headerlink" title="4.1. Low-Density Separation between Classes."></a>4.1. Low-Density Separation between Classes.</h4><ul><li><a href="http://olivier.chapelle.cc/pub/nips_cluster.pdf" target="_blank" rel="noopener">Cluster Assumption</a> (Chapelle et al., 2005)에 의하면, Model의 전반적인 성능을 높이기 위해서는 <strong>Model의 Decision boundary는 Low-densidy regions에 위치해야한다</strong>고 말하고 있습니다. </li><li>즉, 앞에서 살펴본 Decision Boundary를 결정할 때, 그 <u>경계를 구분하는 지점의 데이터가 몰려있는 밀도가 낮으면 낮을수록, 더 미세한 차이점도 구별</u>한다고 생각할 수 있기 때문에, 전체적인 성능을 높일 수 있다고 말하고 있습니다. </li><li>그런 점에서, Pseudo Label이 아닌 다른 SSL들인, Semi-Supervised Embedding (Weston et al., 2008)이나, Manifold Tangent Classifier (Rifai et al., 2011b)도 같은 목적을 달성한 방식이라고 소개하고 있습니다. Pseudo Label도 마찬가지로 <strong><code>Low-Density Separation</code></strong> 효과를 가져오는 방법이라는 것이죠.</li></ul><h4 id="4-2-Entropy-Regularization"><a href="#4-2-Entropy-Regularization" class="headerlink" title="4.2. Entropy Regularization"></a>4.2. Entropy Regularization</h4><ul><li><a href="http://www.iro.umontreal.ca/~lisa/pointeurs/semi-supervised-entropy-nips2004.pdf" target="_blank" rel="noopener">Entropy Regularization</a> (Grandvalet, Yoshua Bengio, 2006)은 Baysian에서 말하는 <strong>Maximum posteriori estimation</strong>(or Maximum a posteriori, <strong>MAP</strong>) 관점에서 Unlabelled data의 이점을 얻는 수단입니다.</li><li>이 방식은 Unlabeled data가 가지는 class별 확률에 대한 Entropy를 최소화시킴으로써, 위에서 언급한 Class들 간의 Low-Density separation을 추구합니다. </li><li>아래에 나오는 MAP식들과 함께 더 자세히 설명하도록 하겠습니다. </li></ul><center><img src="/gallery/formula4.png" height="400"></center><ul><li><p>위와 같은 MAP식에서 $\sum\limits_{m = 1}^{n}\text{log}P(y^{m}|x^{m};\theta)$를 첫번째 항, $-\lambda H(y|x^{‘};\theta)$를 두 번째 항이라고 지칭할 때, 첫 번째 항인 <strong>labeled data의 log-likelihood을 최대화</strong>시키면서, 두 번째 항인 <strong>unlabeled data의 entropy를 최소화</strong>시키기 때문에, 우리는 좀 더 좋은 성능을 얻을 수 있게 됩니다.</p></li><li><p>두번째 항에서 최소화 시킨다는 <strong>Entropy는 Class간의 그 경계치가 Overlap이 되는 정도</strong>를 뜻하는데요, Class Overlap이 작아질수록, data들의 밀집된 부분이 더 낮은 decision boundary를 가지게 됩니다. 이것이 위에서 설명한, </p><blockquote><p>class별 확률에 대한 Entropy를 최소화시킴으로써, 위에서 언급한 Class들 간의 Low-Density separation을 추구합니다.</p></blockquote><p>  의 의미입니다. </p></li><li><p>따라서, 위에서 설명 하였던 <strong>Pseudo-Label의 Loss function에서 나오는 $\alpha$는 Entropy Regularization의 $\lambda$와 같은 역할</strong>을 하고 있다는 것을 관찰하실 수 있습니다. 결론적으로 이 논문에서 말하고 있는 바는, </p><blockquote><p>우리가 취한 Loss function은 Entropy Regularzation과 동일하다! 그래서, Pseudo-Label을 Entropy Regularization으로 Training하는 것이 효과가 있다.</p></blockquote><p>  로 정리할 수 있습니다. </p></li></ul><h4 id="4-3-논문-실험-결과"><a href="#4-3-논문-실험-결과" class="headerlink" title="4.3. 논문 실험 결과"></a>4.3. 논문 실험 결과</h4><ul><li>논문의 저자는 MNIST test data로 t-SNE (Van der Maaten et al., 2008) 2-D embedding results를 첨부하여 그 성능을 보여주고 있습니다. train data는 600개 밖에 쓰지 않았고, 60000개의 unlabeled data를 사용했다고 하네요.</li><li>Pseudo-Label (이하 PL)을 쓰지 않은 DropNN 모델과, 거기에 PL을 쓴 +PL 모델의 Conditional Entropy를 비교해 보면, Train에서는 +PL이 확실히 그 Entropy가 더 높게 나타나지만, Unlabeled data나, Test set에서 나오는 Entropy는 월등히 낮음을 볼 수 있었습니다.</li></ul><center><img src="/gallery/table1.png" height="140"></center><ul><li>시각적으로도 그 구분하는 경계 즉, Decision boundary가 어떤 모델이 더 섬세하게 작용하고 있는지(=더 확실히 구별하고 있는지) 확인할 수 있습니다. </li></ul><center><img src="/gallery/tSNE(a).png" height="350"><img src="/gallery/tSNE(b).png" height="350"></center><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content:encoded>
      
      <comments>https://www.stand-firm-peter.me/2018/08/22/pseudo-label/#disqus_thread</comments>
    </item>
    
    <item>
      <title>Tensorpack tutorial</title>
      <link>https://www.stand-firm-peter.me/2018/08/18/Tensorpack-tutorial/</link>
      <guid>https://www.stand-firm-peter.me/2018/08/18/Tensorpack-tutorial/</guid>
      <pubDate>Sat, 18 Aug 2018 06:00:30 GMT</pubDate>
      <description>
      
        &lt;ul&gt;
&lt;li&gt;Tensorflow Wrapper인 Tensorpack을 소개합니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Tensorflow&lt;/code&gt;, &lt;code&gt;Tensorpack&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
      
      </description>
      
      <content:encoded><![CDATA[<ul><li>Tensorflow Wrapper인 Tensorpack을 소개합니다.</li><li><code>Tensorflow</code>, <code>Tensorpack</code></li></ul><a id="more"></a><h5 id="ModelDesc와-Trainer를-중심으로"><a href="#ModelDesc와-Trainer를-중심으로" class="headerlink" title="ModelDesc와 Trainer를 중심으로"></a>ModelDesc와 Trainer를 중심으로</h5><h3 id="Peter-Cha"><a href="#Peter-Cha" class="headerlink" title="Peter Cha"></a>Peter Cha</h3><h2 id="Tensorpack을-공부하면"><a href="#Tensorpack을-공부하면" class="headerlink" title="Tensorpack을 공부하면,"></a>Tensorpack을 공부하면,</h2><ul><li>우선 모르는 것들 투성이다. 알고나면 너무 쓰기 편하지만, 처음 접할 때는 너무 많이 추상화 된 API에 ‘이게 tensorflow는 맞는지..’할 정도니까.</li><li>우선 이 튜토리얼을 보기 전, 필자의 <a href="https://github.com/PeterCha90/Tensorflow-Deep-Learning/blob/master/Tutorials/Tensorpack_tutorial.ipynb" target="_blank" rel="noopener"><code>tensorpack_tutorial.ipynb</code></a>를 실행해 보길 바란다. 대략적인 dataflow는 데이터를 불러오는 부분으로 이해를 마쳤다고 생각을 하고, dataflow부분은 생략하고 설명을 진행하도록 하겠다. </li><li>이번에는 Model의 선언하게 될 때 상속받은 <strong><code>ModelDesc</code></strong> class와, 학습을 실행하는 Trainer들의 모태가 되는 <strong><code>TowerTrainer</code></strong> 에 대해 알아보고자 한다.<code>tensorpack_tutorial.ipynb</code>에서 설명에 해당하는 부분을 함께 찾아보면 이해에 도움이 더 될 것 같다. </li><li>이 Tutorial은 Tensorpack <a href="https://tensorpack.readthedocs.io/modules/train.html?highlight=TowerFuncWrapper" target="_blank" rel="noopener">documentation</a>을 참고해서 만들었다. </li></ul><hr><br><h2 id="1-Class-ModelDescBase"><a href="#1-Class-ModelDescBase" class="headerlink" title="1. Class ModelDescBase"></a>1. Class <code>ModelDescBase</code></h2><blockquote><p>Base class for a model description이다.</p></blockquote><ul><li><code>ModelDesc</code>는 ModelDescBase를 기반으로 만들어졌기 때문에, <code>ModelDescBase</code>를 먼저 설명한다. </li></ul><h3 id="1-1-build-graph-args"><a href="#1-1-build-graph-args" class="headerlink" title="1.1. build_graph(*args)"></a>1.1. build_graph(*args)</h3><ul><li>모든 symbolic graph (<strong>Model의 형태</strong>)를 Build한다. 이 함수가 뒤에서 설명할 <code>TowerTrainer</code>에서 <code>tower function</code>의 일부분이다.</li><li>그 다음 설명할 <code>inputs()</code>에서 정의된 input list에 맞는 <code>tf.Tensor</code>를 parameter로 받는다. </li><li>아무것도 리턴하지 않는다. </li></ul><h3 id="1-2-inputs"><a href="#1-2-inputs" class="headerlink" title="1.2. inputs()"></a>1.2. inputs()</h3><ul><li>Model에서 input으로 받을 텐서들의 placeholder들을 정의하는 함수다. </li><li>후에 <code>InputDesc</code>로 변환될, <code>tf.placeholder</code>들을 return 한다.</li></ul><center><img src="/gallery/modeldesc.png" width="750"></center><h3 id="1-3-get-inputs-desc"><a href="#1-3-get-inputs-desc" class="headerlink" title="1.3. get_inputs_desc"></a>1.3. get_inputs_desc</h3><ul><li>이름에서 알 수 있듯이, inputs()에서 정의된 모양대로 생긴 InputDesc를 list로 반환하는 함수다. </li></ul><hr><br><h2 id="2-Class-ModelDesc"><a href="#2-Class-ModelDesc" class="headerlink" title="2. Class ModelDesc"></a>2. Class <code>ModelDesc</code></h2><ul><li><strong>주의사항</strong>: <strong>build_graph()를 꼭 cost를 return하도록</strong> 코딩해야 한다.</li><li>앞에서 설명한 ModelDescBase를 상속받은 터라, 위의 3가지는 함수는 내장하고 있다. </li></ul><h3 id="2-1-optimizer"><a href="#2-1-optimizer" class="headerlink" title="2.1. optimizer()"></a>2.1. optimizer()</h3><ul><li><code>tf.train.Optimizer</code>를 여기에 선언해주고 Return하게끔 함수를 짜준다. </li></ul><h3 id="2-2-get-optimizer"><a href="#2-2-get-optimizer" class="headerlink" title="2.2. get_optimizer()"></a>2.2. get_optimizer()</h3><ul><li>optimizer()를 호출하면, 계속 새로 optimizer를 만들어서 생성하는데, 이 함수를 쓰면 이미 optimizer()를 통해 생긴 optimizer를 기록해 놓았다가 반환시켜준다. </li></ul><hr><br><h2 id="3-Class-TowerTrainer"><a href="#3-Class-TowerTrainer" class="headerlink" title="3. Class TowerTrainer"></a>3. Class <code>TowerTrainer</code></h2><h4 id="Tensorpack에서는"><a href="#Tensorpack에서는" class="headerlink" title="Tensorpack에서는,"></a>Tensorpack에서는,</h4><ul><li>우리가 흔히 말하는 Model을 계속 Tower라고 지칭한다.(왜 그런지 모르겠다.<span class="github-emoji" style="color: transparent;background:no-repeat url(https://assets-cdn.github.com/images/icons/emoji/unicode/1f636.png?v8) center/contain" data-src="https://assets-cdn.github.com/images/icons/emoji/unicode/1f636.png?v8">😶</span>)</li><li>그래서 아래에서 나오는 <code>TowerTrainer</code>는 만든 모델을 학습을 시키는 <strong>Trainer</strong>고, 그 트레이너가 어떤 특징들을 가진 함수들을 들고 다니는지 이해하면 이해가 쉽다. </li><li>기본적으로 <u>Tensorpack에 나오는 모든 Trainer들은 <code>TowerTrainer</code>의 subclass다</u>. 이 개념이 그래서 궁극적으로는 모든 neural-network training을 가능하게 해준다. </li></ul><h3 id="3-1-get-predictor-input-names-output-names-device-0"><a href="#3-1-get-predictor-input-names-output-names-device-0" class="headerlink" title="3.1. get_predictor(input_names, output_names, device=0)"></a>3.1. <code>get_predictor</code>(input_names, output_names, device=0)</h3><blockquote><p>Returns a callable predictor built under <code>TowerContext(is_training=False)</code>. </p></blockquote><ul><li>이 함수가 호출되면, 가지고 있는 TowerContext(모델)가 <u>training mode가 아닌 상태(is_training=False)</u>로 돌려준다. 그러니까 <strong>Test data로 시험할 때만 부르는 함수</strong>. 그래서 이름도 predictor.</li><li><strong><code>Parameters</code></strong>: <code>input_names</code> <strong>(list)</strong>, <code>output_names</code> <strong>(list)</strong>, <code>device</code> <strong>(int)</strong> – build the predictor on device ‘/gpu:{device}’ or use -1 for ‘/cpu:0’.</li><li>파라미터로 들어가는 input, output이름은 모델 안에서 선언된 이름이 아니면 안 돌아가니까 조심.</li></ul><h3 id="3-2-inputs-desc"><a href="#3-2-inputs-desc" class="headerlink" title="3.2. inputs_desc"></a>3.2. inputs_desc</h3><blockquote><p>Returns – list[InputDesc]: metainfo about the inputs to the tower.</p></blockquote><ul><li>말 그대로, 모델에 들어갈 Input의 크기와 같은 정보가 들어있는 list를 반환해준다. </li></ul><h3 id="3-3-tower-func"><a href="#3-3-tower-func" class="headerlink" title="3.3. tower_func"></a>3.3. tower_func</h3><blockquote><p>Build Model.</p></blockquote><ul><li>이 친구가 실제 <strong>모델을 정의하고, Build</strong>할 수 있는 함수를 세팅하는 부분!</li><li><strong><code>ModelDesc</code></strong> interface로 정의된 model을 trainer로 돌려야 하는 상황이 자주 발생할 수 있는데, 이 때, <u>ModelDesc에서 선언된 <strong>build_graph 함수</strong>가 이 역할을 대신</u>해 줄 수 있다.</li></ul><h3 id="3-4-towers"><a href="#3-4-towers" class="headerlink" title="3.4. towers"></a>3.4. towers</h3><blockquote><p>Returns – a TowerTensorHandles object, to access the tower handles by either indices or names.</p></blockquote><ul><li>모델 및 Train 전반에 걸쳐 관련된 변수들에 접근하고 싶을 때 사용한다! 그래서 이 함수는 Transfer learning을 할 때 유용할 거 같다.</li><li>이미 <u><strong>모델 그래프가 Set up이 끝난 뒤에만</strong> 이 함수는 호출될 수 있다</u>. </li><li>각각의 <code>layer</code>와 <code>attributes</code>에 이 <code>towers</code>함수를 호출하면 접근할 수 있게 된다! 아래는 예시.</li></ul><figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># Access the conv1/output tensor in the first training tower</span></span><br><span class="line">trainer.towers.training()[<span class="hljs-number">0</span>].get_tensor(<span class="hljs-string">'conv1/output'</span>)</span><br></pre></td></tr></tbody></table></figure><hr><br><h2 id="4-Class-Trainer"><a href="#4-Class-Trainer" class="headerlink" title="4. Class Trainer"></a>4. Class <code>Trainer</code></h2><blockquote><p>Base class for a trainer.</p></blockquote><ul><li><p>분명히 위에서 금방, </p><blockquote><p>“기본적으로 <u>Tensorpack에 나오는 모든 Trainer들은 <code>TowerTrainer</code>의 subclass다</u> “</p></blockquote><p>  라고 했는데, 이 <code>TowerTrainer가 상속을 받는 class</code>가 있었으니, 이름하여 TowerTrainer보다 더 단순한 <strong><code>Trainer</code></strong> 다.</p></li><li><p>다른 TowerTrainer를 상속 받은 Trainer들을 사용할 때, 종종 TowerTrainer에서 본 적 없는 친구들이 나타나는데, 그 친구들이 Trainer의 것인 경우가 있다. </p></li><li><p>하지만, Trainer 고유 함수나 요소에 직접적으로 접근할 일이 별로 없어서 아래의 3가지 정도만 알고 있으면 될 것 같다. 나머지는 <a href="https://tensorpack.readthedocs.io/modules/train.html?highlight=register_callback#tensorpack.train.Trainer" target="_blank" rel="noopener">문서</a>를 참고하자. </p></li></ul><blockquote><p>아래 1, 2번의 max_epoch과, steps_per_epoch은 <code>TrainConfig</code>에서 자주 만나는 키워드들인데, 이 친구들이 Trainer의 요소였다.</p></blockquote><h3 id="4-1-max-epoch"><a href="#4-1-max-epoch" class="headerlink" title="4.1. max_epoch"></a>4.1. max_epoch</h3><ul><li>Epoch은 몇 번 돌릴 것인지</li></ul><h3 id="4-2-steps-per-epoch"><a href="#4-2-steps-per-epoch" class="headerlink" title="4.2. steps_per_epoch"></a>4.2. steps_per_epoch</h3><ul><li>한 에폭당 steps은 총 몇 번인지.</li></ul><center><img src="/gallery/sample.png" width="750"></center><h3 id="4-3-register-callback-cb"><a href="#4-3-register-callback-cb" class="headerlink" title="4.3. register_callback(cb)"></a>4.3. register_callback(cb)</h3><blockquote><p>Register callbacks to the trainer. It can only be called before Trainer.train().</p></blockquote><ul><li><u>Trainer가 모델을 돌릴 때마다(epoch이 진행 됨에 따라), 수행하게 될 부가적인 기능</u>들을 Tensorpack에서는 <strong>callback</strong>이라고 부르고, 대표적인 callback으로 <strong>ModelSaver()</strong> 가 있다.</li><li>이 Callback을 명시적으로 전달하여 Trainer Object에 세팅할 수 있는 기능이다. 주로 모델을 튜닝할 때, 설정하면서 종종 쓰는 것을 코드 상에서 확인할 수 있다. </li></ul><hr><br><h2 id="5-TowerContext"><a href="#5-TowerContext" class="headerlink" title="5. TowerContext"></a>5. TowerContext</h2><ul><li><p><strong><code>TowerContext</code></strong> 는 Training과 Validation 혹은 Test시에 동작이 달라야 하는 <code>BatchNorm</code>이나, <code>Dropout</code>을 제어하기 위해서 만들어진 function이다. </p></li><li><p><code>tensorpack_tutorial.ipynb</code>에서는 이 친구를 찾아볼 수 없는데, SimpleTrainer 소스코드를 보니, 자체적으로 안에서 train/test time에 맞춰서 TrainTowerContext라는 것으로 조절하고 있기 때문이었다. 사용법은 간단하다. </p><figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># training</span></span><br><span class="line"><span class="hljs-keyword">with</span> TowerContext(<span class="hljs-string">''</span>, is_training=<span class="hljs-literal">True</span>):</span><br><span class="line">  <span class="hljs-comment"># call any tensorpack layer</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-comment"># test</span></span><br><span class="line"><span class="hljs-keyword">with</span> TowerContext(<span class="hljs-string">'name or empty'</span>, is_training=<span class="hljs-literal">False</span>):</span><br><span class="line">  <span class="hljs-comment"># build the graph again</span></span><br></pre></td></tr></tbody></table></figure></li></ul><ul><li><p>그래서, 내가 세운 모델을 외부에서 사용하고 싶을 때, 즉, 나만의 Trainer를 새로 정의해서 train/test time때, 다르게 동작을 해야하는 상황이라면, TowerContext를 적절히 써서 분기시켜줘야 한다. </p></li><li><p>아래는 Tensorpack Github에서 제공하는 <a href="https://github.com/tensorpack/tensorpack/blob/master/examples/GAN/GAN.py" target="_blank" rel="noopener">GANTrainer</a>에서 실제로 TowerContext를 어떻게 설정해주는지 보여주는 예시다. </p><figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">GANTrainer</span><span class="hljs-params">(TowerTrainer)</span>:</span></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, input, model)</span>:</span></span><br><span class="line">    ..</span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">    <span class="hljs-comment"># Build the graph</span></span><br><span class="line">        self.tower_func = TowerFuncWrapper(model.build_graph, inputs_desc)</span><br><span class="line">        <span class="hljs-keyword">with</span> TowerContext(<span class="hljs-string">''</span>, is_training=<span class="hljs-literal">True</span>):</span><br><span class="line">            self.tower_func(*input.get_input_tensors())</span><br><span class="line">        opt = model.get_optimizer()</span><br><span class="line">    ...</span><br></pre></td></tr></tbody></table></figure></li></ul><hr><h2 id="Thank-you"><a href="#Thank-you" class="headerlink" title="Thank you :)"></a>Thank you :)</h2><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content:encoded>
      
      <comments>https://www.stand-firm-peter.me/2018/08/18/Tensorpack-tutorial/#disqus_thread</comments>
    </item>
    
    <item>
      <title>Basic Deep learning 02</title>
      <link>https://www.stand-firm-peter.me/2018/04/06/Basic-Deep-Learning-02/</link>
      <guid>https://www.stand-firm-peter.me/2018/04/06/Basic-Deep-Learning-02/</guid>
      <pubDate>Fri, 06 Apr 2018 14:31:02 GMT</pubDate>
      <description>
      
        &lt;ul&gt;
&lt;li&gt;Deep Learning 개념 및 용어들을 알아봅니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Batch&lt;/code&gt;, &lt;code&gt;Epoch&lt;/code&gt;, &lt;code&gt;CNN&lt;/code&gt;  &lt;/li&gt;
&lt;/ul&gt;
      
      </description>
      
      <content:encoded><![CDATA[<ul><li>Deep Learning 개념 및 용어들을 알아봅니다.</li><li><code>Batch</code>, <code>Epoch</code>, <code>CNN</code>  </li></ul><a id="more"></a><h6 id="Peter-Cha"><a href="#Peter-Cha" class="headerlink" title="Peter Cha"></a>Peter Cha</h6><ul><li><p>Deep Learning을 이해하고, 직접 Deep Learning을 구현하고자 했을 때 필요한 기본 개념들을 정리해 보았습니다. 이번 포스팅에서는 <code>Epoch, Batch</code>라는 단어들의 의미와, 기본적인 <code>CNN - Convolutional Neural Network</code>에 대한 키워드들을 다룹니다. 유명한 <a href="https://tensorflowkorea.gitbooks.io/tensorflow-kr/content/g3doc/tutorials/mnist/download/" target="_blank" rel="noopener">MNIST</a> 데이터를 학습하는 모델을 만들고 싶다고 했을 때, 언급한 키워드들이 어떤 의미로 사용되는지 예시로 함께 보려합니다. </p></li><li><p>In this post, you will learn the Concepts needed when you need to understand the process of training AI or implement the AI by yourself. We are going to talk about <code>Epoch, Batch</code>, and basic <code>CNN</code> knowledges.<br>Supposed we want to make a model which classifies <a href="https://tensorflowkorea.gitbooks.io/tensorflow-kr/content/g3doc/tutorials/mnist/download/" target="_blank" rel="noopener">MNIST</a> data, let’s check how the keywords above can be used.</p></li></ul><h2 id="MNIST"><a href="#MNIST" class="headerlink" title="MNIST"></a>MNIST</h2><ul><li>MNIST data는 아래에서 보시는 것처럼 0 ~ 9까지의 숫자가 적혀 있는, 손글씨 data입니다. 따라서 총 10가지의 class가 있습니다. 이 데이터를 이용해서 우리가 학습시키고 싶은 모델은 따라서 새로운 손글씨 data를 보더라도 0 ~ 9중에 어떤 숫자인지 잘 맞추는 AI가 될 것입니다. </li></ul><center><img src="/gallery/mnist.png" width="500"></center><h6 id="Images-from-tensorflow-gitbooks-io"><a href="#Images-from-tensorflow-gitbooks-io" class="headerlink" title="Images from tensorflow.gitbooks.io."></a>Images from <a href="https://tensorflowkorea.gitbooks.io/tensorflow-kr/content/g3doc/tutorials/mnist/download/" target="_blank" rel="noopener">tensorflow.gitbooks.io</a>.</h6><ul><li>As you can see above, MNIST is a dataset of handwritten digits, 0 to 9. Therefore, MNIST dataset has 10 classes to distinguish. Using this data, Our model to be trained will be able to distinguish 0 ~ 9 handwritten digits.</li></ul><br><h2 id="Epoch-Batch"><a href="#Epoch-Batch" class="headerlink" title="Epoch, Batch"></a>Epoch, Batch</h2><ul><li><p>MNIST는 Training data로 총 6만 장의 수기로 된 숫자를 제공하고, Test용으로 1만 장을 제공하는 Dataset입니다. 자, 그럼 우리는 6만장을 한꺼번에 모델에게 주고 학습해!라고 하면 될까요? 할 수는 있더라도 꽤 여유로운 메모리를 가진 local machine이 아니고서는 좀 힘들겠죠? MNIST가 아닌 더 큰 용량의 데이터일 수록 더 그럴 것입니다.  </p></li><li><p>그래서, 우리는 이 데이터들을 특정한 양으로 나눠서 조금씩 학습을 할 수 있게 넣어주는데요, 그 작은 단위를 <code>Batch</code>라고 부르고, 그 Batch의 크기가 어떠한지를 일컫는 말로, <code>Batch size</code>라고 말합니다. </p></li><li><p>우리가 Batch size를 100으로 정했다고 하면, 총 몇 번의 반복을 해야 총 60000장의 Training data를 다 한 번씩 모델이 학습할 수 있게 될까요? 600번 일 것입니다. 그럼 실제로, 우리 모델은 100장의 데이터를 가져와서 한 번 돌고(학습하고), 앞에서 배운 Back propagation을 통해, Weight를 Update하게 되면, 그 다음 100장을 가져와서 또 학습을 똑같이 반복하는 이 행위를 총 600번을 하게 됩니다. 그렇게 600번을 다 돌았을 때, 우리는 <code>'1 epoch을 돌았다'</code>라고 말합니다. 참고로, 이 600번을 Step size라고 일컫습니다. </p></li></ul><br><h2 id="CNN"><a href="#CNN" class="headerlink" title="CNN"></a>CNN</h2><ul><li><strong>CNN</strong>은 <strong>C</strong>onvolution <strong>N</strong>eural <strong>N</strong>etwork의 약어로, Convolution 계산이 어떻게 Neural Network 2D 이미지 계산과 관련이 있는지는 <a href="https://brunch.co.kr/@chris-song/24" target="_blank" rel="noopener">여기</a>를 참고해주세요. 이 글에서는, CNN에서 자주 언급되는, Filter, Kernel, Stride,  Pooling, 그리고 Padding에 대해서 알아봅니다. </li></ul><h3 id="Feature-Channel-or-Activation-map"><a href="#Feature-Channel-or-Activation-map" class="headerlink" title="Feature(= Channel or Activation map)"></a>Feature(= Channel or Activation map)</h3><ul><li>잠시 MNIST대신에 고양이가 어떻게 생겼는지를 학습하는 Model을 만들고 있다고 생각해 봅시다. 그러면 RGB color로 된 사진을 넣어주게 되고, 우리는 모델에게 이 고양이에 대한 특징(Feature)을 추출해서 학습을 하라고 할 것입니다. </li></ul><center><img src="/gallery/cnn2.png" width="600"></center><h6 id="Images-from-ireneli-eu"><a href="#Images-from-ireneli-eu" class="headerlink" title="Images from ireneli.eu."></a>Images from <a href="https://ireneli.eu/2016/02/03/deep-learning-05-talk-about-convolutional-neural-network%EF%BC%88cnn%EF%BC%89/" target="_blank" rel="noopener">ireneli.eu</a>.</h6><ul><li>자, 그러면 우리 모델이 맨 처음 보게될 이미지는 Width, Height, 그리고 <u>Red, Green, Blue 3가지</u>로 이루어진 이미지를 받게 되는 것이죠. 이 때, 우리는 Channel이라고 부르는 부분으로 이 RGB인 Depth를 지칭합니다. 그러면 원본 이미지는 <code>'channel의 size가 3이다'</code>라고 말 할 수 있게 됩니다. </li><li>우리 MNIST 이미지는 가로 28 pixel, 세로 28 pixel 짜리, 흑백 이미지입니다!(이미지에는 32라고 적혀있지만..) 그래서 MNIST 이미지의 channel의 Size는 1입니다. </li></ul><center><img src="/gallery/cnn_archi.jpg" width="600"></center><h6 id="Images-from-parse-ele-tue-nl"><a href="#Images-from-parse-ele-tue-nl" class="headerlink" title="Images from parse.ele.tue.nl."></a>Images from <a href="http://parse.ele.tue.nl/cluster/2/CNNArchitecture.jpg" target="_blank" rel="noopener">parse.ele.tue.nl</a>.</h6><ul><li>이번에는 왜 이 Channel의 또다른 이름이 Feature, Feature maps인지 알아봅시다. 우리 MNIST 데이터가 위의 그림과 같이 들어간다고 했을 때, $C_1$을 보시면 5x5 크기의 Conv를 통과한 뒤, 이미지가 4겹(?)이 됐습니다. 이 때 우리는 Feature map의 size가 4가 됐다고 말할 수 있습니다. 그리고 $C_2$를 보시면 feature map이 12개가 됐죠. </li><li>이런 행위를 해석을 하자면, 들어온 이미지에 대해서 <code>특징을 추출</code>했는데, $C_1$에서는 특징을 4개를 추출하고, $C_2$에서는 특징을 12개를 추출한 뒤 결과물이라고 생각하시면 됩니다. <code>'특징(Feature)을 추출한다'</code>라는 말이 무슨 말인지 이해를 돕기 위해서, 아래 사진을 준비했습니다. </li></ul><center><img src="/gallery/cnn3.png" height="600"></center><h6 id="Images-from-deliveryimages"><a href="#Images-from-deliveryimages" class="headerlink" title="Images from deliveryimages."></a>Images from <a href="https://deliveryimages.acm.org/10.1145/2010000/2000787/figs/f2.html" target="_blank" rel="noopener">deliveryimages</a>.</h6><ul><li>위 사진은, 사람 얼굴을 학습하는 CNN 모델의 Layer별로 추출한 특징들을 시각화 한 것입니다. 맨처음엔 Pixel로 구성돼있는 원본 이미지에서 맨처음에는 취운 특징인 가로, 세로, 대각선, 원, 곡선 등등의 비교적 단순한 edge들만 특징으로 추출하고 있습니다. </li><li>하지만 모델의 구조가 더 깊이 들어갈 수록, 그 단순한 Feature들을 조합해서 조금더 복잡한 눈, 코, 입 등을 그릴 수 있게 되고, 그 자체를 Feature로 삼을 수 있게 됩니다. 그러다 보면 사람의 전체전인 얼굴이라는 object를 Detect할 수 있는 모델이 되는 것이죠. </li><li>그래서 제 개인적으로는 들어올 때는 Input Image의 Color라는 의미의 Channel로 부르는 것이 더 와닿다가, Layer를 통과할 수록 더욱더 정교한 특징들을 이미지에서 뽑기 때문에, Feature map이라는 말이 더 와닿으니 서로 혼용해서 같은 녀석을 부르는 것 같다는 느낌이 있습니다. </li></ul><h3 id="Kernel-Filter-amp-Stride"><a href="#Kernel-Filter-amp-Stride" class="headerlink" title="Kernel(= Filter) & Stride"></a>Kernel(= Filter) & Stride</h3><ul><li>바로 위에서 설명한 Feature Map은 이제 설명할 Kernel, 혹은 Filter라는 녀석을 통과한 뒤 나온 결과물 입니다. </li><li>이미지가 들어왔을 때, kernel이라는 Window를 정하고, 그 Window를 움직이면서 그 Kernel이 가지고 있는 weight값들과 Input image와의 연산을 통해 새로운 값을 가진 Image를 생성하게 되는 것이죠. 아래 예시를 통해 더 자세히 알아 봅시다. </li></ul><center><img src="/gallery/conv_animation.gif" height="250"></center><h6 id="Images-from-blog-bkbklim-com"><a href="#Images-from-blog-bkbklim-com" class="headerlink" title="Images from blog.bkbklim.com."></a>Images from <a href="https://blog.bkbklim.com/2017/11/24/bks-machine-learning-ai-world-5-convolutional-neural-network/" target="_blank" rel="noopener">blog.bkbklim.com</a>.</h6><ul><li><p>위 Animation에서 <strong>Input</strong>이미지는 <strong>5x5</strong> Size이고, <strong>3x3</strong> Size의 <strong>Kernel</strong>, 혹은 Filter가 한 칸씩 움직이면서 Image와 자신이 가지고 있는 Feature map을 계산하여 결과값을 내놓고 있습니다. <strong>Kernel은 X자 모양의 Filter</strong>네요. element-wise 곱, 즉, dot product를 계산하여 자신의 필터에 부합하는 위치면 곱한 값이, 아니면 0이 곱해져서 의미없는 0이 나오게 됩니다. 그렇게 나온 결과들을 <strong><u>다 더한 값</u></strong> 하나만 결과로 내놓습니다.  </p></li><li><p>여기서 등장하는 <code>Stride</code>! 자연스럽게 이 애니메이션에서는 한 칸씩 움직이고 있습니다만, <strong>어디까지나, Stride가 1x1일 때의 움직임</strong>입니다. <strong><code>Stride</code>는 <u>어느 정도의 간격을 가지고 Kernel 계산을 진행할 것인지</u>를 나타내는 척도</strong>입니다. Stride가 2x2였다면, 두칸씩 움직일테고, 이 Input Size와는 맞지 않기 때문에 에러를 일으킵니다.</p></li><li><p>아래는 Filter를 설명하는 또 다른 이미지 인데요, 우리가 언급한 저 Filter에 보이는 $w$가 심상치 않습니다. </p></li></ul><center><img src="/gallery/cnn5.png" width="700"></center><ul><li>Backpropagation을 하면서 Update되는 Weight들은 다 저, Filter의 Weight들입니다! 더 명확한 특징들을 추출하기 위한 세련된 Filter가 되기 위해 그 weight들을 맞춰나가는 것이죠. </li><li>그럼 이렇게 만들어진 Filter들을 통과하는 Feature map들은 어떻게 형성되는지, 더 명확한 이해를 위해 아래 사진을 보실까요.</li></ul><center><img src="/gallery/filter1.png" width="600"></center><h6 id="Images-from-deliveryimages-1"><a href="#Images-from-deliveryimages-1" class="headerlink" title="Images from deliveryimages."></a>Images from <a href="https://deliveryimages.acm.org/10.1145/2010000/2000787/figs/f2.html" target="_blank" rel="noopener">deliveryimages</a>.</h6><ul><li>위와 같은 Filter가 하나 있습니다. 곡선을 찾는 Filter네요. 그럼 이 Filter가 들어온 쥐 이미지를 Stride에 맞게 돌아 다니게 됩니다. 그러면서, 이 곡선에 해당하는 위치가 있는지 찾습니다. 이 Filter가 한바퀴 다 돌고 완성된 Feature map은, 아래와 같이 해당 Filter에 반응하는 부분에 높은 숫자를, 아닌 부분에서는 0에 가까운 수를 가진 Feature map이 되는 것이죠. </li></ul><br><center><img src="/gallery/filter2.png" width="700"><img src="/gallery/filter3.png" width="700"></center><h6 id="Images-from-deliveryimages-2"><a href="#Images-from-deliveryimages-2" class="headerlink" title="Images from deliveryimages."></a>Images from <a href="https://deliveryimages.acm.org/10.1145/2010000/2000787/figs/f2.html" target="_blank" rel="noopener">deliveryimages</a>.</h6><h4 id="작아지는-Image-Size"><a href="#작아지는-Image-Size" class="headerlink" title="작아지는 Image Size"></a>작아지는 Image Size</h4><ul><li>위에 나온 Animation에서 주목할 점은, <strong>5x5 이었던 이미지 사이즈가, Kernel 계산을 마친 후, 3x3가 됐다는 것</strong>입니다! 이런 계산이 저 위에 사진에서 보셨듯이 32x32 size였던 MNIST 이미지가, $C_1$에서 28x28이되고, $C_2$에서 10x10 size로 줄게 되었는지 설명할 수 있게 됩니다.</li></ul><h3 id="Padding"><a href="#Padding" class="headerlink" title="Padding"></a>Padding</h3><ul><li>이미지가 계속 Convolution layer를 통과하면서 작아지면 나중에는 1x1까지 가다못해 없어지지 않을까요?! 그래서 이미지의 Size가 너무 줄어들지 않게 이미지 주변에 값을 넣어주는 기법을 padding이라고 합니다. 가장 많이 쓰이는 Zero padding으로 예시를 보이자면 아래와 같습니다. </li></ul><center><img src="/gallery/zero_padding.png" width="700"></center><ul><li>저렇게 Kernel Size가 2x2이고, Stride가 1x1인 경우, 원본이 3x3 Size였으면 2x2 kernel로 계산을 해도 총 9번을 계산하여 원본 사이즈를 그대로 유지할 수 있게 됩니다. </li></ul><h3 id="Pooling"><a href="#Pooling" class="headerlink" title="Pooling"></a>Pooling</h3><ul><li>Pooling은 Filter 계산이 아닌, kernel size에 해당하는 영역에 있는 값들을 일괄적으로 처리하고 싶을 때 사용합니다. 대표적인 Pooling으로 많이 쓰이는 Max Pooling의 개념은 아래와 같습니다. </li></ul><center><img src="/gallery/maxpool.png" height="250"></center><h6 id="Images-from-deliveryimages-3"><a href="#Images-from-deliveryimages-3" class="headerlink" title="Images from deliveryimages."></a>Images from <a href="https://deliveryimages.acm.org/10.1145/2010000/2000787/figs/f2.html" target="_blank" rel="noopener">deliveryimages</a>.</h6><ul><li>말 그대로 2x2 Max pooling을 하겠다 하면, 해당 사이즈에서 가장 큰 값만 취하는 것이죠. 가장 중요한 정보만 취하겠다는 의도가 있습니다. 그 외에도 Average Pooling을 비롯한 다양한 Pooling이 있습니다. </li><li>이 Pooling의 장점은, 무엇보다 <strong>계산이 단순해서 계산량, Computation Cost가 작다는 것</strong> 정도가 되겠습니다. </li><li>위에서 배운 Padding을 응용해보면, Padding을 적당히 준 이미지에 Pooling을 하면 이미지 사이즈는 줄지 않지만 빠른 계산은 가능한 구조도 가능하겠죠? </li></ul><hr><br><ul><li>여기까지 기본적인 딥러닝 용어인, Batch, Epoch, 그리고 CNN의 기본 용어들을 살펴 보았습니다! 다음 포스팅에서는, Activation Function, MLP와 CNN의 차이점에 대해 이야기 해 보도록 하겠습니다. </li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content:encoded>
      
      <comments>https://www.stand-firm-peter.me/2018/04/06/Basic-Deep-Learning-02/#disqus_thread</comments>
    </item>
    
    <item>
      <title>Basic Deep learning 01</title>
      <link>https://www.stand-firm-peter.me/2018/02/06/Basic-Deep%20learning-01/</link>
      <guid>https://www.stand-firm-peter.me/2018/02/06/Basic-Deep%20learning-01/</guid>
      <pubDate>Tue, 06 Feb 2018 14:31:02 GMT</pubDate>
      <description>
      
        &lt;ul&gt;
&lt;li&gt;Deep Learning 개념 및 용어들을 알아봅니다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Optimizer&lt;/code&gt;, &lt;code&gt;Loss function&lt;/code&gt;, &lt;code&gt;Back propagation&lt;/code&gt;  &lt;/li&gt;
&lt;/ul&gt;
      
      </description>
      
      <content:encoded><![CDATA[<ul><li>Deep Learning 개념 및 용어들을 알아봅니다.</li><li><code>Optimizer</code>, <code>Loss function</code>, <code>Back propagation</code>  </li></ul><a id="more"></a><h6 id="Peter-Cha"><a href="#Peter-Cha" class="headerlink" title="Peter Cha"></a>Peter Cha</h6><h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><ul><li><p>Deep Learning을 사용해서 우리가 하고자 하는 일련의 과정은 결국, 우리가 만든 AI(model)가 특정 데이터를 얼마나 잘, 데이터를 구별(classification), 혹은 감지(detection)할 수 있게 할 것인가? 하는 것입니다. 물론, GAN과 같은 Unsupervised Learning에서는 말이 달라 질 수 있지만, 설명을 위해 편의상 그렇다고 생각해봅시다. </p></li><li><p>AI를 학습시키고자 하는 데이터만 주면, model 스스로 ‘아, A는 이렇게 생겼구나, 이렇게 생기면 B라고 하구나’하고 그 데이터가 가지고 있는 특징(feature)을 스스로 깨우치기 원하는 거죠. 그렇게 잘 학습이 잘 되면, 한 번도 본 적은 없지만 여태껏 봐왔던 특징을 가지고 있는 새로운 이미지를 봤을 때, ‘아, 이건 A야.’혹은, ‘B야’하고 맞출 수 있게 되는 것이구요.</p></li><li><p>더 쉽게 이야기 해보죠. 우리는 강아지와 고양이가 어떻게 생겼는지 우리 model에게 알려주고, 처음보는 강아지나 고양이를 봐도 그 것이 강아지인지, 고양이인지 잘 구별할 수 있었으면 좋겠습니다. 아래 그림처럼 강아지와, 고양이 그림을 엄청나게 많이 주고 우리는 우리가 만든 Model에게 ‘강아지는 이렇게 생긴거야’, ‘고양이는 이렇게 생겼단다.’하고 알려줍니다. 우리는 이 과정을 학습, 혹은 training - learning이라고 부릅니다. 그렇게 잘 학습된 모델은, 훈련할 때 본 적은 없지만, 처음 본 강아지 사진(test)을 봐도 ‘얘는 강아지네요. 고양이는 아니에요’라고 말할 수 있게 됩니다. </p></li></ul><center><img src="/gallery/Model.jpg" width="700"></center><p>(Image from <a href="https://www.kdnuggets.com/2017/09/databricks-vision-making-deep-learning-simple.html" target="_blank" rel="noopener">KDnuggets</a>)</p><ul><li><p>The purpose of deep learning is all about the question, “How can we let our AI <code>classify</code> or <code>detect</code> the certain image or something?” Of course, there are exceptions like GAN, unspervised learning area, let’s simplify the concept for the explanation.</p></li><li><p>What we want to do is to create the model knowing the <code>characteristics</code> or <code>feature</code> of a particular class of data, so it can answer which class the data in.</p></li><li><p>Let’s talk more easily. We want to tell our model how puppies or cats look like and wish it can distinguish whether it is a puppy or a cat when it sees another puppy or another cat for the first time. As shown in the picture above, we give a lot of puppies and cats pictures to our model, and we teach the model, ‘puppy looks like this’, and ‘cat looks like this.’ This is called, <code>learning</code> or <code>training</code>. Then, as the process progresses, the model can distinguish the cat from the dog. That’s all what we are going to talk about.</p></li></ul><h3 id="In-this-post"><a href="#In-this-post" class="headerlink" title="In this post,"></a>In this post,</h3><ul><li><p>Deep Learning을 이해하고, 직접 Deep Learning을 구현하고자 했을 때 필요한 기본 개념들을 정리해 보았습니다. <code>학습</code>이란 무엇을 의미하는지, <code>Optimizer</code>는 어떤 역할을 하는 것인지, <code>Loss function</code>은 무엇인지, 그리고 마지막으로 <code>Back propagation</code>은 어떻게 진행되는지, 간단한 예시를 통해 알아보도록 하겠습니다. :) </p></li><li><p>In this post, I will talk about the basic concepts of deep learning. Let’s start to learn what <code>Learning</code> means, <code>Optimizer</code> does, <code>Loss function</code> is, and How the <code>Back propagation</code> works via a simple example. </p></li></ul><br><h2 id="Learning"><a href="#Learning" class="headerlink" title="Learning"></a>Learning</h2><ul><li><p>특정한 값을 예측을 하고 싶다고 하면, 우리는 먼저 실제로 그러한 예측을 할 수 있는 <code>Model</code>이 필요합니다. 그리고, 그 <u>모델이 예측한 값(<code>prediction</code>)과 실제 값(<code>grounth truth</code> or <code>answer</code>)과의 값의 차이</u>를 <code>loss</code>라고 말합니다.</p></li><li><p>예를 들어, 간단한 선형 모델인 <code>y = wx</code>을 우리가 모델로 가지고 있다고 합니다. <code>y</code>는 실제 정답이고 <code>x</code>는 input값 입니다. 이 때, <code>w</code>를 우리는 <strong>weight</strong>라고 부릅니다. 보통 맨 처음엔 이 <code>w</code>를 랜덤하게 고릅니다. w가 매우 적절하게 잘 정해져서 실제 정답인 <code>y</code>와 <code>wx</code>가 똑같은 값이 되었다면 $loss$는 0이 되겠죠!</p></li><li><p>그래서 Input인 x를 주면 정답인 y를 잘 맞추려면, 당연히 우리는 이 w를 잘 맞출 필요가 있습니다. 근데 위에서 말한 것 처럼 w를 랜덤하게 시작해서는 곤란하죠. 한 번 만에 잘 맞춘다는 건 힘듭니다. </p></li><li><p>그래서 우리는 학습을 진행을 함에 따라, 우리는 <u>무엇이 됐을지 모르는 이 <code>w</code>값</u>을 <code>반복적으로 update</code>를 시켜서, $loss$를 최소화 할 수 있게끔 만듭니다. </p></li><li><p>그래서 <code>학습</code>이라는 것은 <strong>loss를 최소화 시키는 w 찾기!</strong> 라고 할 수 있습니다. </p><hr></li><li><p>When we predict some values, firstly we need a <code>model</code> that can actually do predict, and we call the difference with a prediction and an actual value, ground truch, <code>loss</code>.</p></li><li><p>For example, if we have a linear model <code>y = wx</code>, <code>y</code> is the answer, and <code>x</code> is input. Then, we call the <code>w</code> <strong>weight</strong>. If the weight is set very properly, then the loss will be 0!</p></li><li><p>We often choose the inital value of <code>w</code> randomly.</p></li><li><p>As the training proceeds, we <code>repeatedly update</code> this w so that we can find minimizes the loss.</p></li><li><p>Therefore, <code>Learning</code> is <strong>finding</strong> <code>w</code> that <strong>minimizes the loss!</strong></p></li></ul><br><h2 id="Optimizer"><a href="#Optimizer" class="headerlink" title="Optimizer"></a>Optimizer</h2><center><img src="/gallery/gradient_descent_algorithm.png" width="500"></center><h3 id="Weight-update"><a href="#Weight-update" class="headerlink" title="Weight update"></a>Weight update</h3><ul><li><p>자,우리는 $loss$를 최소화시키는 $w$를 알고 싶습니다. 그럴 때, $w$가 값에따라, 그림과 같이 $loss$와 $w$의 값으로 그래프를 그렸다고 했을 때, U자로 형성됐다고 생각하고, $loss$를 최소화하는 $w$의 값으로 $w$를 update하고 싶습니다. 시작점은 편의상, 랜덤하게 정해졌다고 합시다.</p></li><li><p>w값을 update시키기 위해서, 우리는 다음과 같은 공식을 씁니다. 여기서 $\alpha$가 뜻하는 것은 <code>learning rate</code>라고 하는 것인데요, 보통 0.001같은 아주 작은 값이고, 그래서 <code>다음 학습할 때 쓸 w는 지금 w와 얼마만큼 떨어져있는지</code>정도를 의미합니다. </p><h3 id="w-w-alpha-cdot-frac-partial-loss-partial-w"><a href="#w-w-alpha-cdot-frac-partial-loss-partial-w" class="headerlink" title="$w = w - \alpha  \cdot \frac {\partial loss}{\partial w}$"></a>$w = w - \alpha  \cdot \frac {\partial loss}{\partial w}$</h3></li><li><p>이 w값은 미분을 하면 구할 수 있는데요, 미분의 의미는 결국 아주 작은 구간에서의 <code>순간변화율</code>이라고 우리가 알고 있는 만큼, 이는 미분은 곧, 기울기의 정도를 표현한다고 할 수 있죠. 이 $w$값을 구하기 위한 미분 방법은 아래에 나오는 Back Propagation을 소개하면서 다시 이야기 하도록 하겠습니다. </p></li><li><p>작은 예시로, Back Propagation이 ‘내가 지금 알고 있는 지식을 가지고 대학교 졸업 후의 나로 돌아 갈 수 있다면, 훨씬 더 좋은 선택과 결정을 하면서 살 수 있을 것이다.’ 같은 겁니다. 여기서, 근데 이 learning rate을 너무 크게 설정해줘서, 필요이상으로 군 입대 하루 전으로 돌아간다면 끔찍하겠죠? 그 과거로 ‘적절히’ 돌아가야 지금 가지고 있는 정보를 십분 활용할 수 있기 때문에, 이 learning rate라는 수치가 중요합니다. </p></li></ul><hr><ul><li><p>Let me think we want to know the value of weigh which minimizes the loss. If we draw a graph consists of loss and w, let us consider it looks like a bowl like the image above. Then, we want to <code>update</code> the weight to the point which becomes the value minimizing the loss. Of course, the starting point is randomly selected.</p></li><li><p>To update the w value, we use follwing equation. <code>alpha</code> means <code>learning rate</code> which is usually very small number like 0.001, so it means that <code>How far the next step w is from where now w is.</code>  </p><h3 id="w-w-alpha-cdot-frac-partial-loss-partial-w-1"><a href="#w-w-alpha-cdot-frac-partial-loss-partial-w-1" class="headerlink" title="$w = w - \alpha  \cdot \frac {\partial loss}{\partial w}$"></a>$w = w - \alpha  \cdot \frac {\partial loss}{\partial w}$</h3></li><li><p>As we know, the meaning of derivative is <code>Instantaneous rate of change</code>, inclination. Let me introduce the way how to calculate the derivative of w, later on the Back propagation part.</p></li></ul><h3 id="SGD"><a href="#SGD" class="headerlink" title="SGD"></a>SGD</h3><ul><li>미분을 이용하여, 만약 미분 결과값이 -인 경우, w는 좀더 양수쪽으로 가게 되고, 반대로는 음수로 가는 방식으로 우리는 w를 update할 수 있습니다. 이런 update 방법을 <code>Stochastic Gradient Descent</code> 최적화 - 한국어로는 경사하강법 -, 또는 줄여서 <code>SGD</code>라고 부릅니다. </li><li>SGD 이외에 최적화 기법으로 Adam, Adamx 등등 다양한 기법들이 있습니다만, 클래식한 이런 경사하강법의 방식의 다른 방식이라고 이해해도 크게 틀리지 않습니다.</li></ul><hr><ul><li>By using derivative, We can update the w in this way: if the drivative value(=gradient) is minus, then w will be move toward the posivie side, and visa versa. This kind of update approach is called <code>Stochastic Gradient Descent</code> Optimization, or <code>SGD</code> for short.</li><li>There are other more various different Optimizers like Adam, Adamax and so on, but you might think that those are different to classical stochastic gradient descent.</li></ul><br> <h2 id="Loss-function"><a href="#Loss-function" class="headerlink" title="Loss function"></a>Loss function</h2><ul><li>자, 그러면 위에서 설명한 loss라는 것을 계산하기 위해서는 어떤 방법을 사용할까요? </li><li><code>Loss function</code>을 설명하기 위해서, 쉬운 loss function 하나를 예시로 들어봅시다.</li><li><code>MSE</code>는 모델의 loss를 산출하는 방법 중 하나입니다. </li><li><code>MSE</code>는 Mean Squared Error의 준 말로, 문자 그대로 아래에 보이는 수식 - <strong>예측한 값에서 실제 값을 빼고 그 차이를 제곱하여 평균을 내는 방식</strong> - 으로 모델의 loss를 계산합니다.</li></ul><hr><ul><li><p>Here, what should we do to get the <code>loss</code> mentioned before?</p></li><li><p>To explain <code>loss function</code>, let’s take an easy loss function as an example.</p></li><li><p>MSE is an one of ways to measure the <code>loss</code> of a model.</p></li><li><p>The Acronym for the <strong>Mean Square Error</strong> which is following equation. <code>y hat</code> is a prediction of our model, and <code>y</code> is a real value. So, it means simply the sum of <strong>differences between forecasts and actual values.</strong></p><center><img src="/gallery/mse.png" width="250"></center></li><li><p>Binary class에 대한 loss를 구해줘야 할 때는, MSE 보다는 <code>BCEloss</code>를 더 잘 씁니다. 이렇게 더 다양한 loss function들이 있습니다. </p></li><li><p>There are various other loss functions like <code>BCEloss</code> for binary loss, and so on.</p></li></ul><br><h2 id="Back-Propagation"><a href="#Back-Propagation" class="headerlink" title="Back Propagation"></a>Back Propagation</h2><ul><li><p><code>역전파</code>라고도 하는, <code>Back Progagation</code>은 <code>loss를 weight로 미분한 값</code>을 계산하는 방법입니다.  </p></li><li><p>예를 들어, 우리의 모델이 선형회기식인, Linear model이라고 하고, 우리의 loss function이 MSE라고 합시다. </p></li><li><p>그러면 우리 모델이 loss를 구할 때 거쳐가게 될 공식은,<br>  $loss = (\hat y - y)^2$ 이기 때문에, 즉 $(x*w - y)^2$이 될테고,<br>  이 식은 아래의 그림과 같이 도식화 할 수 있습니다. </p><hr></li><li><p>Back propagation is the way to calculate the derivate value of loss by <code>w</code>.</p></li><li><p>For example, our model is a linear model, and we use MSE as a loss function. Then, the gates of our model will look like following.</p></li></ul><center><img src="/gallery/backprop1.png" width="600"></center><ul><li><code>x = 1, y = 2, 그리고 w = 1</code>이라고 합시다. 그러면 loss를 구하는 forward path는 명백합니다.</li><li>Let’s assume that <code>x = 1, y = 2, and w = 1</code>. Then, the forward path is obvious.</li></ul><center><img src="/gallery/forward.png" width="600"></center><h3 id="Derivate-Computation"><a href="#Derivate-Computation" class="headerlink" title="Derivate Computation"></a>Derivate Computation</h3><ul><li><a href="https://en.wikipedia.org/wiki/Chain_rule" target="_blank" rel="noopener">Chain Rule</a>에 의해서, 우리는 차근 차근 <code>w의 미분값</code>을 계산해 나갈 수 있습니다. </li><li>$loss\text{ } function$ 공식에서 사용하는 operator 하나를, 하나의 gate라고 생각할 때, 각 gate마다 input으로 들어오게 되는 그 값이 최종 $loss$ 가 산출되는데 얼마만큼이나 기여를 하나. 하는 정도가 곧 우리가 미분을 하는 이유입니다. </li><li>그래서 결국은 그렇게 w가 $loss\text{ } function$에서 input으로 들어가게 될 때의 미분값을 구하면, 그 것은 즉, <code>w가 loss를 구하는데 얼마나 영향을 미치는가(= 기울기)</code>라는 의미가 됩니다. :D</li><li>Back Propagation은 가장 우측의 gate와 함께 loss로부터 시작합니다. </li></ul><hr><ul><li>By using <a href="https://en.wikipedia.org/wiki/Chain_rule" target="_blank" rel="noopener">Chain Rule</a>, we can calculate <code>the derivative value of w</code>, step by step. </li><li>Let us consider the each operator in the loss function is a gate, then, we are going to calculate how much this input of each gate contributes to the loss. That’s the reason why we do the derivative calculation.</li><li>So, at last, we can get the derivative of w as an input of a gate, it means <code>the amount of contribution of w to the final loss value</code>. :D</li><li>The back propagation starts from the loss with rightmost local gate. </li></ul><hr><h3 id="x-2-gate"><a href="#x-2-gate" class="headerlink" title="$x^2$ gate"></a>$x^2$ gate</h3><ul><li><p><code>$loss$인 1</code>은 <code>s인 -1을 제곱</code>해서 나온 값이니까요, $loss = s^2$ 으로 생각할 수 있습니다. loss를 <code>제곱 gate</code>로 미분한 다는 의미의  $\frac{\partial loss} {\partial s}$라는 식은 곧, $\frac{\partial s^2} {\partial s}$라는 식과 같다고 생각할 수 있습니다. </p><h3 id="frac-partial-loss-partial-s-frac-partial-s-2-partial-s"><a href="#frac-partial-loss-partial-s-frac-partial-s-2-partial-s" class="headerlink" title="$\frac{\partial loss} {\partial s}$ =  $\frac{\partial s^2} {\partial s}$"></a>$\frac{\partial loss} {\partial s}$ =  $\frac{\partial s^2} {\partial s}$</h3></li><li><p>$s^2$을 $s$로 미분한거죠! 그러면 $\frac{\partial s^2} {\partial s} = 2s$ 이기 때문에, 우리가 알고 있는 s = -1를 대입하면, $x^2$gate의 local gradient는 <code>-2</code>가 됩니다. </p></li></ul><center><img src="/gallery/backward.png" width="600"></center><ul><li><p>$loss$ is 1, and <code>s</code> is -1, so, the local derative of <code>square gate</code> is <code>-2</code>.</p><h3 id="frac-partial-loss-partial-s-frac-partial-s-2-partial-s-2s"><a href="#frac-partial-loss-partial-s-frac-partial-s-2-partial-s-2s" class="headerlink" title="$\frac{\partial loss} {\partial s}$ = $\frac{\partial s^2} {\partial s} = 2s$"></a>$\frac{\partial loss} {\partial s}$ = $\frac{\partial s^2} {\partial s} = 2s$</h3><p>  Again, <code>s</code> is -1. Therefore, <code>the local gradient of - gate</code> is -2.</p></li></ul><hr><h3 id="gate"><a href="#gate" class="headerlink" title="$-$ gate"></a>$-$ gate</h3><ul><li><p>$x^2$gate에서 -2가 <code>- gate</code>에 $loss$로 들어왔습니다. 그리고 그 - gate의 계산결과는 s인, -1 이었구요. 자, 이제 Chain Rule을 사용해서 <code>- gate</code>의 local gradient를 구해볼까요? </p></li><li><p>우리는, Chain Rule에 의해서, <code>- gate</code>의 local gradient를 아래와 같은 식으로 표현할 수 있습니다.</p><h3 id="frac-partial-loss-partial-hat-y-frac-partial-loss-partial-s-frac-partial-s-partial-hat-y-Rightarrow-2-cdot-frac-partial-hat-y-partial-y-partial-hat-y-2-cdot1-2"><a href="#frac-partial-loss-partial-hat-y-frac-partial-loss-partial-s-frac-partial-s-partial-hat-y-Rightarrow-2-cdot-frac-partial-hat-y-partial-y-partial-hat-y-2-cdot1-2" class="headerlink" title="$\frac{\partial loss} {\partial \hat y} = \frac{\partial loss}{\partial s}\frac {\partial s}{ \partial \hat y} \Rightarrow -2\cdot\frac {\partial \hat y - \partial y}{\partial \hat y} = -2\cdot1 = -2$"></a>$\frac{\partial loss} {\partial \hat y} = \frac{\partial loss}{\partial s}\frac {\partial s}{ \partial \hat y} \Rightarrow -2\cdot\frac {\partial \hat y - \partial y}{\partial \hat y} = -2\cdot1 = -2$</h3></li><li><p>$\frac{\partial loss}{\partial s}$은 -2라는 것을 $x^2$ gate에서 이미 알고 있기때문에, 나머지, s를, $\hat y$로 미분한 결과만 계산해서 곱하면 끝납니다. s는 $\hat y - y$ 라는 식의 결과나 마찬가지었으니, 치환해서 생각하면 편하구요. </p></li><li><p>그래서 결과는 <code>-gate</code>에서도 여전히 <code>local gradient는 -2</code>가 되군요!</p></li></ul><center><img src="/gallery/backward.png" width="600"></center><br><ul><li><code>-2</code> is passed to the <code>- gate</code> as loss. In the <code>- gate</code>, $y$ is a constant value and <strong>$\hat y$</strong> is 1, so the derivative is <code>-2</code>.</li><li>We already know that $\frac{\partial loss}{\partial s}$ = -2, so, the thing we need to do is to calculate the $\frac {\partial \hat y - \partial y}{\partial \hat y}$.<h3 id="frac-partial-loss-partial-hat-y-frac-partial-loss-partial-s-frac-partial-s-partial-hat-y-Rightarrow-2-cdot-frac-partial-hat-y-partial-y-partial-hat-y-2-cdot1-2-1"><a href="#frac-partial-loss-partial-hat-y-frac-partial-loss-partial-s-frac-partial-s-partial-hat-y-Rightarrow-2-cdot-frac-partial-hat-y-partial-y-partial-hat-y-2-cdot1-2-1" class="headerlink" title="$\frac{\partial loss} {\partial \hat y} = \frac{\partial loss}{\partial s}\frac {\partial s}{ \partial \hat y} \Rightarrow -2\cdot\frac {\partial \hat y - \partial y}{\partial \hat y} = -2\cdot1 = -2$"></a>$\frac{\partial loss} {\partial \hat y} = \frac{\partial loss}{\partial s}\frac {\partial s}{ \partial \hat y} \Rightarrow -2\cdot\frac {\partial \hat y - \partial y}{\partial \hat y} = -2\cdot1 = -2$</h3></li></ul><hr><h3 id="gate-1"><a href="#gate-1" class="headerlink" title="$*$  gate"></a>$*$  gate</h3><ul><li><p>자 이제 마지막으로, <code>w</code>가 input으로 들어간 <code>* gate</code>의 local gradient를 계산하고 w의 gradient를 계산하는 과정을 끝냅시다. </p></li><li><p>-gate에서 -2가 $loss$로 넘어왔고, 또 다시, 우리는 위와 같은 방법으로 Chain Rule을 쓰면, </p><h3 id="frac-partial-loss-partial-w-frac-partial-loss-partial-hat-y-frac-partial-hat-y-partial-w"><a href="#frac-partial-loss-partial-w-frac-partial-loss-partial-hat-y-frac-partial-hat-y-partial-w" class="headerlink" title="$\frac {\partial loss}{\partial w} = \frac{\partial loss}{\partial \hat y}\frac{\partial \hat y}{\partial w}$"></a>$\frac {\partial loss}{\partial w} = \frac{\partial loss}{\partial \hat y}\frac{\partial \hat y}{\partial w}$</h3><p>  로, 표현할 수 있고, 또 우린 이미 $\frac{\partial loss}{\partial \hat y}$ = -2 라는 것을 알고 있습니다. </p></li><li><p>그래서 여기서 $\hat y$를 의미하는 식인 $wx$를 $w$로 미분한 값만 알면되는데, 그 값은 $x$이므로 그냥 x였던, 1를 넣어주면, $loss$에 대한 <code>w의 미분값</code>이 <code>-2</code>라는 결과를 얻습니다. 이런 식으로 우리는 w의 미분값을 계산해 나가면서, $loss$가 최소가 되는 w를 찾습니다. </p></li></ul><center><img src="/gallery/backprop.png" width="700"></center><br><ul><li>Let’s finish this process with calculating the local gradient of the <code>* gate</code>.</li><li>As we know, -2 is given from the <code>- gate</code>, so, as the same way, using the Chain Rule again, we can write the equation like following.<h3 id="frac-partial-loss-partial-w-frac-partial-loss-partial-hat-y-frac-partial-hat-y-partial-w-1"><a href="#frac-partial-loss-partial-w-frac-partial-loss-partial-hat-y-frac-partial-hat-y-partial-w-1" class="headerlink" title="$\frac {\partial loss}{\partial w} = \frac{\partial loss}{\partial \hat y}\frac{\partial \hat y}{\partial w}$"></a>$\frac {\partial loss}{\partial w} = \frac{\partial loss}{\partial \hat y}\frac{\partial \hat y}{\partial w}$</h3></li><li>We already know the value of $\frac{\partial loss}{\partial \hat y}$ is -2, so, we just put the value of derivative of $wx$ with $w$, 1.</li><li>Then, at last, we can know the <code>derivative value of w</code> is <code>-2</code>. In this way, we can find the weight point where the loss becomes minimum.</li></ul><h3 id="Update-weight"><a href="#Update-weight" class="headerlink" title="Update weight"></a>Update weight</h3><ul><li>그렇게 계산이 끝난 W의 loss를 어떻게 update해줄까요? 아래 보시는 것처럼 단순히 $w = w - learning{:} rate * w.loss$ 로 Update를 하게 됩니다. 아래 예시에서는 learning rate로 0.01을 줬네요.</li><li>이것으로 Back Propagation에 대한 설명을 마치도록 하겠습니다. </li></ul><br><center><img src="/gallery/backprop_last.png" width="700"></center><br><ul><li>Then, how to update calculated weight’s loss? Simply we can calculate simply like this. $w = w - learning{:} rate * w.loss$ . In the example above, it used 0.01 as a learning rate.</li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content:encoded>
      
      <comments>https://www.stand-firm-peter.me/2018/02/06/Basic-Deep%20learning-01/#disqus_thread</comments>
    </item>
    
    <item>
      <title>How to create a Hexo Blog</title>
      <link>https://www.stand-firm-peter.me/2018/01/06/Start/</link>
      <guid>https://www.stand-firm-peter.me/2018/01/06/Start/</guid>
      <pubDate>Fri, 05 Jan 2018 15:08:14 GMT</pubDate>
      <description>
      
        &lt;ul&gt;
&lt;li&gt;Simple Hexo Tutorial입니다. &lt;/li&gt;
&lt;/ul&gt;
      
      </description>
      
      <content:encoded><![CDATA[<ul><li>Simple Hexo Tutorial입니다. </li></ul><a id="more"></a><p> <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>는 Github pages를 사용해서 만드는 블로그입니다. 그러니, Github 계정을 가지고 계셔야 사용하실 수 있습니다. Github pages는 <code>username.github.io</code>라는 이쁜 고유 도메인<strike>(무려 https)</strike>도 주는 아주 고마운 블로그입니다. 지금 보고 계신 이 블로그도, Hexo로 만들어졌습니다. 도메인만 제가 사서 바꿨을 뿐이구요. </p><p>이 블로그를 설치하고 관리하고 사용하려면, <code>HTML</code>, <code>Markdown</code>, <code>git</code>에 대한 기본적인 이해는 있어야 합니다. 사실, 언급한 기술들을 잘은 몰라도, 대충 한 번씩만 해보셨으면, 하시다보면 익숙해져서 할만 하실 것도 같습니다. :) </p><hr><h2 id="1-Make-a-repository-at-Github"><a href="#1-Make-a-repository-at-Github" class="headerlink" title="1. Make a repository at Github"></a>1. Make a repository at Github</h2><p>Github에 가셔서 새로 Repository를 만드시는데, 그 repository의 이름은 꼭, <code>username.github.io</code>로 하셔야 합니다. 아래 보이는 사진처럼요. </p><img src="/gallery/repository.png" style="width: 700px;"><hr><h2 id="2-Install-Hexo"><a href="#2-Install-Hexo" class="headerlink" title="2. Install Hexo"></a>2. Install Hexo</h2><h3 id="node-js-amp-git"><a href="#node-js-amp-git" class="headerlink" title="node.js & git"></a>node.js & git</h3><p>Hexo를 설치하고, 사용하려면 <a href="https://nodejs.org/ko/" target="_blank" rel="noopener"><code>node.js</code></a>와 <a href="https://git-scm.com/downloads" target="_blank" rel="noopener"><code>git</code></a>이 설치되어 있어야 합니다. 이 두가지 툴이 잘 설치가 되어있다면, 아래와 같은 명령어 한 줄로 간단하게 Hexo를 설치할 수 있습니다. </p><blockquote><p>$ npm install -g hexo-cli</p></blockquote><h3 id="local-directory"><a href="#local-directory" class="headerlink" title="local directory"></a>local directory</h3><p>본인이 사용 하고자 하는 폴더를 만드시고 들어가셔서, 명령어로 </p><blockquote><p>$ hexo init</p></blockquote><blockquote><p>$ npm install</p></blockquote><p>를 순차적으로 입력합니다. 그리고 나서 설치가 끝나면, Hexo blog를 시작할 수 있는 파일들이 설치 된 것을 확인 할 수 있습니다. 저는 temp_blog라는 폴더를 만들어서 설치해 보았습니다. </p><img src="/gallery/temp_blog.png" style="width: 700px;"><hr><h2 id="3-Start-Hexo-Blog"><a href="#3-Start-Hexo-Blog" class="headerlink" title="3. Start Hexo Blog"></a>3. Start Hexo Blog</h2><p>믿기지는 않지만, 이렇게 위의 3개 명령어로 당신의 Hexo Blog가 생겼습니다. 생성된 Blog를 확인해 보도록 합시다. </p><blockquote><p>$ hexo server</p></blockquote><img src="/gallery/hexo_server.png" style="width: 700px;"><p>localhost:4000으로 접속을 하라고 하니, 웹브라우저 창을 통해 <a href="http://localhost:4000/" target="_blank" rel="noopener">http://localhost:4000/</a> 을 입력하거나, 주소를 클릭해서 확인해 봅시다. </p><img src="/gallery/blog.png" style="width: 700px;"><p><strong>Ta da!!</strong> 블로그가 생겼다는 것을 확인할 수 있습니다! :D 가장 기본 테마인 <code>landscape</code>로 설정되어있고, 글은 Hello World 밖에 없지만, 이제 여러분의 취향대로 바꿔나가기만 하면 됩니다!<br> 자, 그럼 차근차근히 어떻게 블로그의 설정을 바꿀 수 있는지, 글은 어떻게 쓰면 되는지, 실제로 나에게 부여된 도메인에 배포를 할 수 있는지 알아봅시다. </p><hr><h2 id="4-Hexo-config-yml"><a href="#4-Hexo-config-yml" class="headerlink" title="4. Hexo _config.yml"></a>4. Hexo _config.yml</h2><p>우리가 설치한 폴더를 보면, <code>_config.yml</code>파일을 확인 할 수 있습니다. 대략적인 모습은 아래와 같습니다. 간단하게, <code>title</code>, <code>timezone</code>, <code>url</code>, 그리고 <code>deploy</code>부분만 본인에게 맞는 정보로 고쳐보기로 합니다.</p><figure class="highlight md hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-section"># Hexo Configuration</span></span><br><span class="line"><span class="hljs-section">## Docs: https://hexo.io/docs/configuration.html</span></span><br><span class="line"><span class="hljs-section">## Source: https://github.com/hexojs/hexo/</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-section"># Site</span></span><br><span class="line">title: Stand firm Peter</span><br><span class="line">subtitle:</span><br><span class="line">description:</span><br><span class="line">author: John Doe</span><br><span class="line">language: en</span><br><span class="line">timezone: Asia/Seoul</span><br><span class="line"></span><br><span class="line"><span class="hljs-section"># URL</span></span><br><span class="line"><span class="hljs-section">## If your site is put in a subdirectory, set url as 'http://yoursite.com/child' and root as '/child/'</span></span><br><span class="line">url: http://petercha90.github.io</span><br><span class="line">root: /</span><br><span class="line">permalink: :year/:month/:day/:title/</span><br><span class="line">permalink_defaults:</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="hljs-section"># Extensions</span></span><br><span class="line"><span class="hljs-section">## Plugins: https://hexo.io/plugins/</span></span><br><span class="line"><span class="hljs-section">## Themes: https://hexo.io/themes/</span></span><br><span class="line">theme: landscape</span><br><span class="line"></span><br><span class="line"><span class="hljs-section"># Deployment</span></span><br><span class="line"><span class="hljs-section">## Docs: https://hexo.io/docs/deployment.html</span></span><br><span class="line"><span class="hljs-section">## 배포방식은 git으로, type은 본인의 repository 주소!</span></span><br><span class="line">deploy: </span><br><span class="line">  type: git</span><br><span class="line">  repo: https://github.com/PeterCha90/petercha90.github.io.git</span><br></pre></td></tr></tbody></table></figure><p>Deployment부분에서 deploy 방식(git)과, 우리 블로그와 실제 부여받은 도메인과의 연결을 할 수 있게 주소를 잘 적어줘야, 이후에 나오는 <code>hexo deploy</code>명령어를 통해 실제로 블로그를 배포할 수 있게 됩니다.<br><code>hexo server</code>로 켰던 로컬 서버를 <code>Ctrl + c</code>로 종료한 다음, <code>hexo server</code>로 서버를 구동시킨 뒤, <code>localhost:4000</code>으로 접속해서 확인해 보면, title이 잘 바뀌어 있습니다 :D</p><img src="/gallery/blog2.png" style="width: 700px;"><hr><h2 id="5-Create-a-new-post"><a href="#5-Create-a-new-post" class="headerlink" title="5. Create a new post"></a>5. Create a new post</h2><p>그럼, posting은 어떻게 하면 될까요?! 이역시, 매우 쉽습니다.</p><blockquote><p>$ hexo new “sample_posting”</p></blockquote><p>이 명령어를 치면, 자동으로 <code>/source/_posts/</code> 밑에, <code>sample_posting.md</code>이라는 파일이 뙇.하고 생겼다는 메세지를 볼 수 있습니다. </p><img src="/gallery/hexo_new.png" style="width: 600px;"><p>이 파일을 열어보시면 뭐가 적힌게 별로 없습니다. </p><figure class="highlight md hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">title: sample_posting</span><br><span class="line">date: 2018-01-13 22:56:29</span><br><span class="line">tags:</span><br><span class="line">---</span><br></pre></td></tr></tbody></table></figure><p>그래서 제가 몇 자 적어보았습니다. </p><figure class="highlight md hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">title: sample_posting</span><br><span class="line">date: 2018-01-13 22:56:29</span><br><span class="line">tags:</span><br><span class="line">---</span><br><span class="line">Markdown </span><br><span class="line"></span><br><span class="line"><span class="hljs-quote">> 몇자 적어 보았습니다. </span></span><br><span class="line"></span><br><span class="line"><span class="hljs-section">## 두 자 적어 봤습니다. </span></span><br><span class="line"></span><br><span class="line"><span class="hljs-strong">**세 자 입니다.**</span></span><br></pre></td></tr></tbody></table></figure><p>그럼 이 <code>sample_posting.md</code>파일을 저장하시고, 아래의 명령어를 수행해 봅니다. </p><blockquote><p>$ hexo generate</p></blockquote><p>뭔가 많이 생성됐다는 메세지가 나왔습니다. 그리고 다시 <code>hexo server</code>를 사용해서 서버를 여시고, 로컬 4000번 포트로 접속해서 확인해 주세요 :D</p><img src="/gallery/blog3.png" style="width: 700px;"><p> 짜잔~ 이렇게 우리의 첫 번째 Posting이 잘 등록 됐습니다! <span class="github-emoji" style="color: transparent;background:no-repeat url(https://assets-cdn.github.com/images/icons/emoji/unicode/1f389.png?v8) center/contain" data-src="https://assets-cdn.github.com/images/icons/emoji/unicode/1f389.png?v8">🎉</span><span class="github-emoji" style="color: transparent;background:no-repeat url(https://assets-cdn.github.com/images/icons/emoji/unicode/1f389.png?v8) center/contain" data-src="https://assets-cdn.github.com/images/icons/emoji/unicode/1f389.png?v8">🎉</span> 위의 제가 적은 내용과 결과를 보시면 알 수 있듯이, Hexo는 기본적으로 <code>Markdown</code> 언어를 지원합니다. </p><hr><h2 id="6-Deploy-to-remote-sites"><a href="#6-Deploy-to-remote-sites" class="headerlink" title="6. Deploy to remote sites"></a>6. Deploy to remote sites</h2><p>자, 그럼 이번에는 마지막으로 이렇게 작성한 블로그와 포스팅을 우리의 실제 원격 저장소(Github repository)로 배포해보도록 합니다. </p><p>먼저, 아래와 같이 <code>hexo-deployer-git</code>을 먼저 설치해주시고,</p><figure class="highlight shell hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">$</span><span class="hljs-bash"> npm install --save hexo-deployer-git</span></span><br></pre></td></tr></tbody></table></figure><p>아래의 명령어를 입력하시면, 배포가 끝났습니다!<span class="github-emoji" style="color: transparent;background:no-repeat url(https://assets-cdn.github.com/images/icons/emoji/unicode/1f606.png?v8) center/contain" data-src="https://assets-cdn.github.com/images/icons/emoji/unicode/1f606.png?v8">😆</span></p><figure class="highlight shell hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">$</span><span class="hljs-bash"> hexo deploy</span></span><br></pre></td></tr></tbody></table></figure><p> 2, 3분 뒤에 <code>username.github.io</code>로 접속하셔서 확인해 보세요 :) </p><hr><h2 id="7-Summary"><a href="#7-Summary" class="headerlink" title="7. Summary"></a>7. Summary</h2><p><code>hexo server</code> </p><ul><li>Blog contents가 올바르게 보이는지 확인할 수 있는 로컬 서버를 구동합니다.</li></ul><p><code>hexo new "title"</code> </p><ul><li>새로운 “title”이라는 이름의 posting을 작성합니다. </li></ul><p><code>hexo generate</code></p><ul><li>수정된 사항으로 deploy할 수 있도록 contents를 생성합니다.</li></ul><p><code>hexo deploy</code></p><ul><li>원격 저장소(github repository)에 실제로 배포합니다. </li></ul><h4 id="Tips"><a href="#Tips" class="headerlink" title="Tips :"></a>Tips :</h4><ul><li><code>hexo generate</code> = <code>hexo g</code></li><li><code>hexo deploy</code> = <code>hexo d</code></li><li><code>hexo clean</code>: 게시글에 html문법이 rendering되지 않고 깨져서 나올 때, 가끔씩 실행<h4 id="Contents-생성-후-바로-배포하기"><a href="#Contents-생성-후-바로-배포하기" class="headerlink" title="Contents 생성 후 바로 배포하기"></a>Contents 생성 후 바로 배포하기</h4></li><li><code>hexo generate deploy</code> = <code>hexo g -d</code></li></ul><hr><h2 id="8-Themes"><a href="#8-Themes" class="headerlink" title="8. Themes"></a>8. Themes</h2><p>기본 테마도 훌륭하지만, 좀 더 다른 느낌의 테마를 원하신다면, <a href="https://hexo.io/themes/index.html" target="_blank" rel="noopener">여기</a>로 들어가셔서, 테마를 고르시고 본인의 <code>_config.yml</code>파일을 수정하면 됩니다!<em>구체적인 테마 적용 방식은 보통 선택한 테마에서 설명</em>을 해주기 때문에, 세부설정이 제각각 다릅니다. <code>_config.yml</code> 파일에서, <code>theme</code>이라는 key 값을 본인이 선택한 테마의 이름으로 바꾼다는 점은 공통이겠지만요 :D 지금 이 튜토리얼을 그대로 따라하셨다면 지금 여러분들의 상태는 아래와 같을 겁니다. </p><blockquote><p>theme: landscape</p></blockquote><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content:encoded>
      
      <comments>https://www.stand-firm-peter.me/2018/01/06/Start/#disqus_thread</comments>
    </item>
    
  </channel>
</rss>
